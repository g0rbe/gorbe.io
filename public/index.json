[{"content":"","date":null,"permalink":"/categories/caddy/","section":"Categories","summary":"","title":"Caddy"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"Personalized IT Solutions, Data Protection, Server Protection, IT Infrastructure Operation and Other IT Services in and around Győr.\n","date":null,"permalink":"/","section":"Daniel Gorbe","summary":"Personalized IT Solutions, Data Protection, Server Protection, IT Infrastructure Operation and Other IT Services in and around Győr.","title":"Daniel Gorbe"},{"content":"","date":null,"permalink":"/categories/http/","section":"Categories","summary":"","title":"Http"},{"content":"Download binary #Download the latest binary in .tar.gz archive from GitHub Releases: https://github.com/caddyserver/caddy/releases/latest\nwget https://github.com/caddyserver/caddy/releases/download/v2.7.6/caddy_2.7.6_linux_amd64.tar.gz Verify Checksum #wget https://github.com/caddyserver/caddy/releases/download/v2.7.6/caddy_2.7.6_checksums.txt sha512sum --ignore-missing -c caddy_2.7.6_checksums.txt Verify Signature #See Caddy\u0026rsquo;s documentation how to verify the signature.\nExtract the binary #Extract the binary from the downloaded archive:\ntar -xf caddy_2.7.6_linux_amd64.tar.gz caddy Install the binary #Use the install command to copy the binary to /usr/local/bin/ and set attributes:\nsudo install -v caddy /usr/bin/ Create user and group #Create the group first:\nsudo groupadd --system caddy Create the caddy user:\nsudo useradd --system --gid caddy --create-home --home-dir /var/lib/caddy --shell /usr/sbin/nologin caddy Create Caddyfile #Create the directory for the Caddyfile:\nmkdir /etc/caddy Now, create the Caddyfile:\ntouch /etc/caddy/Caddyfile Change the user and group of the config directory:\nchown -R caddy:caddy /etc/caddy/ Configure systemd #Create the systemd service:\nnano /etc/systemd/system/caddy.service [Unit] Description=Caddy After=network.target network-online.target Requires=network-online.target [Service] Type=notify User=caddy Group=caddy ExecStartPre=/usr/bin/caddy validate --config /etc/caddy/Caddyfile ExecStart=/usr/bin/caddy run --environ --config /etc/caddy/Caddyfile ExecReload=/usr/bin/caddy reload --config /etc/caddy/Caddyfile --force TimeoutStopSec=5s LimitNOFILE=1048576 PrivateTmp=true ProtectSystem=full AmbientCapabilities=CAP_NET_ADMIN CAP_NET_BIND_SERVICE [Install] WantedBy=multi-user.target Reload systemd to load the new service:\nsudo systemctl daemon-reload Enable the service to start at boot:\nsudo systemctl enable --now caddy ","date":"15 August 2024","permalink":"/posts/caddy/install/","section":"Posts","summary":"How to install Caddy on Debian Linux server.","title":"Install Caddy on Linux"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/categories/web/","section":"Categories","summary":"","title":"Web"},{"content":"","date":null,"permalink":"/categories/webserver/","section":"Categories","summary":"","title":"Webserver"},{"content":"","date":null,"permalink":"/categories/encryption/","section":"Categories","summary":"","title":"Encryption"},{"content":"Debian #apt install certbot python3-certbot-nginx ","date":"19 April 2024","permalink":"/posts/certbot/install/","section":"Posts","summary":"Install Certbot to obtain free TLS certificate from Let\u0026rsquo;s Encrypt.","title":"Install Certbot"},{"content":"Nginx #RSA-4096 #certbot certonly --nginx -d example.com --key-type rsa --rsa-key-size 4096 ","date":"19 April 2024","permalink":"/posts/certbot/certificate/","section":"Posts","summary":"Use Certbot to obtain free TLS certificate from Let\u0026rsquo;s Encrypt.","title":"Obtain SSL Certificate(s) with Certbot"},{"content":"","date":null,"permalink":"/categories/security/","section":"Categories","summary":"","title":"Security"},{"content":"","date":null,"permalink":"/categories/ssl/","section":"Categories","summary":"","title":"Ssl"},{"content":"","date":null,"permalink":"/categories/tls/","section":"Categories","summary":"","title":"Tls"},{"content":"Redmine is a flexible project management web application. Written using the Ruby on Rails framework, it is cross-platform and cross-database. Redmine is open source and released under the terms of the GNU General Public License v2 (GPL).\nInstall requirements #sudo apt install postgresql ruby ruby-dev build-essential libpq-dev imagemagick ghostscript Download Redmine #cd /opt/ wget https://www.redmine.org/releases/redmine-5.1.1.tar.gz Check the SHA256SUM of the downloaded archive:\nsha256sum redmine-5.1.1.tar.gz Extract the archive:\ntar -xf redmine-5.1.1.tar.gz ln -s /opt/redmine-5.1.1 /opt/redmine Create an empty database and the user #sudo -u postgres psql CREATE ROLE redmine LOGIN ENCRYPTED PASSWORD \u0026#39;my_password\u0026#39; NOINHERIT VALID UNTIL \u0026#39;infinity\u0026#39;; CREATE DATABASE redmine WITH ENCODING=\u0026#39;UTF8\u0026#39; OWNER=redmine; \\c redmine GRANT ALL ON SCHEMA public TO redmine; Database configuration #Copy config/database.yml.example to config/database.yml and edit this file in order to configure your database settings for \u0026ldquo;production\u0026rdquo; environment.\ncp config/database.yml.example config/database.yml nano config/database.yml production: adapter: postgresql database: redmine host: localhost username: redmine password: \u0026#34;\u0026lt;postgres_user_password\u0026gt;\u0026#34; encoding: utf8 Install Ruby dependencies #Puma #Add Puma gem:\nnano Gemfile.local # Gemfile.local gem \u0026#39;puma\u0026#39; bundle3.1 config set --local without \u0026#39;development test\u0026#39; bundle3.1 install Session token generation #bundle3.1 exec rake generate_secret_token Database schema objects creation #RAILS_ENV=production bundle3.1 exec rake db:migrate Database default data set #RAILS_ENV=production bundle3.1 exec rake redmine:load_default_data Filesystem permissions #Add redmine user:\nadduser --system --group --no-create-home --shell /sbin/nologin redmine chown -R redmine:redmine /opt/redmine Configurations #Redmine settings are defined in a file named config/configuration.yml. If you need to override default application settings, simply copy config/configuration.yml.example to config/configuration.yml.\nStart the server #bundle3.1 exec rails server -e production systemd #nano /lib/systemd/system/redmine.service [Unit] Description=Redmine After=postgresql.service [Service] User=redmine Group=redmine WorkingDirectory=/opt/redmine/ Type=simple Restart=always RestartSec=1 ExecStart=/usr/bin/bundle3.1 exec rails server -e production [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl enable --now redmine.service ","date":"6 February 2024","permalink":"/posts/redmine/install-redmine-5/","section":"Posts","summary":"Redmine is a flexible project management web application.","title":"How to Install Redmine 5 on Debian 12"},{"content":"","date":null,"permalink":"/tags/opensource/","section":"Tags","summary":"","title":"Opensource"},{"content":"","date":null,"permalink":"/tags/productivity/","section":"Tags","summary":"","title":"Productivity"},{"content":"","date":null,"permalink":"/tags/projectmanagement/","section":"Tags","summary":"","title":"Projectmanagement"},{"content":"","date":null,"permalink":"/tags/selfhost/","section":"Tags","summary":"","title":"Selfhost"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"Learn Regex the Easy Way # What is Regular Expression? #A regular expression is a group of characters or symbols which is used to find a specific pattern in a text.\nA regular expression is a pattern that is matched against a subject string from left to right. Regular expressions are used to replace text within a string, validate forms, extract a substring from a string based on a pattern match, and so much more. The term \u0026ldquo;regular expression\u0026rdquo; is a mouthful, so you will usually find the term abbreviated to \u0026ldquo;regex\u0026rdquo; or \u0026ldquo;regexp\u0026rdquo;.\nImagine you are writing an application and you want to set the rules for when a user chooses their username. We want to allow the username to contain letters, numbers, underscores and hyphens. We also want to limit the number of characters in the username so it does not look ugly. We can use the following regular expression to validate the username:\nThe regular expression above can accept the strings john_doe, jo-hn_doe and john12_as. It does not match Jo because that string contains an uppercase letter and also it is too short.\n1. Basic Matchers #A regular expression is just a pattern of characters that we use to perform a search in a text. For example, the regular expression the means: the letter t, followed by the letter h, followed by the letter e.\n\"the\" =\\\u003e The fat cat sat on the mat. Test the regular expression\nThe regular expression 123 matches the string 123. The regular expression is matched against an input string by comparing each character in the regular expression to each character in the input string, one after another. Regular expressions are normally case-sensitive so the regular expression The would not match the string the.\n\"The\" =\\\u003e The fat cat sat on the mat. Test the regular expression\n2. Meta Characters #Meta characters are the building blocks of regular expressions. Meta characters do not stand for themselves but instead are interpreted in some special way. Some meta characters have a special meaning and are written inside square brackets. The meta characters are as follows:\nMeta character Description . Period matches any single character except a line break. [ ] Character class. Matches any character contained between the square brackets. [^ ] Negated character class. Matches any character that is not contained between the square brackets * Matches 0 or more repetitions of the preceding symbol. + Matches 1 or more repetitions of the preceding symbol. ? Makes the preceding symbol optional. {n,m} Braces. Matches at least \u0026ldquo;n\u0026rdquo; but not more than \u0026ldquo;m\u0026rdquo; repetitions of the preceding symbol. (xyz) Character group. Matches the characters xyz in that exact order. | Alternation. Matches either the characters before or the characters after the symbol. \\ Escapes the next character. This allows you to match reserved characters [ ] ( ) { } . * + ? ^ $ \\ | ^ Matches the beginning of the input. $ Matches the end of the input. 2.1 The Full Stop #The full stop . is the simplest example of a meta character. The meta character . matches any single character. It will not match return or newline characters. For example, the regular expression .ar means: any character, followed by the letter a, followed by the letter r.\n\".ar\" =\u003e The car parked in the garage. Test the regular expression\n2.2 Character Sets #Character sets are also called character classes. Square brackets are used to specify character sets. Use a hyphen inside a character set to specify the characters\u0026rsquo; range. The order of the character range inside the square brackets doesn\u0026rsquo;t matter. For example, the regular expression [Tt]he means: an uppercase T or lowercase t, followed by the letter h, followed by the letter e.\n\"[Tt]he\" =\u003e The car parked in the garage. Test the regular expression\nA period inside a character set, however, means a literal period. The regular expression ar[.] means: a lowercase character a, followed by the letter r, followed by a period . character.\n\"ar[.]\" =\u003e A garage is a good place to park a car. Test the regular expression\n2.2.1 Negated Character Sets #In general, the caret symbol represents the start of the string, but when it is typed after the opening square bracket it negates the character set. For example, the regular expression [^c]ar means: any character except c, followed by the character a, followed by the letter r.\n\"[^c]ar\" =\u003e The car parked in the garage. Test the regular expression\n2.3 Repetitions #The meta characters +, * or ? are used to specify how many times a subpattern can occur. These meta characters act differently in different situations.\n2.3.1 The Star #The * symbol matches zero or more repetitions of the preceding matcher. The regular expression a* means: zero or more repetitions of the preceding lowercase character a. But if it appears after a character set or class then it finds the repetitions of the whole character set. For example, the regular expression [a-z]* means: any number of lowercase letters in a row.\n\"[a-z]*\" =\u003e The car parked in the garage #21. Test the regular expression\nThe * symbol can be used with the meta character . to match any string of characters .*. The * symbol can be used with the whitespace character \\s to match a string of whitespace characters. For example, the expression \\s*cat\\s* means: zero or more spaces, followed by a lowercase c, followed by a lowercase a, followed by a lowercase t, followed by zero or more spaces.\n\"\\s*cat\\s*\" =\u003e The fat cat sat on the concatenation. Test the regular expression\n2.3.2 The Plus #The + symbol matches one or more repetitions of the preceding character. For example, the regular expression c.+t means: a lowercase c, followed by at least one character, followed by a lowercase t. It needs to be clarified thatt is the last t in the sentence.\n\"c.+t\" =\u003e The fat cat sat on the mat. Test the regular expression\n2.3.3 The Question Mark #In regular expressions, the meta character ? makes the preceding character optional. This symbol matches zero or one instance of the preceding character. For example, the regular expression [T]?he means: Optional uppercase T, followed by a lowercase h, followed by a lowercase e.\n\"[T]he\" =\u003e The car is parked in the garage. Test the regular expression\n\"[T]?he\" =\u003e The car is parked in the garage. Test the regular expression\n2.4 Braces #In regular expressions, braces (also called quantifiers) are used to specify the number of times that a character or a group of characters can be repeated. For example, the regular expression [0-9]{2,3} means: Match at least 2 digits, but not more than 3, ranging from 0 to 9.\n\"[0-9]{2,3}\" =\u003e The number was 9.9997 but we rounded it off to 10.0. Test the regular expression\nWe can leave out the second number. For example, the regular expression [0-9]{2,} means: Match 2 or more digits. If we also remove the comma, the regular expression [0-9]{3} means: Match exactly 3 digits.\n\"[0-9]\\{2,\\}\" =\u003e The number was 9.9997 but we rounded it off to 10.0. Test the regular expression\n\"[0-9]\\{3\\}\" =\u003e The number was 9.9997 but we rounded it off to 10.0. Test the regular expression\n2.5 Capturing Groups #A capturing group is a group of subpatterns that is written inside parentheses (...). As discussed before, in regular expressions, if we put a quantifier after a character then it will repeat the preceding character. But if we put a quantifier after a capturing group then it repeats the whole capturing group. For example, the regular expression (ab)* matches zero or more repetitions of the character \u0026ldquo;ab\u0026rdquo;. We can also use the alternation | meta character inside a capturing group. For example, the regular expression (c|g|p)ar means: a lowercase c, g or p, followed by a, followed by r.\n\"(c|g|p)ar\" =\u003e The car is parked in the garage. Test the regular expression\nNote that capturing groups do not only match, but also capture, the characters for use in the parent language. The parent language could be Python or JavaScript or virtually any language that implements regular expressions in a function definition.\n2.5.1 Non-Capturing Groups #A non-capturing group is a capturing group that matches the characters but does not capture the group. A non-capturing group is denoted by a ? followed by a : within parentheses (...). For example, the regular expression (?:c|g|p)ar is similar to (c|g|p)ar in that it matches the same characters but will not create a capture group.\n\"(?:c|g|p)ar\" =\u003e The car is parked in the garage. Test the regular expression\nNon-capturing groups can come in handy when used in find-and-replace functionality or when mixed with capturing groups to keep the overview when producing any other kind of output. See also 4. Lookaround.\n2.6 Alternation #In a regular expression, the vertical bar | is used to define alternation. Alternation is like an OR statement between multiple expressions. Now, you may be thinking that character sets and alternation work the same way. But the big difference between character sets and alternation is that character sets work at the character level but alternation works at the expression level. For example, the regular expression (T|t)he|car means: either (an uppercase T or a lowercase t, followed by a lowercase h, followed by a lowercase e) OR (a lowercase c, followed by a lowercase a, followed by a lowercase r). Note that I included the parentheses for clarity, to show that either expression in parentheses can be met and it will match.\n\"(T|t)he|car\" =\u003e The car is parked in the garage. Test the regular expression\n2.7 Escaping Special Characters #A backslash \\ is used in regular expressions to escape the next character. This allows us to include reserved characters such as { } [ ] / \\ + * . $ ^ | ? as matching characters. To use one of these special character as a matching character, prepend it with \\.\nFor example, the regular expression . is used to match any character except a newline. Now, to match . in an input string, the regular expression (f|c|m)at\\.? means: a lowercase f, c or m, followed by a lowercase a, followed by a lowercase t, followed by an optional . character.\n\"(f|c|m)at\\.?\" =\u003e The fat cat sat on the mat. Test the regular expression\n2.8 Anchors #In regular expressions, we use anchors to check if the matching symbol is the starting symbol or ending symbol of the input string. Anchors are of two types: The first type is the caret ^ that checks if the matching character is the first character of the input and the second type is the dollar sign $ which checks if a matching character is the last character of the input string.\n2.8.1 The Caret #The caret symbol ^ is used to check if a matching character is the first character of the input string. If we apply the following regular expression ^a (meaning \u0026lsquo;a\u0026rsquo; must be the starting character) to the string abc, it will match a. But if we apply the regular expression ^b to the above string, it will not match anything. Because in the string abc, the \u0026ldquo;b\u0026rdquo; is not the starting character. Let\u0026rsquo;s take a look at another regular expression ^(T|t)he which means: an uppercase T or a lowercase t must be the first character in the string, followed by a lowercase h, followed by a lowercase e.\n\"(T|t)he\" =\u003e The car is parked in the garage. Test the regular expression\n\"^(T|t)he\" =\u003e The car is parked in the garage. Test the regular expression\n2.8.2 The Dollar Sign #The dollar sign $ is used to check if a matching character is the last character in the string. For example, the regular expression (at\\.)$ means: a lowercase a, followed by a lowercase t, followed by a . character and the matcher must be at the end of the string.\n\"(at\\.)\" =\u003e The fat cat. sat. on the mat. Test the regular expression\n\"(at\\.)$\" =\u003e The fat cat. sat. on the mat. Test the regular expression\n3. Shorthand Character Sets #There are a number of convenient shorthands for commonly used character sets/ regular expressions:\nShorthand Description . Any character except new line \\w Matches alphanumeric characters: [a-zA-Z0-9_] \\W Matches non-alphanumeric characters: [^\\w] \\d Matches digits: [0-9] \\D Matches non-digits: [^\\d] \\s Matches whitespace characters: [\\t\\n\\f\\r\\p{Z}] \\S Matches non-whitespace characters: [^\\s] 4. Lookarounds #Lookbehinds and lookaheads (also called lookarounds) are specific types of non-capturing groups (used to match a pattern but without including it in the matching list). Lookarounds are used when a pattern must be preceded or followed by another pattern. For example, imagine we want to get all numbers that are preceded by the $ character from the string $4.44 and $10.88. We will use the following regular expression (?\u0026lt;=\\$)[0-9\\.]* which means: get all the numbers which contain the . character and are preceded by the $ character. These are the lookarounds that are used in regular expressions:\nSymbol Description ?= Positive Lookahead ?! Negative Lookahead ?\u0026lt;= Positive Lookbehind ?\u0026lt;! Negative Lookbehind 4.1 Positive Lookahead #The positive lookahead asserts that the first part of the expression must be followed by the lookahead expression. The returned match only contains the text that is matched by the first part of the expression. To define a positive lookahead, parentheses are used. Within those parentheses, a question mark with an equals sign is used like this: (?=...). The lookahead expressions is written after the equals sign inside parentheses. For example, the regular expression (T|t)he(?=\\sfat) means: match either a lowercase t or an uppercase T, followed by the letter h, followed by the letter e. In parentheses we define a positive lookahead which tells the regular expression engine to match The or the only if it\u0026rsquo;s followed by the word fat.\n\"(T|t)he(?=\\sfat)\" =\u003e The fat cat sat on the mat. Test the regular expression\n4.2 Negative Lookahead #Negative lookaheads are used when we need to get all matches from an input string that are not followed by a certain pattern. A negative lookahead is written the same way as a positive lookahead. The only difference is, instead of an equals sign =, we use an exclamation mark ! to indicate negation i.e. (?!...). Let\u0026rsquo;s take a look at the following regular expression (T|t)he(?!\\sfat) which means: get all The or the words from the input string that are not followed by a space character and the word fat.\n\"(T|t)he(?!\\sfat)\" =\u003e The fat cat sat on the mat. Test the regular expression\n4.3 Positive Lookbehind #Positive lookbehinds are used to get all the matches that are preceded by a specific pattern. Positive lookbehinds are written (?\u0026lt;=...). For example, the regular expression (?\u0026lt;=(T|t)he\\s)(fat|mat) means: get all fat or mat words from the input string that come after the word The or the.\n\"(?\\\u003c=(T|t)he\\s)(fat|mat)\" =\u003e The fat cat sat on the mat. Test the regular expression\n4.4 Negative Lookbehind #Negative lookbehinds are used to get all the matches that are not preceded by a specific pattern. Negative lookbehinds are written (?\u0026lt;!...). For example, the regular expression (?\u0026lt;!(T|t)he\\s)(cat) means: get all cat words from the input string that are not after the word The or the.\n\"(?\u0026lt;!(T|t)he\\s)(cat)\" =\u003e The cat sat on cat. Test the regular expression\n5. Flags #Flags are also called modifiers because they modify the output of a regular expression. These flags can be used in any order or combination, and are an integral part of the RegExp.\nFlag Description i Case insensitive: Match will be case-insensitive. g Global Search: Match all instances, not just the first. m Multiline: Anchor meta characters work on each line. 5.1 Case Insensitive #The i modifier is used to perform case-insensitive matching. For example, the regular expression /The/gi means: an uppercase T, followed by a lowercase h, followed by an e. And at the end of regular expression the i flag tells the regular expression engine to ignore the case. As you can see, we also provided g flag because we want to search for the pattern in the whole input string.\n\"The\" =\u003e The fat cat sat on the mat. Test the regular expression\n\"/The/gi\" =\u003e The fat cat sat on the mat. Test the regular expression\n5.2 Global Search #The g modifier is used to perform a global match (finds all matches rather than stopping after the first match). For example, the regular expression/.(at)/g means: any character except a new line, followed by a lowercase a, followed by a lowercase t. Because we provided the g flag at the end of the regular expression, it will now find all matches in the input string, not just the first one (which is the default behavior).\n\"/.(at)/\" =\u003e The fat cat sat on the mat. Test the regular expression\n\"/.(at)/g\" =\u003e The fat cat sat on the mat. Test the regular expression\n5.3 Multiline #The m modifier is used to perform a multi-line match. As we discussed earlier, anchors (^, $) are used to check if a pattern is at the beginning of the input or the end. But if we want the anchors to work on each line, we use the m flag. For example, the regular expression /at(.)?$/gm means: a lowercase a, followed by a lowercase t and, optionally, anything except a new line. And because of the m flag, the regular expression engine now matches patterns at the end of each line in a string.\n\"/.at(.)?$/\" =\u003e The fat cat sat on the mat. Test the regular expression\n\"/.at(.)?$/gm\" =\u003e The fat cat sat on the mat. Test the regular expression\n6. Greedy vs Lazy Matching #By default, a regex will perform a greedy match, which means the match will be as long as possible. We can use ? to match in a lazy way, which means the match should be as short as possible.\n\"/(.*at)/\" =\u003e The fat cat sat on the mat. Test the regular expression\n\"/(.*?at)/\" =\u003e The fat cat sat on the mat. Test the regular expression\nContribution # Open a pull request with improvements Discuss ideas in issues Spread the word Reach out with any feedback Twitter URL License #MIT © Zeeshan Ahmad\n","date":"1 February 2024","permalink":"/posts/regex/learn-regex-the-easy-way/","section":"Posts","summary":"Learn Regex the Easy Way # What is Regular Expression?","title":""},{"content":"I have been dealing with cyber security and IT systems operation for more than 5 years, of which I have provided system administrator services to businesses in and around Győr for the last three years. My area of expertise is the operation and protection of Linux-based servers.\nMy clients describe me as a helpful, problem-oriented person. I quickly find common ground with everyone, thanks to which I work quickly and efficiently in a team. I pay special attention to development. I help make a decision with suggestions and testable demos. In addition to the infrastructure, I also keep my knowledge up-to-date so that I can provide the best technology solutions, as I know that innovative ideas have outstanding added value.\nMy goal is to build and operate a safe, stable and cost-effective infrastructure that can serve hundreds of thousands of customers with 99.9% availability. I constantly monitor the existing systems so that I can react immediately to errors that occur. In addition to security, I pay particular attention to avoiding data loss and to user-friendly design so that the work goes smoothly.\nI have helped many of my partners to modernize and further develop their businesses. I have successfully completed every project, be it a custom-made website or a fully automated infrastructure supported by artificial intelligence.\n","date":"23 January 2024","permalink":"/about/","section":"Daniel Gorbe","summary":"I have been dealing with cyber security and IT systems operation for more than 5 years, of which I have provided system administrator services to businesses in and around Győr for the last three years.","title":"About"},{"content":"Phone/Signal: +36203323371\nEmail: daniel@gorbe.io\nPGP: 5AEB729B3E642A16\nLocation: Hungary, Győr\nGitHub: g0rbe\nLinkedIn: g0rbe\nTwitter: _g0rbe\n","date":"1 January 2024","permalink":"/contact/","section":"Daniel Gorbe","summary":"Phone/Signal: +36203323371","title":"Contact"},{"content":"IT service for small and medium-sized companies tailored to your business needs. #\nAdvice, analysis Planning, redesign Operation, optimization Hosting in your own data center Mail, contacts, calendar Data backup Linux and Windows server systems Virtualization and containers Network, firewall, VPN, WLAN Hosting # Websites Video conference Password manager NAS Git server Server monitoring Anything you want, there is 99% chance that there is an open source solution for your problem. Hardening / Tuning # OpenSSH Nginx Linux kernel Firewall # Creating and/or setting firewall DDOS protection Brute Force protection TCP/IP Network # Router configuration VPN Tor Ethical Hacking # Wireless penetration Network audit Vulnerability assessment Consulting # Data protection against unauthorized access Incident prevention ","date":"1 January 2024","permalink":"/services/","section":"Daniel Gorbe","summary":"IT service for small and medium-sized companies tailored to your business needs.","title":"Services"},{"content":"PHP is a crucial component for web development, and having the latest version ensures access to the newest features and security updates. Debian 12, known for its stability and reliability, is a popular choice for hosting PHP-based applications. This post guides you through installing the latest PHP version on Debian 12.\nTLDR #sudo apt install -y lsb-release apt-transport-https ca-certificates curl \u0026amp;\u0026amp; \\ sudo wget -O \u0026#34;/etc/apt/trusted.gpg.d/php.gpg\u0026#34; \u0026#34;https://packages.sury.org/php/apt.gpg\u0026#34; \u0026amp;\u0026amp; \\ echo \u0026#34;deb https://packages.sury.org/php/ $(lsb_release -sc) main\u0026#34; | sudo tee \u0026#34;/etc/apt/sources.list.d/php.list\u0026#34; \u0026amp;\u0026amp; \\ sudo apt update Pre-Installation Steps #Before beginning the installation, it\u0026rsquo;s important to update your system:\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade These commands will update your package list and upgrade existing packages to their latest versions.\nAdding a Third-Party Repository #Debian’s default repositories might not always contain the latest PHP version. To access the most recent release, you\u0026rsquo;ll need to add a third-party repository maintained by Ondřej Surý, a well-known PHP maintainer:\nsudo apt install lsb-release apt-transport-https ca-certificates curl sudo wget -O /etc/apt/trusted.gpg.d/php.gpg https://packages.sury.org/php/apt.gpg echo \u0026#34;deb https://packages.sury.org/php/ $(lsb_release -sc) main\u0026#34; | sudo tee /etc/apt/sources.list.d/php.list This sequence adds the necessary GPG key and repository for the latest PHP versions.\nInstalling the Latest PHP #First, update your package list:\nsudo apt update Then, install the latest PHP version available in the repository:\nsudo apt install php NOTE: php and php-fpm packages are dependency packages, which depends on latest stable PHP version.\nOptionally, you can install additional PHP modules based on your requirements:\nsudo apt install php-cli php-fpm php-mysql php-xml php-curl ... ","date":"16 December 2023","permalink":"/posts/php/install/","section":"Posts","summary":"PHP is a crucial component for web development, and having the latest version ensures access to the newest features and security updates.","title":"Install PHP on Debian"},{"content":"Setting up a chroot jail for SFTP (Secure File Transfer Protocol) on a Debian server enhances security by restricting users\u0026rsquo; access to a specific directory. This is particularly useful for granting limited file transfer capabilities without providing full shell access.\nInstalling and Configuring SSH #Ensure that the SSH server is installed:\nsudo apt-get install openssh-server Then, edit the SSH configuration file:\nsudo nano /etc/ssh/sshd_config Configuring Chroot Environment #In the sshd_config file, locate or add the following lines to set up a chroot environment:\nSubsystem sftp internal-sftp Match Group sftponly ChrootDirectory /home/%u ForceCommand internal-sftp AllowTcpForwarding no X11Forwarding no Replace /home/%u with your desired chroot directory and sftponly with the group name for restricted users.\nCreating User and Group #Create a group for chroot-restricted users:\nsudo groupadd sftponly Add a user to this group and set their home directory:\nsudo useradd -m -g sftponly -s /bin/false username sudo passwd username Ensure the user\u0026rsquo;s home directory is owned by root:\nsudo chown root:root /home/username Create a subdirectory for user files, with appropriate permissions:\nsudo mkdir /home/username/files sudo chown username:sftponly /home/username/files Restarting SSH #Apply changes by restarting the SSH service:\nsudo systemctl restart sshd Testing the Configuration #Test your setup by connecting through an SFTP client using the newly created user credentials. The user should only access the specified directory.\n","date":"15 November 2023","permalink":"/posts/openssh/sftp-chroot/","section":"Posts","summary":"Setting up a chroot jail for SFTP (Secure File Transfer Protocol) on a Debian server enhances security by restricting users\u0026rsquo; access to a specific directory.","title":"Configure SFTP with Chroot Jail on Debian"},{"content":"","date":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux"},{"content":"","date":null,"permalink":"/tags/security/","section":"Tags","summary":"","title":"Security"},{"content":"","date":null,"permalink":"/tags/sftp/","section":"Tags","summary":"","title":"Sftp"},{"content":"","date":null,"permalink":"/tags/ssh/","section":"Tags","summary":"","title":"Ssh"},{"content":"","date":null,"permalink":"/tags/php-fpm/","section":"Tags","summary":"","title":"Php-Fpm"},{"content":"PHP-FPM (FastCGI Process Manager) is an alternative PHP FastCGI implementation with some additional features useful for sites of any size, especially busier sites.\nInstall #apt install php-fpm Configuration #The FPM\u0026rsquo;s main configuration file is /etc/php/$VERSION/fpm/php.ini.\nMemory limit #Maximum amount of memory that the PHP script can use.\nmemory_limit = 128M FPM Pool #It is possible to isolate the php codes with fpm pools.\nFirst, create a new user to the new pool:\nadduser --no-create-home --disabled-login pooluser Create the new pool file (copy the existing one):\ncp /etc/php/7.2/fpm/pool.d/www.conf /etc/php/7.2/fpm/pool.d/newpool.conf Modify the new pool\u0026rsquo;s configurations:\nnano /etc/php/7.2/fpm/pool.d/newpool.conf # The section name must be changed from [www] [newpool] ... # The user who will be run the process user = pooluser group = pooluser ... # The new pool\u0026#39;s socket\u0026#39;s name listen = /run/php/php-fpm-newpool.sock Other configurations may be needed. The above ones are the basics to create a new pool.\nChange the files ownership to the new user:\nchown -R pooluser:pooluser /path/to/code ","date":"14 July 2020","permalink":"/posts/php/php-fpm-configurations/","section":"Posts","summary":"PHP-FPM (FastCGI Process Manager) is an alternative PHP FastCGI implementation with some additional features useful for sites of any size, especially busier sites.","title":"PHP-FPM Configurations"},{"content":"","date":null,"permalink":"/tags/debian/","section":"Tags","summary":"","title":"Debian"},{"content":"Install #Instal Requirements #Passenger #Passenger will be the the application server to run Ruby on Rails app.\napt-get install -y dirmngr gnupg apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 561F9B9CAC40B2F7 apt-get install -y apt-transport-https ca-certificates sh -c \u0026#39;echo deb https://oss-binaries.phusionpassenger.com/apt/passenger buster main \u0026gt; /etc/apt/sources.list.d/passenger.list\u0026#39; apt update Packages #apt install ruby-dev mariadb-server libmariadb-dev git imagemagick ghostscript build-essential patch zlib1g-dev liblzma-dev nginx libnginx-mod-http-passenger certbot python3-certbot-nginx -y Redmine #Download Redmine from here.\nwget https://www.redmine.org/releases/redmine-4.1.1.tar.gz Check the checksum:\nsha256sum redmine-4.1.1.tar.gz Extract the tar file:\ntar -xf redmine-4.1.1.tar.gz -C /var/www Create a link for easier version management:\nln -s /var/www/redmine-4.1.1/ /var/www/redmine Configure MariaDB #Initialize MariaDB:\nmysql_secure_installation Create the database for Redmine:\nmysql -u root -p create database [REDMINEDB] character set utf8mb4; grant all on [REDMINEDB].* to [REDMINEUSER]@localhost identified by \u0026#39;S3cur3P4ssw0rd\u0026#39;; flush privileges; quit; Configure Redmine #cd /var/www/redmine/ cp config/database.yml.example config/database.yml nano config/database.yml production: adapter: mysql2 database: [REDMINEDB] host: localhost username: [REDMINEUSER] password: \u0026#34;S3cur3P4ssw0rd\u0026#34; encoding: utf8mb4 gem install bundler bundle install --without development test bundle exec rake generate_secret_token RAILS_ENV=production bundle exec rake db:migrate RAILS_ENV=production bundle exec rake redmine:load_default_data chown -R www-data:www-data /var/www/redmine/ Because of Passenger\u0026rsquo;s sandboxing system, Redmine will be running as www-data.\nVerify it later with ps:\nps aux | grep redmine ... www-data 19895 0.0 8.7 484136 173532 ? Sl Jun20 0:06 Passenger AppPreloader: /var/www/redmine (forking...) Get a certificate from Let\u0026rsquo;s Encrypt #certbot certonly --nginx -d example.com --rsa-key-size 4096 Configure Nginx #A basic Nginx config:\n# https server { listen [::]:443 ssl http2; listen 443 ssl http2; ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; root /var/www/redmine/public; server_name example.com; passenger_enabled on; passenger_ruby /usr/bin/ruby; passenger_sticky_sessions on; } # redirect http to https server { listen 80; listen [::]:80; server_name example.com; return 301 https://$host$request_uri; } Append passenger_show_version_in_header off; to the http context to hide Passenger version number.\nConfigure #SMTP #To use your own SMTP server edit configuration.yml:\nnano /var/www/redmine/config/configuration.yml email_delivery: delivery_method: :smtp smtp_settings: address: smtp.example.com port: 587 domain: example.com enable_starttls_auto: true authentication: :login user_name: redmine@example.com password: SmtpP4ssw0rd Attachment storage path #For the easier version management, store the attachments outside of the web root. I made a directory in /etc:\nmkdir -p /etc/redmine/storage chown -R www-data:www-data /etc/redmine Modify configuration.yml:\nnano /var/www/redmine/config/configuration.yml attachments_storage_path: /etc/redmine/storage ","date":"28 June 2020","permalink":"/posts/redmine/install-redmine-4/","section":"Posts","summary":"Install #Instal Requirements #Passenger #Passenger will be the the application server to run Ruby on Rails app.","title":"How to Install Redmine 4 on Debian 10"},{"content":"","date":null,"permalink":"/tags/redmine/","section":"Tags","summary":"","title":"Redmine"},{"content":"","date":null,"permalink":"/categories/ceh/","section":"Categories","summary":"","title":"Ceh"},{"content":"Cloud computing is shared pools of configurable computer system resources and higher-level services that can be rapidly provisioned with minimal management effort, often over the Internet. Third-party clouds enable organizations to focus on their core businesses instead of expending resources on computer infrastructure and maintenance. Advocates note that cloud computing allows companies to avoid or minimize up-front IT infrastructure costs. Proponents also claim that cloud computing allows enterprises to get their applications up and running faster, with improved manageability and less maintenance.\nCharacteristics of Cloud Computing # Increase users flexibility Cost reduction Device and location independence Distributed storage Automated management Virtualization Measured services Cloud Computing Service Models #Infrastructure as a Service (IaaS) #The capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can include operating systems and applications. The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, and deployed applications and possibly limited control of select networking components (e.g., host firewalls).\nPlatform as a Service (Paas) #The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services, and tools supported by the provider. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment.\nSoftware as a Service (SaaS) #The capability provided to the consumer is to use the provider’s applications running on a cloud infrastructure. The applications are accessible from various client devices through either a thin client interface, such as a web browser (e.g., web-based email), or a program interface. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration settings.\nCloud Computing Deployment Module #Private Cloud #The cloud infrastructure is provisioned for exclusive use by a single organization comprising multiple consumers (e.g., business units). It may be owned, managed, and operated by the organization, a third party, or some combination of them, and it may exist on or off premises.\nCommunity Cloud #The cloud infrastructure is provisioned for exclusive use by a specific community of consumers from organizations that have shared concerns (e.g., mission, security requirements, policy, and compliance considerations). It may be owned, managed, and operated by one or more of the organizations in the community, a third party, or some combination of them, and it may exist on or off premises.\nPublic Cloud #The cloud infrastructure is provisioned for open use by the general public. It may be owned, managed, and operated by a business, academic, or government organization, or some combination of them. It exists on the premises of the cloud provider.\nHybrid Cloud #The cloud infrastructure is a composition of two or more distinct cloud infrastructures (private, community, or public) that remain unique entities, but are bound together by standardized or proprietary technology that enables data and application portability (e.g., cloud bursting for load balancing between clouds).\nNIST Cloud Computing Reference Architecture # National Institute od Standards and Technology (NIST) presented a high-level conceptual reference architecture Identifies the major components and their functions in cloud computing Intended to facilitate the understanding of the requirements, uses, characteristics and standards of cloud computing Actors # Cloud Consumer : A person or organization that maintains a business relationship with, and uses services from cloud providers. Cloud Provider : A company or individual that delivers cloud computing based services and solutions to businesses and/or individuals. Cloud Auditor : A party that can conduct an independent assessment of cloud services. Cloud Broker : An entity that manages the use, performance and delivery of cloud services, negotiates relationships between providers and consumers. Cloud Carrier : An intermediary that provides connectivity and transport of cloud services from providers to consumers. Cloud Computing Threads # Data loss / breach Abusing cloud services Insecure interfaces / APIs Inadequate infrastructure design Virtualization level attacks Service termination and failure Malicious insider Hardware failure Weak authentication Privilege escalation Loss of logs Cloud Computing Attacks # Social engineering attacks (password guessing, \u0026hellip;) XSS attacks DNS attacks (DNS poisoning, domain hijacking, \u0026hellip;) SQL injection Network sniffing (obtain credentials, cookies, \u0026hellip;) Session hijacking (cookie stealing, \u0026hellip;) Cryptanalysis (weak encryption, \u0026hellip;) DoS / DDoS Side Channel Attacks or Cross-Guest Virtual Machine Breaches # Deploy a malicious virtual machine on the same host Take advantage of sharing resources (processor cache, keys, \u0026hellip;) Installation can be done by a malicious insider or an impersonated legitimate user Cloud Security #Application Layer # Application firewall (filter and observe traffic) Systems Development Life Cycle (SDLC) Binary Code Analysis Script analysis Transactional security Network Layer # Next Generation IPS / IDS (NGIPS / NGIDS) Firewalls DNSSec Anti-DDoS Information # Provide confidentiality and integrity Data Loss Prevention (DLP) Content Management Framework (CMF) Trusted Computing # Root of Trust (RoT) is established by validating each component of hardware and software to ensure that only trusted hardware and software can be used Computer and Storage # Host-based IPS / IDS (HIDS/HIPS) Integrity check File system monitoring Log file analysis Connection analysis Storage encryption Physical Security # Physical protection is priority Protect against theft, unauthorized physical access, environmental impact (rain, earthquake, power failure, \u0026hellip;) Responsibilities in Cloud Security #Cloud Service Provider # Web Application Firewall (WAF) Real Traffic Grabber (RTG) Firewall Data Loss Prevention (DLP) Intrusion Prevention System (IPS) Secure Web Gateway (SWG) Application Security (App Sec) Virtual Private Network (VPN) Load Balancer CoS / QoS Trusted Platform Module Netflow Cloud Service Consumer # Public Key Infrastructure (PKI) Security Development Life Cycle (SDLC) Firewall Encryption Intrusion Prevention System (IPS) Application Security Virtual Private Network (VPN) Countermeasures and Security Considerations # Software Configuration Management (SCM) Disaster Recovery Plan Load Balancing Data Integrity Patching and updates SSL Cryptography implementation Reliability Quality of Service (QoS) Monitoring Service Level Agreement (SLA) ","date":"1 February 2020","permalink":"/posts/ceh/cloud-computing/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 19: Cloud Computing","title":"CEH v10: 19 Cloud Computing"},{"content":"","date":null,"permalink":"/tags/cehv10/","section":"Tags","summary":"","title":"Cehv10"},{"content":"Study material for CEHv10.\nUPDATE #Because of the high traffic, i decided to reformat the chapters and upload everything to my blog at danielgorbe.com/en/tags/ceh/ to be more readable.\nBut I need YOUR help!\nIf you have anything to append to the chapters, please do a pull request, open an issue or contact me. Every help is warmly welcome!\nExamples #I try to include examples to the chapters.\nThese examples are for Linux users only!\nYou can always run those examples on danielgorbe.com, but please, dont be a d*ckhead!\nStudy material for CEHv10 #CEHv9 Notes #https://docs.google.com/document/d/1YvAOM1o6qkgFEdzJpn01rLRBGV8JPfK4cHvfgRiAgEM/edit\nhttps://arc.bukancoder.co/Certified-Ethical-Hacker-Module-V9/\nhttps://github.com/yeahhub/cehv9\nhttps://github.com/Brute-f0rce/CEH\nExercise #https://yeahhub.com/cehv9-practice-exam-questions/chapter0-assessment.php\nhttps://www.skillset.com/\nhttps://ceh.cagy.org/\nTODO # Complete chapter 1,2,11,12 Sources #The base and the structure provided by IPSpecialst\u0026rsquo;s CEH v10 book (It\u0026rsquo;s worth to buy and read it!)\nThe details is got from DuckDuckGo\nSource code #These chapters source code can be found on GitHub\n","date":"1 February 2020","permalink":"/posts/ceh/readme/","section":"Posts","summary":"Certified Ethical Hacker v10 learning material. Chapter 00: Readme.","title":"CEH v10: 00 Readme"},{"content":"Essential Terminologies\nHack Value: A notion among hackers that something is worth doing or is interesting.\nVulnerability: Existence of a weakness, design, or implementation error that can lead to an unexpected event compromising the security of the system.\nExploit: A breach of IT system security through vulnerabilities.\nPayload: Payload is the part of an exploit code that performs the intended malicious action, such as destroying, creating backdoors, and hijacking computer.\nZero-Day Attack: An attack that exploits computer application vulnerabilities before the software developer releases a patch for the vulnerability.\nDaisy Chaining: It involves gaining access to one network and/or computer and then using the same information to gain access to multiple networks and computers that contain desirable information.\nDoxing: Publishing personally identifiable information about an individual collected from publicly available databases and social media.\nBot: A \u0026ldquo;bot\u0026rdquo; is a software application that can be controlled remotely to execute or automate predefined tasks.\nInformation Security #The information security is a state of well-being of information and infrastructure in which the possibility of theft, tampering , and disruption of information and services is kept low or tolerable.\nElements of Information Security #CIA triad #Confidentiality: Assurance that the information is accessible only to those authorized to have access.\nIntegrity: The trustworthiness of data or resource in terms of preventing improper and unauthorized changes.\nAvailability: Assurance that the systems responsible for delivering, storing, and processing information are accessible when required by the authorized users.\nOther #Authenticity: Authenticity refers to the characteristic of a communication, document or any data that ensures the quality of being genuine.\nNon-Repudiation: Guarantee that the sender of a message cannot later deny having sent the message and that the recipient cannot deny having received the message.\nThe Security, Functionality, and Usability triangle #Security: Restrictions imposed on accessing the components of the system (restrictions).\nFunctionality: The set of features provided by the system (features).\nUsability: The GUI components used to design the system for ease of use (GUI).\nInformation Security Attacks and Attack Vectors #Attacks = Motive (Goal) + Method + Vulnerability\nA motive originates out of the notion that the target system stores or process something valuable and this leads to threat of an attack on the system\nAttackers try various tools and attacks techniques to exploit vulnerabilities in a computer system or security policy and controls to achieve their motives\nMotives behind attacks: # Disrupting business continuity Information theft and manipulating data Creating fear and chaos by disrupting critical infrastructures Financial loss to the target Propagating religious or political beliefs Achieving state\u0026rsquo;s military objectives Demanding reputation of the target Taking revenge Demanding ransom Top InfoSec Threats # Cloud Computing Threat Advanced Persistent Threats (APT): stealing information from the victim machine without the user being aware of it Viruses and Worms Ransomware Mobile Threats Top InfoSec vectors: # Botnet Insider Attack Phishing Web Application Threat IoT Threats InfoSec Threats categories: # Network Threats (spoofing, sniffing, \u0026hellip;) Host Threats (malware, dos, \u0026hellip;) Application Threats (auth attacks, SQL injection, \u0026hellip;) Type of Attacks on a System: # Operating System Attacks (OS vulnerabilities) Misconfiguration Attacks Application-Level Attacks (exploit the application) Shrink-Wrap Code Attacks (exploit the common vulnerable libraries) ICT : Information and Communication Technologies\n","date":"1 February 2020","permalink":"/posts/ceh/introduction/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 01: Introduction","title":"CEH v10: 01 Introduction"},{"content":"Collect information about a target network.\nTerminology #Footprinting: collect information about a target network.\nPassive Footprinting: collect without direct interaction.\nActive Footprinting: collect with direct interaction.\nSocial Network Footprinting: get information about the target.\nWebsite Footprinting: Information about the target through web pages.\nMethods # Examining the web page\u0026rsquo;s source code Examining cookies Extracting metadata of web sites Monitoring website for updates Tracking email Email header analysis Competitive Intelligence Gathering Monitoring website traffic Tracking online reputation WHOIS IP geolocation DNS footprinting Information collected # Organization Information (phone numbers, employee details, etc\u0026hellip;) Relations with other companies Network Information (Domains, IPs, etc\u0026hellip;) System Information (OSes, passwords) Objectives of Footprinting: # Know Security Posture: know the security posture of the target organization Reduce Focus Area: reduce the attackers focus area to a specific range of IP, network, domain names, etc\u0026hellip; Identify Vulnerabilities: identify vulnerabilities in the target system Draw Network Map: draw a map or outline the target organization\u0026rsquo;s network infrastructure Advanced Google Hacking Techniques #Operators:\ncache: - Display the web page stored in the google cache link: - List of web pages that have links to the specified web page related: - List of web pages that are similar to a specified web page info: - Presents some information that google has about the particular page site: - Restrict the results to those websites in the given domain allintitle: - Restricts the result to those websites with all of the search keywords in the title intitle: - Restrict the results to documents containing the search keyword in the title allinurl: - Restrict the results to those with all of the search keywords in the URL inurl: - Restrict the results to documents containing the search keyword in the URL location: - Find information for a specific location intext: - Restrict the results to documents containing the search keyword in the content Find more at ahrefs blog.\nWHOIS #Whois databases are maintained by Regional Internet Registries and contain personal information of domain owner (eg.: email address).\nwhois uses TCP port 43.\nExample on Linux:\nwhois danielgorbe.com DNS footprinting #DNS record types:\nA: Points to a host\u0026rsquo;s IP address MX: Points to a domain\u0026rsquo;s mail server NS: Points to a host\u0026rsquo;s name server CNAME: Canonical naming allows aliases to a host SOA: Indicate authority for domain SRV: Service records PTR: Maps IP address to a hostname RP: Responsible person HINFO: Host information record includes CPU type and OS TXT: Unstructured text records Example on Linux:\ndig danielgorbe.com Traceroute #Trace the path between you and your target computer.\nExample on Linux:\ntraceroute danielgorbe.com ","date":"1 February 2020","permalink":"/posts/ceh/footprinting/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 02: Footprinting","title":"CEH v10: 02 Footprinting"},{"content":"Protocols #These definitions is must-know !\nTCP (Transmission Control Protocol) UDP (User Datagram Protocol) ARP ICMP Ping Sweep: mass ICMP echo (ping) message SSDP DHCP DNS UPnP TCP Flags # SYN: Initiates a connection between two hosts to facilitate communication ACK: Acknowledge the receipt of a packet URG: Indicates that the data contained in the packet is urgent and should process it immediately PSH: Instructs the sending system to send all buffered data immediately FIN: Tells te remote system about the end of the communication. In essence, this gracefully closes the connection RST: Reset a connection Three-way handshake # Establish a TCP connection sequenceDiagram Computer1-\u0026gt;\u0026gt;Computer2: SYN Computer2-\u0026gt;\u0026gt;Computer1: SYN+ACK Computer1-\u0026gt;\u0026gt;Computer2: ACK OSI Model # Layer Name Example protocols 7 Application layer HTTP, SNMP 6 Presentation layer MIME, ASCII 5 Session layer SOCKS, NetBIOS 4 Transport layer TCP, UDP 3 Network layer IP, ICMP 2 Data link layer MAC, ARP 1 Physical layer ethernet, Wi-Fi TCP/IP Model # Layer Name Example protocols 4 Application layer HTTP, SNMP 3 Transport layer TCP, UDP 2 Internet layer IP, ICMP 1 Link layer ARP, MAC Scanning Techniques #TCP Connect() / Full Open Scan # Three-way handshake Completed connection Logged and detected Don\u0026rsquo;t need ROOT nmap: -sT Open port:\nsequenceDiagram Attacker-\u0026gt;\u0026gt;Target: SYN Target-\u0026gt;\u0026gt;Attacker: SYN+ACK Attacker-\u0026gt;\u0026gt;Target: ACK Target-\u0026gt;\u0026gt;Attacker: RST Closed port:\nsequenceDiagram Attacker-\u0026gt;\u0026gt;Target: SYN Target-\u0026gt;\u0026gt;Attacker: RST Example:\nnmap -sT danielgorbe.com Stealth Scan / Half-Open Scan # Half Three-way Handshake Nmap: -sS Open Port:\nsequenceDiagram participant Attacker participant Target Attacker-\u0026gt;\u0026gt;Target: SYN Target-\u0026gt;\u0026gt;Attacker: SYN+ACK Attacker-\u0026gt;\u0026gt;Target: RST Closed port:\nsequenceDiagram Attacker-\u0026gt;\u0026gt;Target: SYN Target-\u0026gt;\u0026gt;Attacker: RST Example:\nnmap -sS danielgorbe.com Inverse TCP Flag Scanning # Send TCP probe with TCP flags (i.e. FIN, URG, PSH, without flag) Xmas and Null scan Xmas Scan # PSH+URG+FIN flag or ALL flag Create abnormal situation Nmap: -sX Open port:\nsequenceDiagram participant Attacker participant Target Attacker-\u0026gt;\u0026gt;Target: FIN+URG+PSH Target-\u0026gt;\u0026gt;Attacker: No Response Closed port:\nsequenceDiagram participant Attacker participant Target Attacker-\u0026gt;\u0026gt;Target: FIN+URG+PSH Target-\u0026gt;\u0026gt;Attacker: RST Example:\nnmap -sX danielgorbe.com NULL Scan # No flag Easy to detect Nmap: -sN Open port:\nsequenceDiagram participant Attacker participant Target Attacker-\u0026gt;\u0026gt;Target: NULL Target-\u0026gt;\u0026gt;Attacker: No Response Closed port:\nsequenceDiagram participant Attacker participant Target Attacker-\u0026gt;\u0026gt;Target: NULL Target-\u0026gt;\u0026gt;Attacker: RST Example:\nnmap -sT danielgorbe.com FIN Scan # FIN scan work with RFC-793 based TCP/IP (before Win XP) Only FIN flag Probably pass firewalls Nmap: -sF Open port:\nsequenceDiagram participant Attacker participant Target Attacker-\u0026gt;\u0026gt;Target: FIN Target-\u0026gt;\u0026gt;Attacker: No Response Closed port:\nsequenceDiagram participant Attacker participant Target Attacker-\u0026gt;\u0026gt;Target: FIN Target-\u0026gt;\u0026gt;Attacker: RST Example:\nnmap -sF danielgorbe.com ACK Flag probe scanning # Only ACK flag The response is always an RST Examine the RST header (i.e. TTL, WINDOW), the decide if port open or not Help identify filtering system: RST mean no firewall, No response mean there is a firewall Nmap: -sA Example:\nnmap -sA danielgorbe.com IDLE / IPID Header scan # Remaining low profile Scanning done by a zombie Based on Full Open scan The unsolicited SYN+ACK packet is ignored or responded with RST Every IP packet has Fragment Identification Number (IPID) OS increment IPID for each packet Nmap: -sI \u0026lt;zombie host[:probeport]\u0026gt; Explanation on Nmap\u0026rsquo;s website UDP Scan # Connectionless protocol nmap: -sU Open port:\nsequenceDiagram participant Attacker participant Target Attacker-\u0026gt;\u0026gt;Target: UDP Port Probe Target-\u0026gt;\u0026gt;Attacker: No Response Closed port:\nsequenceDiagram participant Attacker participant Target Attacker-\u0026gt;\u0026gt;Target: UDP Port Probe Target-\u0026gt;\u0026gt;Attacker: ICMP Port Unreachable Example:\nnmap -sA danielgorbe.com IDS / IPS evasion # Packet fragmentation: Nmap: -f The IDS have to reassemble the packets to detect an attack Sending packet with delay Example:\nnmap -f danielgorbe.com OS Fingerprinting #Active OS fingerprinting # Nmap: -O Send TCP and UDP packets and observe the response from the host Example:\nnmap -O danielgorbe.com Passive OS fingerprinting # Detail assessment of the traffic (TTL, TCP Window Size) Common values: OS TTL TCP Window Size Linux 64 5840 Windows XP 128 65535 Windows 2008 128 8192 FreeBSD 64 5840 More values here Banner Grabbing # Determine the service Typically uses Telnet Example:\nnmap -sV danielgorbe.com Proxy # System between the attacker and the target Hiding source IP address Impersonating Hide identity Proxy chaining # Using multiple proxy server Most used proxy chains: Tor Spoofing IP address # Modify packet header nmap has a decoy scan option, this option send packets with spoofed source IP to cloak the your address. Example:\nnmap -D 192.168.1.1,192.168.1.2 danielgorbe.com This option sends 3 packets with source IP:\n192.168.1.1 192.168.1.2 Your IP Detect Spoofing # Direct TTL probe (on same subnet) IP Identification Number ","date":"1 February 2020","permalink":"/posts/ceh/scanning-networks/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 03: Scanning Networks","title":"CEH v10: 03 Scanning Networks"},{"content":"Enumeration is the process of extracting user names, machine names, network resources, shares and services from a system.\nNOTE: This may cross legal boundaries, you must have proper permission to perform these actions.\nBasic # initiates active connection with the target\ndirect queries are generated\nenumerated information:\nrouting information SNMP information DNS information machine name user information group information application and banners network sharing information network resources Email # Extract useful information (username, domain, ..) Default password # sometimes the default credentials didn\u0026rsquo;t changed Active Directory (AD) # Centralized command and control of domain users, computers, printers Brute force or generating queries to LDAP Ports: TCP / UDP 389 Information from LDAP: Username Address Credentials Privileges information Lightweight Directory Access Protocol (LDAP) # Accessing and maintaining distributed directory information services in a hierarchical and logical structure Allowing the sharing of information like user, system, network services, etc. throughout the network Provides a central place to store usernames and passwords Apps and services connect to LDAP to validate users Client initiates an LDAP session bt sending an operation request to Directory System Agent (DSA) Communication between client and server uses Basic Encoding Rules (BER) Port: TCP 389 Directory services using LDAP: Active Directory Open Directory Oracle iPlanet OpenLDAP Simple Network Management Protocol (SNMP) # Allow management of devices (routers, servers, \u0026hellip;) Manage network performance Find, troubleshoot, solve problems Design, plan for network growth Application layer protocol Ports: UDP 161 UDP 162 (Trap) Three element: -SNMP manager: - A software running on the management station - Display collected information SNMP agent: A software running on the network nodes Different components are monitored (CPU, RAM, \u0026hellip;) Management Information Base (MIB): A collection of information organized hierarchically in a virtual database 2 types: Scaler: single object instance Tabular: multiple related object instance Use default community strings or guess to extract information Community strings: Used for authentication Types: read-only (read only information from a device) read-write (read information, modify settings) trap SNMP Trap: Initiated by the SNMP agent Report an issue Information from SNMP: Host Devices Shares Network information Versions: v1: No support for encryption and hashing Plain text community string v2: No support for encryption and hashing Some function added (i.e. get data in bulk from agents) v3: Support encryption (DES) Support hashing (MD5 or SHA) 3 model: NoAuthNoPriv: no encrypt and no hashing AuthNoPriv: no encrypt, just hashing AuthPriv: encryption + hashing used DNS Zone Transfer # Zone transfer is a process to update DNS server, copy containing database record to another DNS server Ports: UDP 53 (DNS queries) TCP 53 (DNS Zone Transfer) Information from DNS zone transfer process: Locating DNS server DNS records Hostname IP address Username Tool: Linux: nslookup, dig, host Example:\nhost -t axfr zonetransfer.me nsztm1.digi.ninja. Network Basic Input/Output System (NetBIOS) # Allows communication between different application on different system within LAN Uses a 16 ASCII Character string to identify devices The initial 15 chars is identifying the device, the last char identify the service Session layer protocol Ports: UDP 137 (name services) UDP 138 (datagram services) TCP 139 (session services) Information from NetBIOS: List of machines within a domain File sharing Printer sharing Username Group information Password Policies NetBIOS names are classified into the following types: Unique Group Domain name Internet group Multihomed Tools: -Windows: nbtstat -Linux: nbtscan Network Time Protocol (NTP) # Synchronize the clocks across the hosts and network devices A lot of services rely on clock settings (logging, login, \u0026hellip;) Application layer protocol Port: UDP 123 Based on UTC Stratum: Distance between NTP server and device Like TTL Start from 1 and increases by every hop Attacker may change time to mislead forensic team, who investigate the events (change timestamp) Version 3 and above: Support a cryptographic authentication technique between NTP peers Without authentication, the client do not authenticate the server as a secure source, if the legitimate server goes down, a fake NTP server can replace the real Information from NTP: Host information Client information (IP, machine name, OS) Network information Tool: Linux: ntpdc, ntptrace, ntpq, nmap, wireshark Simple Mail Transfer Protocol (SMTP) # Ensures mail communication between Email servers Application layer protocol Port: TCP 25 (Unencrypted) TCP 587 (TLS) Enumeration with Telnet Commands: HELO: identify domain name of the sender EXPN: verify Mailbox on localhost MAIL FROM: identify sender of the email RCPT TO specify the message recipients SIZE: specify maximum supported size DATA: define data RSET: reset connection and buffer of SMTP VRFY: verify the availability of Mail server HELP: show help QUIT: terminate session Countermeasures # Advanced security softwares Updated version of protocols Strong security protocols Unique and difficult password Strong encrypted communications Disable unnecessary ports ","date":"1 February 2020","permalink":"/posts/ceh/enumeration/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 04: Enumeration","title":"CEH v10: 04 Enumeration"},{"content":"Vulnerability Assessment is a process of examination, discovery, and identification of a system and applications security measures and weakness. It helps to recognize the vulnerabilities that could be exploited, need of additional security layers, and information that can be revealed using scanners.\nTypes of Vulnerability Assessment # Active Assessments : actively sending requests to the live network and examining the the responses. It requires probing the target host. Passive Assessments : includes packet sniffing to discover vulnerabilities, running services, open ports, and others. It is a process without interfering the target host. External Assessment : find out vulnerabilities and exploit them from outside. Internal Assessment : find and exploit vulnerabilities in the internal network. Vulnerability Assessment Life-Cycle #Creating baseline # Identifies the nature of the network, the applications, and services. Creates an inventory of all resources and assets which helps to manage, prioritize the assessment. Helps to maps the infrastructure, learns about security controls, policies, and standards. Helps to plan the process effectively. Vulnerability Assessment # Includes examination and inspection of security measures (physical security, security policies and controls, \u0026hellip;). The target is evaluated for misconfigurations, default configurations, faults, and other vulnerabilities. Probing each component individually or using assessment tools. The report shows the vulnerabilities, their scope, and priorities. Risk Assessment # Scoping the identified vulnerabilities and their impact on the infrastructure Remediation # Remedial actions for the detected vulnerabilities Start with the highest priority Verification # Make sure that all vulnerabilities are eliminated Monitor # Monitor the network traffic and system behaviors for any further intrusion Vulnerability Assessment Solutions #Product based solution vs Service based solution # Product based solutions are deployed within the network. Usually dedicated for internal network. Service based solutions are third-party solutions which offers security and auditing. This can be host either inside or outside the network. This can be a security risk of being compromised. Tree-based Assessment vs Inference-based Assessment # Tree-based Assessment is the approach in which auditor follows different strategies for each component of an environment Inference-based Assessment is the approach to assist depending on the inventory of protocols in an environment Best Practice # Know your tool, know everything about it Make sure to not cause any damage with the tool Make sure the source location of scan to reduce the focus area Run scan frequently Vulnerability Scoring System #Common Vulnerability Scoring System (CVSS) # None: 0.0 Low: 0.1 - 3.9 Medium: 4.0 - 6.9 High: 7.0 - 8.9 Critical: 9.0 - 10.0 Common Vulnerabilities and Exposures (CVE) #Another platform to find information about vulnerabilities\nDatabases:\nhttps://nvd.nist.gov/ https://cve.mitre.org/ Vulnerability Scanning #Vulnerability Scanners are automated utilities to detect vulnerabilities. These scanning tools perform deep inspection of scripts, open ports, banners, running services, configuration errors, etc\u0026hellip;\nTop scanners:\nNessus OpenVAS Owasp-ZED Vega Nexpose Retina GFI LanGuard ","date":"1 February 2020","permalink":"/posts/ceh/vulnerability-analysis/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 05: Vulnerability Analysis","title":"CEH v10: 05 Vulnerability Analysis"},{"content":"Methodology # Cracking Password Escalating Privileges Executing Applications Hiding Files Covering Tracks Goals # Bypass the access control Gain access to the system Exploit vulnerabilities Gain privileges Execute applications Hide malicious activities Hide the evidence of compromising Password Cracking #Three type of authentication factors:\nSomething i have : username, password, \u0026hellip; Something i am : biometrics, \u0026hellip; Something i possess : allowed / registered devices, \u0026hellip; Password Cracking is the method for extracting the password to gain authorized access to the target system in the guise of a legitimate user. Usually, only the username and password authentication are configured, but now password authentication is moving toward two-factor authentication or multiple-factor authentication.\nA good password contain:\nCase sensitive letters Special characters Numbers Lengthy password (more than 8 character) Types of Password Attacks #Non-Electronic Attacks #Don\u0026rsquo;t require any type of technical understanding and knowledge.\nExample:\nShoulder surfing Social Engineering Dumpster Diving Active Online Attack #Directly interact with the target for cracking password.\nDictionary Attack #A password cracking application is used along with with a dictionary file. This dictionary file contains entire dictionary or a list of known and common words. This is the most common type of password cracking. Systems are not vulnerable if they use a strong, unique alphanumeric password.\nBrute Force Attack #Attempt to recover the password by trying every possible combination of characters until password is accepted. Common and basic technique.\nHash Injection #Compromising a workstation by exploiting the vulnerability, and extract the log-on hashes. Hashing and other cryptography knowledge require.\nPassive Online Attacks #Password Attack without probing the target.\nWire Sniffing #Sniffing the packets with a packet sniffing tool within the Local Area Network (LAN), and inspecting the captured packets.\nMan-in-the-Middle (MITM) Attack #The attacker involves himself into the communication, insert himself in.\nMITM Attacks:\nSSL Strip Burp Suite Browser Exploitation Framework (BeEF) Replay Attack : Capture the packets and extract information such as password from it. Then generating a replay traffic with the injection of extracted information to gain access to the system.\nDefault Password #Gain access to the system by using the preconfigured password. The default password can be find on the manufacturer site or through online tools.\nOffline Attack #Pre-computed hashes and Rainbow table #Comparing a password using a rainbow table. Rainbow Table is the pregenerated hashes of the words in a dictionary or the combination of characters. The advantage of Rainbow Table is the speed, because it takes less time to compare the hashes. The disadvantage is the time and storage, it takes much more time and storage to compute and store the hashes.\nDistributed Network Attack (DNA) #Using the unused processing power of machines across the network to decrypt the hashes. DNA requires a DNA manager and DNS Clients. DNA Manager allocate small tasks over the distributed network to be computed in the background.\nPassword Guessing #The attacker uses the information extracted by initial phases and guess the password. Not common method and the rate of failure is high.\nUSB Drive #Attacker plug in an USB Drive that contain a password hacking tool. Windows Autorun feature allows running the application automatically, if enabled.\nMicrosoft Authentication #Authentication is a verification process to identify any user or device.\nMicrosoft authentication protocols:\nKerberos Security Account Manager (SAM) NT LAN Manager (NTLM) LM Security Account Manager (SAM) #SAM is database that stores credentials and other account parameters such as passwords for the authentication process in Windows. While the OS running, this database os locked to be accessed by any other service and process. There are several other security algorithms are applied to the database to secure and validate the integrity of data. Within Microsoft, SAM stores password in LM/NTLM hashing format. Windows XP and later versions do not store the value of LM hash, or when LM hash is exceeding 14 characters, it stores blank or dummy value instead.\nFormat :\nUsername: user ID: LM hash: NTLM hash::: Location:\nC:\\windows\\system32\\config\\SAM NTLM Authentication #NT Lan Manager is a proprietary authentication protocol by Microsoft. In the authentication process, user sends login credentials to a domain controller in hashed format. Domain controller responds to a challenge known as nonce to be encrypted by the password\u0026rsquo;s hash. This challenge is a 16 byte random number generated ny the domain controller. By comparing the challenge with the database, domain controller permit or deny the login. Microsoft upgraded its default authentication mechanism from NTLM to Kerberos.\nNTLM has two version:\nNTLMv1 (Older) NTLMv2 (Improved) For additional security layer, NTLM is combined with Security Support Provider.\nKerberos #Kerberos is an advanced authentication protocol. Clients receive tickets from Kerberos Key Distributor Center (KDC)\nKDC depend upon two components:\nAuthentication Server (AS) Ticket-Granting Server (TGS) The client send a request to the AS to grant Tick-granting-ticket. The AS authenticates the client by comparing the user identity and password from its datbase and reply with Tick-Granting Ticket and a session key. The session key is for a session between client and TGS. Now, client can communicate with the Ticket-Granting Server (TGS). The client send TGT to TGS, ask for communication with another user. TGS reply with a Ticket and session key. Ticket and Session key is for communicating with other user within a trusted domain.\nPassword salting #Password salting is the process of adding additional character in the password to one-way function. This makes the password more difficult to reverse the hash. The function os salting is to defeat the Dictionary Attacks and Rainbow Table attacks\nPassword file by Operating Systems # Windows: SAM (C:\\windows\\system32\\config\\SAM) Linux: Shadow (/etc/shadow) Domain Controller: NTDS:DIT Password Cracking tools # pwdump7 fgdump RainbowCrack Cain and Abel John The Ripper Pyrit Hashcat Password Cracking Countermeasures # Change default password Do not store/save passwords in applications Do not use guessable passwords Set strong password Password encryption Keep credentials secure and secret Enable SYSKEY Password salting Advance security audits Periodically update passwords Monitor attacks Different password for each service Configure policies for incorrect password attempts Escalating Privileges #The main goal is to get a high-level access to the system.\nHorizontal Privileges Escalation #The attacker attempts to gain access to user that has same set of privileges.\nVertical Privileges Escalation #The attacker attempts to escalate privileges to a higher level. Vertical privileges occurs when attacker is trying to gain access to the Administrator account. Higher privileges allow attacker to access sensitive information, modify files and execute programs.\nPrivilege Escalation using DLL Hijacking #Applications need Dynamic Link Libraries (DLL) to run. In Windows, most of the application search for DLL in directories, instead of using the full qualified path. The Attacker replace the DLL to a malicious one.\nDLL Hijacking tool: Metasploit\nKnown DLLs are specified in the registry key:\nHKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Session Manager\\ Search paths used by Microsoft:\nDirectory of application or current directory System directory (i.e. C:\\Windows\\System32) Windows directory Executing Applications #The Attacker\u0026rsquo;s next step is to execute malicious applications. This execution is for gaining access to system resources, crack passwords, set up backdoors and many more. This process is called as \u0026ldquo;System Owning\u0026rdquo;.\nGoals:\nInstall malware to collect information Setup Backdoor to maintain access crack passwords and scripts Install Keylogger etc\u0026hellip; RemoteExec #RemoteExec is software designed for installation of application, execution of code and scripts remotely. RemoteExec can upload file across the network.\nFeatures:\nDeploy packages Remotely execution of programs Scheduling execution Remote configuration (settings, files, \u0026hellip;) Remote controlling (turn off, lock, \u0026hellip;) PDQ Deploy #PDQ Deploy is a software for system administrators to install and send updates silently to the remote systems. It can silently deploy almost every application (.exe, .msi, \u0026hellip;). It can install, uninstall, copy, execute and send files.\nKeyloggers #Keystroke logging, keylogging and keyboard capturing is a process of monitoring and/or recording the actions by any user. Logging the actions to steal information from the target machine.\nGoals:\nCapture the pushed buttons Take screenshots Capture mouse Many more\u0026hellip; Software Keyloggers #Software-based keyloggers are remotely installed, or send it to the target to execute the application.\nTypes:\nApplication keyloggers Kernel keyloggers Hypervisor-based keyloggers Form Grabbing based keyloggers Hardware Keyloggers #It is a physical hardware which are installed on hardware by physically accessing the device.\nTypes:\nPC/BIOS Embedded keyloggers Keylogger keyboard External keylogger (video, bluetooth, wi-fi, acoustic, \u0026hellip;) Anti-Keyloggers #Anti-Keylogger is an application which ensures protection against keylogging by providing SSl protection, keylogging protection, clipboard logging protection and screen logging protection.\nAnti-Kelogger softwares:\nZemana Spyshelter Anti-keylogger Anti-Keylogger Key-logging Countermeasures # Keystroke interference software Don\u0026rsquo;t click on doubtful URLs Anti-Keylogger software On-Screen keyboard for secrets Physical monitoring Host-based IDS File scanning prior to installation Spyware #Spywares are the software designed for gathering user interaction information with a system such as login credentials, emails and many more without informing the user of the system. The gathered information is sent to a remote destination. Spyware hides its files and processes to avoid detection.\nTypes:\nAdware System monitors Tracking cookies Trojans Features:\nTracking users (i.e. keylogging) Monitor user\u0026rsquo;s activity Blocking services Remote delivery of logs Email tracking Record removable media communication (i.e. USB) Voice recording Video recording Tracking location (GPS) Mobile tracking Rootkits #Rootkit is a software designed to provide privileged access to a remote user over a system, creates a backdoor. Deployed after attacker gain high-level access to a system. Rootkits often mask their existence to avoid detection.\nTypes # Application level rootkit: perform manipulation of standard application file with an injection of codes. Kernel-level rootkit: inject malicious code to the kernel Hardware/Firmware level rootkit: built into a chipset Hypervisor level rootkit: exploits hardware features like AMD-V or Intel VT Boot Loader level rootkits (Bootkits): replace the legitimate boot loader with the malicious one, which enables the bootkit to activated before an OS run. It can attack Master Boot Record (MBR), Volume Boot Record (VBR) or boot sector. It can be used to attack full disk encryption systems, hack encryption keys and passwords. Tool # Avatar Necurs Azazel ZeroAccess Detecting and Defending Rootkits # Integrity-Based Detection Digital signatures Difference-based detection Behavior-based detection Cross-view based detection Run-time execution path profiling Anti-rootkit software Deploying a network-based firewall Host-based firewall Install application/OS from trusted sources Integrity verification Kernel memory dump analysis Unix tools:\nZeppo chrootkit Windows tools:\nMicrosoft Sysinternals Rootkit Revealer Sophos Anti-Rootkit New Technology File System (NTFS) Data Stream #NTFS is a Windows file system by Microsoft. NTFS is the default file system for Windows 10,- 7,- Vista,- XP,- 2000,- NT.\nAlternate Data Stream (ADS) #ADS is a file attribute in in NTFS file system, contains metadata for locating a particular file. ADS is capable of hiding file data into an existing file without altering or modifying any noticeable changes. It can be security threat because it can hide malicious files.\nNTFS Streams Countermeasures:\nMoving file to a FAT partition (FAT doesn\u0026rsquo;t support ADS, but this will corrupt the file) Third-party tools (ADS Spy, ADS Tools, LADS, \u0026hellip;) Steganography #Steganography is a technique for hiding sensitive information in an ordinary message to ensure the confidentiality. Steganography uses encryption to maintain the confidentiality and integrity. It hides the encrypted data to avoid detection. An attacker may use this to technique to transfer data without being detected.\nClassification of Steganography # Technical Steganography includes concealing information using methods like using invisible link, microdots. Linguistic Steganography uses text as covering media to hide information like using ciphers and code to hide information. Types of Steganography # Whitespace Steganography Image/Pixel Steganography Document Steganography Video Steganography Audio Steganography File/Folder Steganography Spam/Email Steganography Web Steganography Frequency Steganography Least Significant Bit Steganography Whitespace Steganography #hide information in a text file using extra blank space inserted in between words covering file. Using LZW and Huffman compression method to decrease the size of the message.\nImage Steganography #Hidden information can be kept in image formats, such as PNG, JPG, others. Image steganography places redundant bits of the image in the message. It cannot be detected by human eye.\nTechniques:\nLeast significant bit insertion Masking and filtering Algorithm and transformations Tools:\nOpenStego QuickStego Stegohide (Linux) Steganalysis #Analysis of suspected information using steganography techniques to discover nad retrieve the hidden information.\nMethods:\nStego-only: have only stego object Known stego: have stego object, algorithm and cover Known message: have stego object and hidden message Known cover: have stego object and cover Chosen message: generate stego form known message to identify the algorithm Chosen stego: have stego object and algorithm Covering tracks #After gaining access, escalating privileges, executing applications, the next step is to wipe the evidence. In this phase, attacker removes all the event logs, error messages and other evidence to prevent its attack from being discovered easily.\nCommon techniques:\nDisable auditing Clearing logs Manipulating logs Disable auditing #Preventing another security mechanism to indicate an alert any sort of intrusion, and leaving to track leaving to track on the machine. The best practice for leaving no track and prevent detection is by disabling the auditing as you logged in on the system. It will not only prevent to log events, but also resist in the detection. Auditing in a system is enabled to detect and track events.\nList auditing categories in windows:\nC:\\Windows\\system32\u0026gt;auditpol /list /category /v Check all category audit policies:\nC:\\Windows\\system32\u0026gt;auditpol /get /category:* Clearing logs #By clearing logs, all events logged during the compromise will be erased.\nFolder of log files:\nWindows 2000/Server2003/Windows XP:\n%SystemRoot%\\System32\\Config Server 2008/Vista and up:\n%SystemRoot%\\system32\\winevt\\logs Linux, OpenBSD:\n/var/log/ Other methods # Clear cookies Clear cache Clear temporary files CCleaner Clear Most Recent Used (MRU) ","date":"1 February 2020","permalink":"/posts/ceh/system-hacking/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 06: System Hacking","title":"CEH v10: 06 System Hacking"},{"content":"Basic #Malware (Malicious Software) defines a wide variety of potentially harmful software.\nMalware propagation ways # Free software (crack files, \u0026hellip;) File sharing services: during the transfer, the file can be infected (torrent, \u0026hellip;) Removable media (firmware embedded malware, \u0026hellip;) Email (attachment, \u0026hellip;) Not using firewall or anti-virus Trojan #Misleads from its true intention and wait for the best time to attack. Typically spread by social engineering.\nMost common use:\nCreate back door Gaining unauthorized access Steal information Infect connected devices Ransomware attacks Using victim as botnet Download other malicious software Disable security Trojan infection process # Creating trojan Create a dropper Create a wrapper Propagate the trojan Execute dropper Trojan Construction Kit allow attacker to create their own trojan. Trojans created by using construction kits can avoid detection from virus and trojan scanning.\nTrojan construction kits:\nDark Horse trojan virus maker Senna Spy Generator Trojan Horse Construction Kit Progenic mail Trojan Construction Kit Pandora\u0026rsquo;s Box Droppers #Dropper is a program that is designed to deliver a payload on the target machine, install the malware without being detected.\nTools:\nWin32/Rotbrow.A Win32/Swisyn Win32/Meredrop Troj/Destover-C Wrappers #Wrapper binds malicious file in order to create and propagate the trojan along with it to avoid detection. Wrappers often popular executable files, like games, music, etc.\nCrypter #The basic purpose is to encrypt, obfuscate and manipulate the malware. By using crypter, it becomes more difficult to detect. Crypter is used while creating the trojan.\nTools:\nCryogenic Crypter Heaven Crypter Swayz Cryptor Deployment of trojan #An attacker is upload the trojan on a server, where it can be downloaded immediately when the victim clicks on the link\nTypes of trojans #Command Shell Trojans # Command Shell Trojans provide a remote control of command shell (i.e. open a port for Netcat) Defacement Trojans # Defacement Trojans allow attacker to view, edit and extract information, for example User-Styled Custom Application HTTP/HTTPS Trojans # HTTP/HTTPS Trojans create a http/https tunnel to communicate Botnet trojans # Botnet is a large scale of compromised system, they spread over the world Botnets controlled by Command and Control Center Used to launch distributed attacks, like DDoS, spamming Proxy Server Trojans # Proxy Server Trojans turns the compromised system into a proxy server Attacker use this to hide the actual source of the attack Remote Access Trojans (RAT) # RAT allows the attacker to get remote desktop access to the victim\u0026rsquo;s computer RAT includes a back door to maintain the access and control over the victim Attacker can monitor user, access information, alter files, etc\u0026hellip; Tools # SSH-R.A.T. BlackHole RAT Pandora RAT Other Types of Trojans # FTP Trojans VNC Trojans Mobile Trojans ICMP Trojans Covert Channel Trojans Notification Trojans Data Hiding Trojans Trojan Countermeasures # Avoid to click on suspected email attachments Block unused ports Monitor network traffic Avoid download from untrusted sources Install / update security softwares and anti-viruses Scan removable media before use File integrity Enable auditing Configure host-based firewall Intrusion detection software Detection Techniques for Trojans # Scanning for suspicious network activities Scanning for suspicious ports Scanning for suspicious registry entries Scanning for suspicious Windows services Scanning for suspicious start-up programs Scanning for suspicious files and folders Scanning for suspicious processes Virus and Worms #Viruses #The virus is a self-replicating program, it is capable of producing multiple copies by attaching with another program.\nCharacteristics of viruses:\nInfecting other files Alteration of data Corruption Encryption Self-replication Stages of Virus Life # Design: develop virus from scratch or using construction kits Replication: after the virus is deployed, it will start to spread itself Launch: user accidentally launch the infected program Detection: the behavior of a virus is observed, the virus is identified Incorporation: developers design a defensive code Elimination: update the anti-virus, virus eliminated Working of Viruses #Infection Phase #During infection phase, virus planted on a target system, replicate itself onto an executable file. It can be launched when user execute an infected program. These viruses spread by reproducing and infecting programs, documents or email attachments. They can enter the operating system through removable drives or any digital media.\nAttack Phase #File is executed accidentally by user. Normally, viruses require a triggering action to infect, but they can also have configured to infect upon certain predefined conditions.\nTypes of Viruses # System or Boot Viruses: move actual Master Boot Record (MBR) from its actual location, the virus responds from the original location of MBR when the system boots, it executes yje virus first. File Viruses: infect executable files or BAT files. Multipartite Viruses: infect boot sector and files simultaneously. Macro Viruses: designed for Microsoft Office and other application using Visual Basic for Application (VBA). Cluster Viruses: designed to attack and modify the file location table or directory table. Stealth/Tunneling Viruses: to evade detection, stealth virus employs tunnel technique ti launch under anti-virus via a tunnel and intercepting request from Operating System Interruptionhandler. Logic Bombs: designed to remain in waiting state until a predetermined event occurs, then payload detonate and perform its intended task, difficult to detect, difficult to detect. Encryption Virus: uses encryption to avoid detection, use new encryption to encrypt and decrypt the replica. Ransomware #Ransomware is a malware program which restricts the access to the system files and folders by encrypting them. Some type of ransomware may lock the system as well. Attacker demands ransom to provide the decryption key. Ransomware is deployed using trojans. Example: WannaCry\nTypes:\nCryptobit Ransomware CryptoLocker Ransomware CryptoDefense Ransomware CryptoWall Ransomware Police-themed Ransomware Others:\nMetamorphic Viruses File Overwriting or Cavity Viruses Sparse Infection Viruses Companion/Camuflage Viruses Shell Viruses File Extension Viruses Add-on and Intrusive Viruses Transient and Terminate and Stay Resident Viruses Virus generating tools # Sam\u0026rsquo;s Virus Generator JPS Virus Maker Sonic Bat Worms #Worms can replicate themselves but cannot attach themselves. It has the capability to travel without human action. The worm can propagate using file transport and spread across the infected network which virus is not capable of.\nAnalysis and Detection Methods # Scanning: the suspected file is scanned for the signature string Check: the entire disk is checked for integrity, integrity checker records integrity of all files by calculating checksum usually Interception: request from operating system is monitored, emulation and heuristic analysis include behavior analysis and code analysis by executing it in a sophisticated environment Malware Reverse Engineering #Sheep Dipping #The analysis is performing on a dedicated computer, along with port monitoring, anti-viruses and other security programs.\nMalware Analysis #The process of identification of a malware until its verification that the malware is completely removed, including observing the behavior of malware, scoping the potential threat to a system and finding other measures.\nProcess:\nCreating the testbed: use a virtual machine as a host operating system where malware analysis is performed by executing the malware, this virtual machine is isolated from the network, creating a quarantine with it Static and Dynamic malware analysis: observe the behavior, using process monitoring tools, packet monitoring tools and debugging tools, later the network connection is also set up Goals of Malware Analysis # Diagnostics of threat severity or level of attack Diagnostics of the type of malware Scope the attack Build defense to secure networks and systems Finding root cause Built incident response actions Develop anti-malware to eliminate Types of Malware Analysis #Static Analysis or Code Analysis #Disassemble the binary file, fragmenting the resources, without executing it and study each component.\nDynamic Analysis or Behavioral Analysis #Execute the malware and observing its behavior. These analysis are performed in a sandbox environment. Sandboxing technology helps analysis in a dedicated manner in a sophisticated environment. During the sanboxing of the malware, it is searched in the intelligence database for the analysis report. The diagnose is recorded for future use, helps to respond faster.\n","date":"1 February 2020","permalink":"/posts/ceh/malware-threats/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 07: Malware Threats","title":"CEH v10: 07 Malware Threats"},{"content":"With sniffing, you can monitor all sorts of traffic either protected or unprotected. Sniffing is the process pf scanning and monitoring of the captured data like DNS traffic, web traffic and many more by enabling the promiscuous mode on the network interface. The attacker can reveal information from it such as usernames and passwords. Anyone within the same LAN can sniff the packets.\nWorking of Sniffers #In the process of sniffing, the attacker gets connected to the target network to start sniffing. Sniffers turns Network Interface Card (NIC) into promiscuous mode. Promiscuous mode is a mode of the interface in which NIC respond for every packet it receives. The attacker decrypt the packets to extract information.\nConcept:\nSwitch maintain its MAC table to validate the connected hosts Attacker alter this table with Port Mirroring, Switched Port Analyzer (SPAN) and many other techniques All packets copied to the attacker Switch vs Hub # Switch forward broadcast and multicast to all ports, but forward unicast packets to a specific port. Hub transmits all packets to all ports. Types of Sniffing #Passive Sniffing #There is no need of sending additional packet or interfering the device, for example when connected to a hub.\nActive Sniffing #Attacker has to send additional packets to the connected device to start receiving packets.\nTechniques:\nMAC Flooding DHCP Attacks DNS Poisoning Switch Port Stealing ARP Poisoning Spoofing Hardware Protocol Analyzer #A hardware or software that analyze the captured packets and signals over the transmission channel. Hardware Protocol Analyzers are the physical equipment which is used to capture without interfering the network traffic. A major advantage of this hardwares are the mobility, flexibility and throughput.\nHardware Protocol Analyzer can:\nMonitor network usage Identify traffic Decrypt packets Extract information Seize packet Switch Port Analyzer (SPAN) Port #In other name: Port Mirroring\nIt is used on a network switch to send a copy of network packets seen on one switch port (or an entire VLAN) to a network monitoring connection on an other switch port.\nWiretapping #Gaining information by tapping the signal from wire such as telephone lines or the internet. Wiretapping mostly performed by a third party. Legal Wiretapping is called legal interception which is mostly performed by governments or security agencies.\nActive Wiretapping #Monitoring and recording the information with alteration of the communication.\nPassive Wiretapping #Monitoring and recording the information without any alteration in the communication.\nLawful Interception #Wiretapping with legal authorization which allows law enforcement agencies to wiretap the communication of user.\nTelecommunication standardization organization standardized the legal interception gateways for the interception of communication by agencies.\nPlanning tool for Resource Integration, Synchronization, and Management (PRISM) #PRISM is a tool designed to collect information and process that passing through American servers. Developed by Special Source Operation (SSO) division of National Security Agencies (NSA). PRISM is intended for identifying and monitoring of suspicious communication. Internet traffic routing through the US, or data stored on a US server are wiretap by NSA.\nSniffing Countermeasures # HTTPS instead of HTTP SFTP instead of FTP Switch instead of Hub Port security DHCP Snooping Dynamic ARP inspection Source guard Sniffing detection tool Strong encryption protocol Detection: # Ping method ARP method Promiscuous port detection MAC Attacks #Media Access Control (MAC) is the physical address of a device. MAC address is a 48-bit unique identification number that is assigned to a network device for communication at data-link layer (layer 2). First 24 bits are the Object Unique Identifier (QUI), the last 24 bits are the Network Interface Controller (NIC).\nMAC Address Table / CAM Table #MAC address table or Content-Addressable Memory table is used in ethernet switches to record MAC address, and it\u0026rsquo;s associated information which is used to forward packets.\nThe switch observe the incoming frames and records the source MAC of the frames in it\u0026rsquo;s MAC address table. It also records the specific port for the source MAC address. Based on this, switch can make intelligent frame forwarding. Switch removes MAC from the table after switch not seen it for a while.\nMAC Flooding #Attacker sends random MAC addresses mapped with random IP to overflow the storage capacity of CAM table. CAM table has a fixed length, so when filled, switch act as a hub, broadcast every packet on every port, help attacker to sniff packets.\nLinux tool:\nmacof Switch Port Stealing #This technique base on MAC flooding, the attacker send bogus ARP packets with the source MAC address of the target and destination address of its own. The switch update the CAM table because of it.\nIf the attacker send a bogus ARP packet immediately after the target packet, the attacker will get the respond instead of the target.\nDefending against MAC Attacks #Port Security is used to bind MAC address of known devices to the physical ports and violation action is also defined.\nDHCP Attacks #Dynamic Host Configuration Protocol (DHCP) #DHCP is the process of allocating the IP address dynamically so these addresses are assigned automatically and they can be reused when hosts don\u0026rsquo;t need them. Round Trip Time is the measurement of time from discovery of DHCP server until obtaining the leased IP address.\nIPv4 DHCP process # By using UDP broadcast, DHCP client sends an initial DHCP-Discovery packet. The DHCP server reply with a DHCP-Offer packet, offering the configuration parameters. The DHCP client send back a DHCP-Request packet destined for DHCP server for requesting the DHCP parameters. Finally, the DHCP server send the DHCP-Acknowledgement packet containing configuration parameters. CLIENT SERVER DHCP-Discovery -\u0026gt; \u0026lt;- DHCP-Offer DHCP-Request -\u0026gt; \u0026lt;- DHCP-Acknowledgement Ports: UDP port 67 for Server UDP port 68 for Client IPv6 DHCP process # CLIENT SERVER Solicit -\u0026gt; \u0026lt;- Advertise Request -\u0026gt; \u0026lt;- Reply Ports: UDP port 546 for Client UDP port 547 for Server DHCP Relay is needed when the DHCP server is not on the same subnet, because routers do not forward any broadcast IP packet to interfaces. DHCP Relay Agent allows DHCP messages to be exchanged between the DHCP client and the DHCP server residing on different subnet. DHCP Option 82 allows Agents to insert circuit specific information into a request that is being forwarded to a DHCP server.\nDHCP Starvation Attack #DHCP Starvation Attack is a Denial-of-Service attack on a DHCP server. Attacker send bogus requests to DHCP server with spoofed MAC address to lease all IP address in DHCP address pool. Once all IP address is allocated, upcoming users will be unable to obtain IP address or renew the lease.\nTools:\nDhcpstarv Yersinia Rogue DHCP Server #Attacker deploy the rogue DHCP server in the network along with the DHCP starvation attack. When legitimate DHCP server is in Denial-of-Service attacks, DHCP clients are unable to gain IP address from the legitimate DHCP server. Upcoming DHCP Discovery (IPv4) and Solicit (IPv6) are replied by the bogus DHCP server with configuration parameter which directs the traffic towards it.\nDefending against DHCP Starvation and Rogue Server Attack #DHCP Snooping #DHCP snooping feature identify the only trusted ports from DHCP traffic. Any access port who tries to reply the DHCP request will be ignored.\nPort Security # Limit the learning number of a maximum number of MAC addresses on a port Configure violation action, aging time, \u0026hellip; ARP Poisoning #Address Resolution Protocol (ARP) #The Address Resolution Protocol (ARP) is a communication protocol used for discovering the link layer address, such as a MAC address, associated with a given internet layer address, typically an IPv4 address. By broadcasting the ARP request with IP address, the switch can learn the associated MAC address information from the reply of the specific host. If there is no map, or map is unknown, the source will send a broadcast to all node.\nARP Spoofing Attack #Attacker send forged ARP packets over Local Area Network (LAN). In this case, switch will update the attacker\u0026rsquo;s MAC address with the IP address of a legitimate user or server, then start forwarding the packets to the attacker. Attacker can steal information by extracting it from packets.\nARP Poisoning used for:\nSession hijacking Denial-of-Service attacks Man-in-the-Middle attacks Packet sniffing Data interceptions VoIP tapping Connection resetting Stealing passwords Defending ARP Poisoning #Dynamic ARP Inspection (DAI) #DAI is used with DHCP snooping, IP-to-MAC bindings can be tracked from DHCP transactions to protect against ARP poisoning.\nSpoofing Attacks #MAC Spoofing/Duplicating #Manipulating the MAC address to impersonate the legitimate user or launch attack such as DoS. Attacker sniffs the MAC address of users which are active on switch ports and duplicate the MAC address. This can intercept the traffic and traffic destined to the legitimate user may direct to the attacker.\nDefend against MAC Spoofing # DHCP Snooping Dynamic ARP Inspection Source Guard: monitor and prevent the host to impersonate another host DNS Poisoning #Domain Name System (DNS) #DNS is used in networking to translate human-readable domain names to IP address. When DNS Server receives the request, it doesn\u0026rsquo;t have the entry, it generates the query to another DNS Server for the translation and so on. DNS server having the translation will send back the IP address.\nDNS Poisoning Techniques #When DNS server receives a false entry, it updates its database. To increase performance, DNS servers maintain a cache in which this entry is updated to provide quick resolution of queries. This false entry causing poison in DNS translation until the cache expires.\nIntranet DNS Spoofing #Normally performed over Local Area Network (LAN) with switched network. With the help of ARP poisoning, attacker sniff packet, extract the ID of DNS requests and reply with fake IP translation directing traffic to the malicious site.\nInternet DNS Poisoning #Attacker replace the DNS configuration on the target machine.\nProxy Server DNS Poisoning #Attacker replace the DNS configuration of the web browser.\nDNS Cache Poisoning #Attacker exploiting flaws in DNS software, adds or alter the entries.\nDefending Techniques against DNS Poisoning # Segregate authoritative and recursive resolver Query and response verification using DNS Guard Restrict external DNS lookup Prevent DNS Open Resolver configuration Transaction ID randomization DNS application inspection configuration DNS resolver IP Source Guard IDS deployment Disable recursion DNS non-existent domain rate limiting Uni-Cast path forwarding UDP source port randomization DNSSEC Sniffing Tools #Wireshark #Filters in Wireshark:\n==\tEqual eq\tEqual !=\tNot equal ne\tNot equal contains\tContains specified value Defending Against Sniffing # HTTPS instead of HTTP SFTP instead if FTP Switch instead if Hub Port security DHCP Snooping Dynamic ARP Inspection Source guard Sniffing detection tools Strong encryption protocol Sniffing Detection Technique #Ping Method #A ping is sent to the suspect IP address with spoofed MAC. If the NIC is not in promiscuous mode, it will not it will not respond.\nARP Method #First, sending non broadcast ARP packet to the suspect, MAC address will be cached if the NIC is in promiscuous mode.\nSecond, send a broadcast with spoofed MAC, if NIC is in promiscuous mode, it will be able to reply the packet only as it has already learned the actual MAC from sniffed non-broadcast ARP packet.\n","date":"1 February 2020","permalink":"/posts/ceh/sniffing/","section":"Posts","summary":"Certified Ethical Hacker learning material. Chapter 08: Sniffing.","title":"CEH v10: 08 Sniffing"},{"content":"Social engineering is an act of stealing information from humans.\nNo interaction with target system or network Non-technical attack Convincing the target to reveal information One of the major vulnerability which leads to this type of attack is \u0026ldquo;Trust\u0026rdquo;. User trust in another user and does not secure their credentials from them.\nEmployees are uneducated at organizations, so this is a major vulnerability.\nLack of security policies and privacy are also vulnerable.\nSteps of Social Engineering #Research # Collection of information from the target organization Collected by dumpster diving, scanning, search on the internet, \u0026hellip; Select target # Select the target among other employees A frustrated target is more preferred Relationship # Create relationship with the target Earn the trust Exploit # Collecting sensitive information such as usernames, password, etc\u0026hellip; Social Engineering Techniques ###Types of Social Engineering\nHuman-based Social Engineering #One-to-one interaction with the target. Earn the trust to gather sensitive information from the target.\nImpersonation #Pretend to be something or someone, pretending to be a legitimate user or authorized person. Impersonation is performed by identity theft.\nEavesdropping and Shoulder Surfing #Eavesdropping is a technique in which attacker is revealed information by listening to the conversation. Reading or accessing any source of information without being notified.\nShoulder Surfing is a method of gathering information by standing behind the target.\nDumpster Diving #Looking for treasure in trash.\nReverse Social Engineering #The attacker convinces the target of having a problem or might have in the future to get sensitive information.\nPiggybacking and Tailgating #Piggybank is a technique in which attacker waits for an authorized person to gain entry in a restricted area. Tailgating is a technique in which attacker gains access to the restricted area by following the authorized person.\nComputer-based Social Engineering #Phishing #Attacker send fake emails which looks like legitimate email. When recipient opens the link, he is enticed for providing information.\nSpear Phishing #Similar as phishing but it is focused on one target. Because of this, it is generate higher response rate.\nMobile-based Social Engineering #Publishing Malicious Apps #These applications are normally a replica or similar copy of a popular application.\nRepackaging Legitimate Apps #Repack a legitimate app with a malware.\nFake Security Apps #Attacker develop a fake security app.\nInsider Attack #Social Engineering is not all about a third person gathering information, it may be an insider with privileges.\nImpersonation on Social Network Sites #Social Engineering Through Impersonation on Social Network Sites #Attacker gathers personal information of a target from different sources mostly from social network sites such as full name, date of birth, email address, residential address, etc. After gathering the information, the attacker create an account that is exactly the same. Then introduced to friends, group joined by the target to get updates or convince the target\u0026rsquo;s friends to reveal information.\nRisks of Social Network in a Corporate Networks #Social network sites is not secured enough as a corporate network secures the authentication. The major risk of social network is its vulnerability in the authentication. The employee while communicating on social network may not take care of sensitive information.\nIdentity Theft # Stealing the identification information of someone Popularly used for frauds Prove the fake identity to take advantage of it Process # Gathering information: full name, address, contacts, accounts, birth information, bill from social networks, dumpster diving, etc\u0026hellip; Fake identity proof: get fake IDs (driving licence, ID card, etc\u0026hellip;) Fraud: spend money, unauthorized access, use ID for frauds, etc\u0026hellip; Countermeasures # Security of sensitive information Physical security Rotational duties Monitoring Controlled access Least privileges Strong policies Training Bio-metric authentication Audit Awareness Tools # social engineering toolkit (linux) ","date":"1 February 2020","permalink":"/posts/ceh/social-engineering/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 09: Social Engineering.","title":"CEH v10: 09 Social Engineering"},{"content":"Denial-of-Service is type of attack on which service offered by a system or a network is denied. Service may either be denied, reduce the functionality or prevent the access.\nSymptoms of DoS attack: # Slow performance Increase in spam email Unavailability of a resource Loss of access to a website Disconnection of a wireless or wired internet connection Denial of access to any internet services Distributed Denial of Service (DDoS) #In DDoS, multiple compromised systems are involved to attack a target.\nThe attacker send several connection request to the server with fake return address, so the server can\u0026rsquo;t find a user to send the connection approval. The authentication process waits for a certain time to close the session. The attacker is continuously sending requests which causing a number of open connection on the server that lead to a denial of service.\nCategories of DoS/DDoS Attacks #Volumetric Attacks #Denial of Service attack performed by sending a high amount of traffic towards the target. Volumetric attack are focused on overloading the bandwidth capability.\nFragmentation Attacks #DoS attacks witch fragment the IP datagram into multiple smaller size packets. It requires to reassembly at the destination which requires resources of routers.\nTypes:\nUDP and ICMP fragmentation attacks TCP fragmentation attacks TCP-State-Exhaustion Attacks #TCP-State-Exhaustion Attacks are focused on web servers, firewalls, load balancers and other infrastructure component to disrupt connections by exhausting their finite number of concurrent connections.\nMost common state-exhaustion attack is ping of death.\nApplication Layer Attacks / Layer 7 DDoS #The application level attack overloads the particular service of a website or application.\nDoD/DDoS Attack Techniques #Bandwidth Attacks #Bandwidth attack requires multiple sources to generate q request to overload the target. The goal is to consume the bandwidth completely.\nZombie servers or Botnets used to perform this type of attack.\nService Request Floods #Attacker flood the request towards a web service or server until it is overloaded.\nSYN Attack / Flooding #The attacker sending a lot of SYN request to tying up a system. The victim waits for the acknowledgement from the IP address, but there will be no response because the source address is spoofed. This waiting period ties up a connection \u0026ldquo;listen to queue\u0026rdquo;, that can tie up for 75 seconds.\nICMP Flood Attack #Flooding ICMP request without waiting for the response overwhelm the resource of the network device.\nPeer-to-Peer Attacks #Exploit bugs in peer-to-peer servers using Direct Connect (DC++). Using one or more malicious hosts in a peer-to-peer network to perform the attack.\nPermanent DoS Attack (PDoS) #Permanent DoS attack is focused on hardware sabotage, cause irreversible damage to the hardware. Affected hardware require replacement or reinstall the software.\nMethods:\nPhlashing Bricking a system : sending fraudulent hardware updates Application Level Flood Attacks #Attacker finds the fault and flaws in an application or operating system and exploits the vulnerability to gain control over a system.\nDistributed Reflection Denial of Service (DRDoS) #Attacker uses an intermediary victim which redirect the traffic to a secondary victim. Secondary victim redirects the traffic to the target. The intermediary and secondary victim is used for spoofing the attack.\nBotnet #Attacker compromises victims to make bot, which compromise other system to create a botnet. These botnets are controlled by Command and Control server owned by the attacker. This server is used to send instructions to perform the attack.\n","date":"1 February 2020","permalink":"/posts/ceh/denial-of-services/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 10: Denial of Service","title":"CEH v10: 10 Denial of Service"},{"content":"Web Server #Web Servers are the programs that are used for hosting services.\nWeb Servers are deployed on a separate web server hardware or installed on a host as a program.\nIt delivers content over Hyper Text Transfer Protocol (HTTP).\nWeb Servers support different types of application extensions whereas all of the support Hypertext Markup Language (HTML).\nWeb Server Security Issue #Web server vulnerabilities:\nImproper permission of file directories Default configurations Enabling unnecessary services Lack of security Bugs Misconfigured SSL certificate Enabled debugging Open Source Web Servers # Apache HTTP Server Nginx Apache Tomcat Lighttpd Internet Information Services (IIS) #IIS is a Windows-based webserver.\nComponents of IIS # Protocol listener are responsible for receiving and returning protocol-specific requests. HTTP.sys are responsible for HTTP requests. World Wide Web Publishing Service (WWW Service) Windows Process Activation Service (WAS) Web Server Attacks #DoS/DDoS #DNS Server Hijacking #DNS Amplification Attack #Spoof the source address of the DNS request, by the amplification of the size of the request and using botnets, it results a DDoS attack.\nDirectory Traversal Attacks #Attacker using trials and error method to access restricted directories to reveal sensitive information.\nMan-in-the-Middle / Sniffing Attacks #Phishing Attacks #Website Defacement #After a successful intrusion, attacker alters and modify the content of the website.\nWebserver Misconfiguration #Attacker looks for misconfigurations and vulnerabilities to exploit.\nHTTP Response Splitting Attack #Read more here\nWeb Cache Poisoning Attack #The attacker wipe the actual cache of the webserver and sending crafted request to store fake entries.\nWeb Application Attacks # Cookie Tampering DoS SQL Injection Session Hijacking Cross-Site Request Forgery (CSRF) Cross-Site Scripting (XSS) Buffer Overflow Attack Methodology #Information Gathering #Collecting information from internet.\nrobots.txt #Attacker extract information about internal files.\nRead more\nWeb Server Footprinting #Results the server name, type, OS, applications, etc.\nTools:\nNetcraft Maltego httprecon Mirroring a website #Download the website, to inspect offline, without any interaction to the target.\nTool:\nhttrack Vulnerability Scanning #Automated tool to inspect website and detect vulnerabilities. These tools perform depp inspection of scripts, open ports, banners, etc.\nTools:\nowasp-zap openvas Hacking Web Passwords #Extract passwords to gain authorized access to the system. Password may be get from social engineering, tampering the communication, etc.\nPassword Attacks classification:\nNon-Electronic attacks Active online attacks Passive online attacks Default password offline attack Countermeasures # Place web server in a secure zone (behind firewall, IDS, IPS, DMZ) Detect potential changes (hashing, script to detect change) Auditing ports Disable insecure and unnecessary ports Using port 443 (HTTPS) over port 80 (HTTP) Encrypted traffic Server certificate Code Access Security Policy Disable tracing Disable debug complies Software update Disable default account Patch Management #Hotfix is a small update which fix an issue. Patch is a bigger of software to fix one or more issues.\nMethods:\nManual download Auto-Update Patch Management is an automated process to detect missing security patches, find out solutions, download patch, test the patch in an isolated environment then deploy the patch onto the systems.\nTools:\nMicrosoft Baseline Security Analyzer (MBSA) ","date":"1 February 2020","permalink":"/posts/ceh/hacking-web-servers/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 13: Hacking Web Servers","title":"CEH v10: 13 Hacking Web Servers"},{"content":"Terminology #Web Applications are that applications that is running on a remote application server and available for clients over the internet.\nServer Administrators are responsible for the web server\u0026rsquo;s safety, speed, functioning and performance.\nApplication Administrators are responsible for the management and configuration required for the web application.\nClients are the endpoints which interact with the web application / server.\nHow Web Applications work? #Front-end \u0026lt;-\u0026gt; Back-end\nUsers are interacting with the front-end. The processing was controlled and processed by the back-end.\nServer-side languages:\nPHP Java C# Python JavaScript many more\u0026hellip; Client-side languages:\nCSS JavaScript HTML Layers of Web Applications # Presentation Layer is responsible for displaying the information to the user. Logical Layer : manipulate information to and from the forms. Data Layer : hold the data for the application. Web 2.0 #In web 1.0, the users are limited to passive viewing the content.\nIn web 2.0, the users can interact and collaborate, it contain rich user experience, dynamic content.\nWeb Application Threats # Cookie poisoning Insecure storage Information leakage Directory traversal Parameter/Form tampering DOS attack Buffer overflow Log tampering SQL injection Cross-site Script Cross-site Request Forgery Security misconfiguration Broken session management DMZ attacks Session hijacking Network access attacks Unvalidated input #Process an non-validated input from the client to the back-end. This is a major vulnerability, this is the basics of injection attacks (SQL injection, xss, buffer overflow).\nParameter / Form Tampering #Parameter tempering is an attack, where the attacker manipulate the parameter while client and server are communicating with each other. Parameters such as Uniform Resource Locator (URL) or web page form fields are modified (cookies, HTTP Header, form fields).\nInjection Flaws #Works if a web application allows untrusted input to be executed.\nMalicious code injection File injection SQL injection Command injection LDAP injection SQL Injection #Injection of malicious SQL queries. Attacker can manipulate the database These vulnerabilities can be detected by using an automated scanner.\nCommand Injection # Shell injection File injection HTML embedding LDAP Injection #Attacker can access the database using LDAP filter to search information.\nDoS Attack # User Registration DoS : an automated process, the attacker keep registering fake accounts. Login DoS : attacker keep sending login requests. User Enumeration : attacker brute force login credentials with a dictionary attacks. Account Lock : attacker attempt to lock the user account by attempting invalid passwords. Web Application Hacking Methodology #Analyze Web Application # Observing functionality Identify vulnerabilities, entry points, servers HTTP request analyze HTTP fingerprinting Hidden content discovery Attack Authentication #Exploit the authentication mechanism:\nUsername enumerate Cookie exploitation Session attacks Password attacks Authorization Attack Schemes # Accessing the web application with low level privilege account, then escalate privileges to get information Parameter tampering (URL, POST data, Query string, cookies, HTTP header) Session Management Attack #Impersonate a legitimate user.\nSession hijacking techniques:\nSession token prediction Session token tampering Man-in-the-Middle attack Session replay Injection Attacks #Inject malicious code, commands and files.\nTechniques:\nWeb Script injection OS Command injection SMTP injection SQL injection LDAP injection XPath injection Buffer Overflow Canonicalization Data Connectivity Attack #Exploit the data connectivity between application and its database. Data connection requires a connection string.\nConnection String Injection Connection String Parameters Pollution (CSPP) Connection Pool DoS Countermeasures #Percent Encoding #Percent Encoding or URL Encoding is a technique for secure handling of URL by replaces unsafe and non-ascii characters with % followed by two hexadecimal digits.\nExample:\n%20 or + both are used for SPACE\nIn URL:, there are some reserved character such as \u0026lsquo;/\u0026rsquo; that is used to separate paths in URL. To use this not as separator, then it must be encoded.\n%2F used for \u0026lsquo;/\u0026rsquo;\nFull list of percent encoded characters here\nHTML Encoding #HTML Encoding specify how special character will shown.\nSQL Injection Contermeasures # Input validation Customized error messages Monitoring database traffic Limit length of user input XSS Attack Countermeasures # Testing tools Filtering meta Filtering output DOS Attack Countermeasures # Reverse proxy Remove unnecessary functions Secure remote administration Firewall IDS Other Countermeasures # Dynamic testing Source Code analysis Strong cryptography Use SSL Hotfixes / patches Cookie timeout ","date":"1 February 2020","permalink":"/posts/ceh/hacking-web-applications/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 14: Hacking Web Applications","title":"CEH v10: 14 Hacking Web Applications"},{"content":"The intention of SQL injection is to reveal or manipulate sensitive information from the database by injecting commands into existing queries.\nBypassing authentication Revealing sensitive information Compromise data integrity Erase database Remote code execution Tools # sqlmap SQL #SQL stands for Structured Query Language.\nSQL tutorial here\nTypes of SQL Injection #In-Band SQL Injection #Use the same communication channel to launch the attack and get the result.\nError Based SQL Injection # Server throw an error message Error message is useful during the development, but should be disabled it when the application is live Techniques to perform SQL Injection # System stored procedure End of line comment Illegal / Logically incorrect query Tautology (something that is inherently true, like \u0026quot; OR 1=1\u0026quot;) Union SQL Injection #Involves the UNION SQL operator, to combine the queries.\nSelect the password from table1 and table2 using UNION:\nSELECT password FROM table1 UNION SELECT password FROM table2 Inferential SQL Injection # Known as Blind SQL Injection No data is transferred from the via the application, the attacker sending payloads, then observe the web application\u0026rsquo;s response and behavior. Boolean-based Blind SQL Injection #Sending an SQL query to the database which send a different result depending on whether the query returns TRUE or FALSE result, the HTTP response will change or remain the same.\nThis type of attack is slow, attacker need to enumerate the database, character by character.\nTime-based Blind SQL Injection #Attacker send a query, force the database to wait for a specified time before respond. The respond time indicate that the query TRUE or FALSE.\nOut-of-band SQL Injection #Depends on the features allowed on the database server (DNS, HTTP request), so not a very common attack.\nUse different channel to launch the attack.\nSQL Injection Methodology #Information Gathering And Vulnerability Detection # Collect the information about the web application, server, OS, database, \u0026hellip; Identify vulnerabilities Evaluate input fields Launch Attack # Select the appropriate type of SQL Injection, based on the gathered information Advanced SQL Injection # Enumerate the database (Postgre, MySQL, Oracle, \u0026hellip;) Identify privilege level of users Passwords and hashes grabbing Transfer database to a remote machine Evasion Techniques #Evading IDS # Inserting inline comment in between keywords Character encoding String Concatenation Obfuscated codes Manipulating white spaces Hex encoding Sophisticated matches Countermeasures # Penetration testing (manual, with tool) Source code analysis Wep Application Firewall (WAF) Remove debugging messages Database account with minimal privileges Input validation Filter data Customize error messages IDS ","date":"1 February 2020","permalink":"/posts/ceh/sql-injection/","section":"Posts","summary":"Certified Ethical Hacker learning material. Chapter 15: SQL Injection.","title":"CEH v10: 15 SQL Injection"},{"content":"Terms #Wireless network is a computer network that uses wireless data connection between network nodes.\nAccess Point: Access Point (AP) or Wireless Access Point (WAP) is a hardware device that allows wireless connectivity to the end devices.\nService Set Identifier (SSID): A 32 bit identification string of the Access Point, the AP\u0026rsquo;s name. SSID inserted into the header of every data packet.\nBasic Service Set Identifier (BSSID): MAC address of the Access Point.\nISM Band: A frequency band dedicated to the Industrial, Scientific and Medical purpose.\nGSM # Global System for Mobile Communication Generations: 2G (GSM), 3G (UMTS), 4G (LTE) Frequency: 900 MHz - 1800 MHz Wireless Standards # Protocol Frequency Modulation 802.11a 5 GHz OFDM 802.11b 2.4 GHz DSSS 802.11g 2.4 Ghz OFDM 802.11n 2.4/5 Ghz MIMO-OFDM 802.11ac 5 Ghz MIMO-OFDM Bluetooth 2.4 Ghz Wi-FI #Wi-Fi is a local area networking technology based on the IEEE 802.11 standard.\nWi-Fi Authentication # Open authentication Shared Key authentication Open Authentication # Client WAP Probe Request -\u0026gt; \u0026lt;- Probe Response Open System Authentication Request -\u0026gt; \u0026lt;- Open System Authentication Response Association Request -\u0026gt; \u0026lt;- Association Response The Probe Request is to discover the network The Probe Response contains the parameters (SSID, data rate, encryption, \u0026hellip;) The Open System Authentication Request (authentication frame) is to set authentication open, the sequence number is set to 0x0001 The Open System Request Response\u0026rsquo;s sequence number is 0x0002 The Association Request contains the security parameters (choosen encryption, \u0026hellip;) The Association Response complete the associations process Shared Key Authentication # Client WAP Authentication Request -\u0026gt; \u0026lt;- Authentication Response with Challenge Text Encrypted Challenge Response -\u0026gt; \u0026lt;- Successful / Unsuccessful response Challenge test # The client encrypt the challenge test with his shared key The AP decrypt the encrypted challenge test with his shared key, if the decrypted text matches, the successful authentication response frame is sent to the client This challenge test can be captured by a hacker as a clear text, so the hacker can get the shared key IEEE 802.1X #IEEE 802.1X is an IEEE Standard for port-based Network Access Control (PNAC). It provides an authentication mechanism to devices wishing to attach to a LAN or WLAN.\nExtensible Authentication Protocol (EAP) is an authentication framework frequently used in wireless networks and point-to-point connections. For example, in IEEE 802.11 (Wi-Fi) the WPA and WPA2 standards have adopted IEEE 802.1X with one hundred EAP Types as the official authentication mechanisms.\nParties # Supplicant : a client device (such as a laptop) that wishes to attach to the LAN/WLAN Authenticator : a network device, such as an Ethernet switch or wireless access point Authentication server : typically a host running software supporting the RADIUS and EAP protocols Authentication Progress # The client may send an EAP-start message. The access point sends an EAP-request identity message. The client\u0026rsquo;s EAP-response packet with the client\u0026rsquo;s identity is \u0026ldquo;proxied\u0026rdquo; to the authentication server by the authenticator. The authentication server challenges the client to prove themselves and may send its credentials to prove itself to the client (if using mutual authentication). The client checks the server\u0026rsquo;s credentials (if using mutual authentication) and then sends its credentials to the server to prove itself. The authentication server accepts or rejects the client\u0026rsquo;s request for connection. If the end user was accepted, the authenticator changes the virtual port with the end user to an authorized state allowing full network access to that end user. At log-off, the client virtual port is changed back to the unauthorized state. Wardriving #Wardriving is the act of searching for Wi-Fi wireless networks by a person usually in a moving vehicle, using a laptop or smartphone.\nVariants : warwalking, warcycling, warflying (drone)\nWarchalking is the drawing of symbols in public places to advertise Wi-Fi networks.\nTypes of Wireless Antennas #Directional Antenna #Direction antennas are designed to function in a specific direction to improve efficiency\nSome types of directional antenna: Parabolic antenna , Yagi-Uda antenna , Horn antenna\nOmnidirectional antennas #Omnidirectional antenna radiates equal radio power in all directions. When graphed in three dimensions this radiation pattern is often described as doughnut-shaped.\nUse cases: radio broadcasting, cell phones, GPS\nSome type: Whip antenna , Rubber Ducky antenna , Monopole antenna\nWireless Encryption #Wired Equivalent Privacy (WEP) # Designed to provide the same level of security as that of a wired LAN Authentications: Open System authentication, Shared Key (need to provide a key) WEP Key is a sequence of hexadecimal values WEP Key length: 10 digit (40 or 64 bit), 26 digit (104 or 128), 58 digit (256 bit) WEP is used in Physical layer and Data Link layer of OSI model Initialization Vector (IV) is 24-bit long WEP work Breaking WEP Encryption # Monitor the Access Point channel Test injection capability to the AP Use tool for fake authentication Sniff the packets Inject encrypted packets Extract the encryption key form IV with a cracking tool Wi-Fi Protected Access (WPA) # Used for WLAN network based on 802.11i Temporal Key Integrity Protocol (TKIP) implements a key mixing function that combines the secret key with the initialization vector before passing it to the RC4 cipher. WEP, in comparison, merely concatenated the initialization vector to the root key, and passed this value to the RC4 routine. TKIP increased the key length to 128-bit Implements a sequence counter to protect against replay attacks Implements a 64-bit Message Integrity Check, a checksum to protect against tampering Initialization Vector is 48-bit long WPA2 # Counter Mode Cipher Block Chaining Message Authentication Code Protocol (CCMP) is an enhanced data cryptographic encapsulation mechanism designed for data confidentiality Implements AES based encryption mode Wi-Fi Protected Setup (WPS) allows users to quickly connect to a WPA protected WLAN WPA-Personal uses password (Pre-Shared Key(PSK)) for authentication WPA-Enterprise includes EAP or RADIUS for centralized authentication Breaking WPA Encryption # Brute forcing the PSK with a dictionary attack Capture the Authentication Handshake packets to crack the WPA-PSK offline Deauthenticate client to force to reconnect to brute force the Pairwise Master Key (PMK) Wireless Threats # Access Control Attacks : evading access control parameters (MAC spoofing, Rogue Access point) Integrity Attacks : Data frame injection, replay attacks, etc\u0026hellip; Confidentiality Attacks : traffic analysis, session hijacking, MITM, etc\u0026hellip; Availability Attacks : prevent user from accessing the wireless network (flooding, ARP poisoning, De-Authentication attacks) Authentication Attacks : steal identity information or impersonating clients (password cracking, identity theft, password guessing) Rogue Access Point : a fake access point in a place with the legitimate one, with the same SSID to monitor victims activity by sniffing packets Client Mis-Association Attacks : a rogue access point outside the place with the legitimate one, when Wi-Fi turned on, it will probe for networks that previously connected to Misconfigured Access Point Attacks : get legitimate access by taking advantage of access point\u0026rsquo;s misconfiguration (default or week password, without password) Unauthorized Association : a trojan turns the victims computer into an access point to get connection with the target network Ad Hoc Connection Attack : attacker compromise the client ad hoc mode Jamming Signal Attacks : jamming or blocking the wireless communication, causing a denial of service Hacking Methodology #Wi-Fi Discovery # Passive footprinting (sniffing packets) Active footprinting (probing the AP to get information) GPS Mapping # Create list of discovered Wi-Fi networks including GPS location Wireless Traffic Analysis # Capture the packets to reveal any information (SSID, authentication method, \u0026hellip;) Launch Attacks # ARP poisoning MAC spoofing De-Authentication Rogue access point MITM Wireless Security Tools #Wireless Intrusion Prevention System (WIPS) # Monitors the wireless network Protect against unauthorized access points Perform automatic intrusion prevention Monitors the radio spectrum to prevents rogue access point and alert the network administrator Fingerprint approach to filter devices with spoofed MAC address WIPS has three component: server, sensor and console Can detect AP misconfiguration Detect honeypots Mitigate DoS Wi-Fi Security Auditing Tool # Wireless network auditing Troubleshooting Intrusion detection / prevention Threat mitigation Rogue detection Zero-day threat protection Wi-Fi Countermeasures # Change default parameters Disable remote login to wireless devices Wireless IPS deployment Use strong password Use the latest standards (WPA2 AES) MAC filtering Update software often Enable firewall Use network management software Bluetooth # Bluetooth is a wireless technology for exchanging data over short distance Range: typically less then 10m Operates on the 2.4 GHz Discovery feature can control the visibility of the device Bluetooth Attacks # BlueSmacking : flooding echo packages to cause a denial of service BlueBugging : exploiting bugs in Bluetooth devices to gain remote access BlueJacking : send unsolicited data to Bluetooth devices BluePrinting : extract information about the device BlueSnarfing : steal data from target device Countermeasures # Check paired devices Turn off visibility / turn off Bluetooth if not used Use strong PIN Use encryption Don\u0026rsquo;t accept unknown requests ","date":"1 February 2020","permalink":"/posts/ceh/hacking-wireless-networks/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 16: Hacking Wireless Networks","title":"CEH v10: 16 Hacking Wireless Networks"},{"content":"Mobile Platform Attack Vectors\nOWASP Top 10 Mobile Threats #OWASP Mobile Security Project maintain a list of the most common mobile security risks.\nTop Ten (2014) # Weak Server Side Controls Insecure Data Storage Insufficient Transport Layer Protection Unintended Data Leakage Poor Authorization and Authentication Broken Cryptography Client Side Injection Security Decisions via Untrusted Inputs Improper Session Handling Lack of Binary Protections Top Ten (2016) # Improper Platform Usage: misuse of a platform feature or failure to use a platform security controls Insecure Data Storage: insecure data storage + unintended data leakage Insecure Communication: poor handshaking, incorrect SSL, weak negotiation, cleartext communication of sensitive assets, \u0026hellip; Insecure Authentication: captures notions of authenticating the end user or bad session management Insufficient Cryptography: cryptography was attempted, but it wasn\u0026rsquo;t done correctly Insecure Authorization: capture any failures in authorization Client Code Quality: all of the code-level implementation problem in the mobile client Code Tampering: binary patching, local resource modification, method hooking, dynamic memory modification, \u0026hellip; Reverse Engineering: analysis of the final core binary to determine the source code, libraries, \u0026hellip; Extraneous Functionality: internal development security controls that are not intended to be released into a production environment Attack Vector #Basic Threats # Malware / rootkit Data Loss Data Tampering Data Exfiltration Vulnerabilities And Risks on Mobile Platforms # Malicious third-party application / in the store Application vulnerability Data security Excessive permissions Weak encryptions Operating System update issue Application update issue Jailbreaking / rooting Physical attack OS Sandboxing Issue # Sandbox is a security mechanism for separating running programs, usually in an effort to mitigate system failures or software vulnerabilities from spreading Sandbox limits the app\u0026rsquo;s access to files, preferences, network resources, \u0026hellip; Advanced malware designed to bypass it, by fragment code or put sleep timer in the script to bypass the inspection process Android #Device Administration API # Provides device administration features at the system level This API allows to create security-aware apps that are useful in the enterprise settings, where require rich control over employee devices Rooting # A process of allowing user to attain privileged control Needed for modify settings, get full control over the kernel or install custom ROMs iOS #Jailbreaking # Rooting the iOS Escalating the privileges on iOS to remove or bypass the factory default restrictions Types of Jailbreaking # Userland Exploit : allow user-level access without escalating iBoot-level access iBoot Exploit : allow user-level and boot-level access Bootrom Exploit : allow user-level and boot-level access Jailbreaking Techniques #Untethered Jailbreak # Does not require to reboot with a connection to your computer Exploit bypass the iBoot sequence Tethered Jailbreak # Need a connection to your computer to reboot, without it, the boot stuck with an Apple logo Offers complete jailbreak features Semi-Untethered Jailbreak # Allows to boot into the iOS device, but with limited functionality The jailbreak functions will be disabled until the launch of a jailbreak app Semi-Tethered Jailbreak # Allows you to boot with limited functionality To get the full functionality, a reboot with a tethered jailbreak required Semi-Tethered Jailbreak: tethered jailbreak + a package to allow reboot with limited functionality Windows Phone # Windows Phone 8 using the Windows NT Kernel Windows Phone 8 include app sandboxing, remote device management, native code support (C++) BlackBerry OS # Support for Java Micro Edition MIDP 1.0 and MIDP 2.0 OS update with BlackBerry over the air software loading service (OTASL) Attack Vectors #Malicious Code Signing # Obtaining a code-signing ket from the code signing service to create a malicious application JAD File Exploit # Java Application Description (.jad) contains attributes of Java application Attacker can craft a .jad file with spoofed information Mobile Device Management (MDM) # Deployment, maintenance and monitoring of mobile devices MDM Functions # Enforce device to be locked after certain failed login Enforce strong password policy for all BYOD MDM can detect attempt of hacking BYOD device and then limit the network access of the affected device Enforce confidentiality by using encryption as per organization\u0026rsquo;s policy Administration and implementation of Data Loss Prevention (DLP) MDM Deployment Methods #Two type:\nOn-Site MDM Deployment # Install MDM application on local servers Management is done by local staff Provide full control over the MDM Cloud-Based MDM Deployment # MDM application is installed and maintained by a third party Less administration needed The deployment and maintenance is the responsibility of the service provider Bring Your Own Device (BYOD) #BYOD is a trend of employees using their personal devices for work. It could be a laptop, a phone, etc\u0026hellip;\nBYOD Policies #BYOD policies should include:\nDevice: which devices and operating systems are supported Password: require all devices to be password protected Access: determine which data can be accessed from employee\u0026rsquo;s device Application: which applications allowed, which should be banned Mobile Security Guideline # Avoid auto-upload of files Perform security assessment of applications Turn off Bluetooth Allow only necessary GPS-enabled applications Do not connect to open network Install applications from trusted sources Use strong password Use Mobile Device Management (MDM) softwares Update operating system often Do not allow rooting / jailbreaking Encrypt phone storage Periodic backup Configure mobile device policies ","date":"1 February 2020","permalink":"/posts/ceh/hacking-mobile-platforms/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 17: Hacking Mobile Platforms.","title":"CEH v10: 17 Hacking Mobile Platforms"},{"content":"The Internet of things (IoT) is the network of devices, vehicles, and home appliances that contain electronics, software, actuators, and connectivity which allows these things to connect, interact and exchange data.\nIoT involves extending Internet connectivity beyond standard devices, such as desktops, laptops, smartphones and tablets, to any range of traditionally dumb or non-internet-enabled physical devices and everyday objects.\nEmbedded with technology, these devices can communicate and interact over the Internet, and they can be remotely monitored and controlled.\nMain Components # Sensors Device Gateway Cloud IoT Architecture # Perception Layer : sensors that gather information about the environment (heat sensor) Transport Layer : transfer the sensor data through network (Wi-Fi, Bluetooth, \u0026hellip;) Processing Layer : stores, processes, analyses data (cloud computing, big data, \u0026hellip;) Application Layer : delivering application specific services to the user Business Layer : manage the whole IoT system (business and profit model, user\u0026rsquo;s privacy) IoT Technologies # IoT uses IPv6 due to the limited number of IPv4 addresses Wireless #Short-Range Wireless Communication # Bluetooth Low Energy (BLE) Wi-FI Radio-Frequency Identification (RFID) Light-Fidelity (Li-Fi): similar to Wi-Fi, but using visible light for communication Near-Field Communication (NFC) Medium-Range Wireless Communication # LTE-Advanced : formally submitted as a candidate 4G, often being described as 3.9G (beyond 3G but pre-4G) Wi-Fi HaLow : uses 900MHz to provide extended range, lower energy consumption Long Range Wireless Communication # Low-Power Wild-Area Network (LPWAN) : designed to allow long range communication at a low bit rate among things Very Small Aperture Terminal (VSAT) : satellite communication technology uses small dish antennas Cellular Wired Communication # Ethernet Power-Line Communication (PLC) : using electrical wiring to carry power and data Operating System # Linux on embedded systems Windows IoT IoT Communication Models #Device-To-Device Model # The devices communicating with each other without interfering any other device Using communication medium such as a wireless network Device-To-Cloud Model # The IoT device directly communicating with the application server The application server provide information exchange between these devices Device-To-Gateway Model # Gateway collects the data from the sensors, then send it to the application server Gateway provides security or information and protocol translation Back-End Data-Sharing Model # Used a collective partnership between different application providers Access granted to the uploaded data to third-parties An extended Device-To-Cloud model Challenges to IoT # Lack of security Vulnerable interfaces Physical security risk Lack of vendor support Difficult ot update firmware and OS Interoperability issues OWASP Top Ten IoT (2014) # Insecure web interface Insufficient authentication / authorization Insecure network services Lack of transport encryption / integrity verification Privacy concerns Insecure cloud interface Insecure mobile interface Insufficient security configurability Insecure software / hardware Poor physical security Common Attacks # Device memory containing credentials Access control Firmware extraction Privilege escalation Resetting to an insecure state Removal of storage media Web attacks Firmware attack Network service attacks Unencrypted local data storage Confidentiality and integrity issues Cloud computing attacks Malicious updates Insecure APIs Mobile application threats DoS / DDoS Rolling Code Attack: attacker capture signal from transmitter device, simultaneously blocking the receiver to receive the signal, later it will used to gain unauthorized access (steal car with captured signal) BlueBorn Attack: using different exploits to gain unauthorized access to the target device Jamming Attack: jamming the signal to prevent the communication of devices Backdoor (not just IoT related) Eavesdropping Sybil attack Exploit kits Man-in-the-middle attack Replay attack Forged malicious devices Side channel attack Ransomware attack Hacking Methodology #Information Gathering # IP address Running protocols Open ports Type of device Vendor shodan is a helpful search engine for IoT Vulnerability Scanning # Scanning the network and devices to find vulnerabilities Search for weak password Software and firmware vulnerabilities Tools: nmap, hping, \u0026hellip; Attack # Exploiting vulnerabilities Tools: HackRF Gain Access # Gain unauthorized access Privilege escalation Install backdoor Maintain Attack # Logging out Clearing logs Covering tracks Countermeasures # Firmware update Block unnecessary ports Disable telnet Use encrypted communication (SSL/TLS) Use strong password Encrypt drives Periodic assessment of devices Secure password recovery Two-Factor Authentication Disable UPnP ","date":"1 February 2020","permalink":"/posts/ceh/iot-hacking/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 18: IoT Hacking","title":"CEH v10: 18 IoT Hacking"},{"content":"Cryptography is the practice and study of techniques for secure communication in the presence of adversarial behavior.\nTerms # Clear text / plaintext: the unencrypted data Cipher text: the encrypted data Key: specifies the transformation of data for encryption / decryption (\u0026ldquo;key\u0026rdquo; is not synonymous with \u0026ldquo;password\u0026rdquo;, although a password can in fact be used as a key) Cipher: an algorithm for performing encryption and decryption Symmetric cryptography # Use the same key for the encryption and the decryption Symmetric-key either use stream cipher and block cipher Popular algorithms: AES, DES Asymmetric / Public Key cryptography # Two key used: public and private Public key is publicly known to everyone, issued by Public Key Infrastructure (PKI) and use to encrypt the data Private key is a secret for the public,only known by the owner and it is used to decrypt the data Asymmetric cryptography delivers confidentiality, integrity, authenticity and non-repudiation Popular algorithms : RSA, DSA and Diffie-Hellman Methods #Substitution Cipher # Every character is substituted with another one More on Wikipedia Example cipher : Caesar cipher Example:\nPlaintext : THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG Ciphertext : QEB NRFZH YOLTK CLU GRJMP LSBO QEB IXWV ALD Key : right shift of 3 Transposition Cipher # The positions held by units of plaintext are shifted according to a regular system Example cipher Rail Fence cipher Example:\nClear text: WE ARE DISCOVERED. FLEE AT ONCE W . . . E . . . C . . . R . . . L . . . T . . . E . E . R . D . S . O . E . E . F . E . A . O . C . . . A . . . I . . . V . . . D . . . E . . . N . . Ciphertext: WECRLTEERDSOEEFEAOCAIVDEN Polyalphabetic Cipher # Based on substitution Using multiple substitution alphabets Example cipher : Vigenère cipher Stream Cipher # Text digits are combined with a pseudorandom cipher digit stream (keystream) Each plaintext digit is encrypted one at a time with the corresponding digit of the stream 2 type: Synchronous Stream Ciphers : stream of pseudo-random digits is generated independently of the plaintext and ciphertext messages, and then combined with the plaintext (to encrypt) or the ciphertext (to decrypt) Self-Synchronizing Stream Cipher : uses several of the previous N ciphertext to compute the keystream Example cipher: RC4 Block Cipher # Operating on fixed-length groups of bits, called a block, with an unvarying transformation that is specified by a symmetric key Example cipher: AES, DES Stream Cipher #RC4 # Designed in 1987, leaked in 1994 Used in SSL, WEP Simple amd fast algorithm RC4 generates a pseudorandom stream of bits (a keystream) and combining it with the plaintext using bit-wise exclusive-or for encryption The permutation is initialized with a variable length key, typically between 40 and 2048 bits Marked as insecure Symmetric Algorithms #Data Encryption Standard (DES) # Introduced in 1975 Standardized in 1977 Problem with DES: short key length (56 bits) Now considered as insecure Improved version: Triple DES (involves DES three times) Problem with Triple DES: slow, compute heavy Parameters # Parameter Value Block size 64 bits Key size 56 bits No. of rounds 16 Advanced Encryption Standard (AES) # First published in 1998 Became a federal government standard in 2002 First approved (and only) publicly accessible cipher approved by the NSA for top secret information Parameters # Parameter AES-128 value AES-192 value AES-256 value Block size 128 bits 128 bits 128 bits Key size 128 bits 192 bits 256 bits No. of rounds 10 12 14 ","date":"1 February 2020","permalink":"/posts/ceh/cryptography/","section":"Posts","summary":"Certified Ethical Hacker v10 Chapter 20: Cryptography","title":"CEH v10: 20 Cryptography"},{"content":"","date":null,"permalink":"/tags/apache/","section":"Tags","summary":"","title":"Apache"},{"content":"","date":null,"permalink":"/tags/automation/","section":"Tags","summary":"","title":"Automation"},{"content":"","date":null,"permalink":"/tags/cache/","section":"Tags","summary":"","title":"Cache"},{"content":"Nginx is a popular web server known for its performance, stability, and rich feature set. While it\u0026rsquo;s an excellent tool for managing web traffic, improper configurations can lead to performance issues, security vulnerabilities, and operational problems.\nCommon Nginx misconfigurations and their solutions can be quite varied, depending on the specific use case and environment. However, there are several frequently encountered issues that administrators often run into. Here are a few of them along with their solutions and examples:\nInsecure SSL/TLS Settings #Using outdated SSL protocols or weak ciphers can make your website susceptible to attacks like SSL stripping or man-in-the-middle (MITM) attacks.\nSolution #Ensure that you\u0026rsquo;re using the latest TLS protocols (e.g., TLS 1.2 or 1.3) and strong ciphers. Regularly update your configurations to align with current best practices in SSL/TLS security.\nSSL/TLS Misconfiguration #SSL/TLS certificates are improperly set up, leading to security warnings or errors in browsers.\nSolution #Correctly configure SSL certificates and settings, including the ssl_certificate and ssl_certificate_key directives.\nExample # Problem: SSL handshake failure. Solution: server { listen 443 ssl; server_name example.com; ssl_certificate /path/to/certificate.crt; ssl_certificate_key /path/to/private.key; ... } Incorrect Permission Settings #Running Nginx with inappropriate user permissions, particularly as the root user, poses a significant security risk.\nSolution #Run Nginx as a non-root, low-privilege user. This limits the potential damage in case of a security breach.\nInadequate Buffer Sizes #Small buffer sizes can lead to poor performance and increased disk I/O, whereas large buffer sizes can cause resource wastage and even crash under heavy load.\nSolution #Tune buffer sizes (e.g., client_body_buffer_size, , proxy_buffer_size, client_header_buffer_size) based on your server\u0026rsquo;s workload and memory availability.\nExample: # Problem: Slow response times for dynamic content. Solution: client_body_buffer_size 10K; client_max_body_size 8m; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; Inappropriate Timeouts #Incorrectly setting timeout directives can lead to dropped connections or allow slow denial-of-service (DoS) attacks.\nSolution #Configure client_body_timeout, client_header_timeout, and keepalive_timeout appropriately to balance between usability and security.\nExample # Problem: Connections dropping unexpectedly. Solution: keepalive_timeout 65; client_body_timeout 12; send_timeout 10; Misconfigured Location Blocks #Incorrectly ordering or defining location blocks can lead to unexpected behavior and security issues.\nSolution #Understand the order in which Nginx processes location blocks (e.g., the first regular expression match, longest prefix match). Test configurations thoroughly before deployment.\nMissing or Inefficient Rate Limiting #Lack of rate limiting can make your server vulnerable to DOS attack, brute-force attacks and / or spam.\nSolution #Use the limit_req module to implement rate limiting and control access based on IP addresses or other criteria.\nExample # Problem: Website experiencing frequent brute-force attacks. Solution: http { limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s; server { ... location /login/ { limit_req zone=mylimit burst=20 nodelay; } } } Missing Access or Error Logs #Logs are not properly configured, making troubleshooting difficult.\nSolution #Ensure that access and error logs are correctly configured in the Nginx config file.\nExample # Problem: No logs are generated for a site. Solution: server { ... access_log /var/log/nginx/example_access.log; error_log /var/log/nginx/example_error.log; ... } Ignoring Server Logs #Not monitoring server logs can lead to missed opportunities in identifying and addressing performance or security issues.\nSolution #Regularly monitor and analyze access and error logs. Consider using automated tools for log analysis.\nPoor Reverse Proxy Configurations #Incorrectly configuring Nginx as a reverse proxy can lead to header manipulation vulnerabilities, exposing backend servers to attacks.\nSolution #Validate and sanitize headers and content passed to backend servers. Ensure secure communication between Nginx and the backend.\nNeglecting HTTP2 and Server Push #Not leveraging HTTP2 and its server push feature, when appropriate, can result in suboptimal performance.\nSolution #Enable HTTP2 to improve latency and server push for faster loading times, but be aware of browser compatibility.\nIncorrect File Permissions #The Nginx user does not have the proper permissions to access the website\u0026rsquo;s files and directories.\nSolution #Adjust the file and directory permissions so that the Nginx user can read (and, if necessary, write) them.\nExample # Problem: 403 Forbidden error. Solution: Use chown and chmod to change the ownership and permissions. E.g., sudo chown -R nginx:nginx /var/www/html and sudo chmod -R 755 /var/www/html. Poorly Configured Server Blocks #Incorrect setup of server blocks (also known as virtual hosts) can lead to server errors or wrong content being served.\nSolution #Ensure server blocks are correctly defined, with proper server_name, listen, and root directives.\nExample # Problem: Default page is served instead of the specific site. Solution: Correct the server block: server { listen 80; server_name example.com www.example.com; root /var/www/example; ... } Inefficient Caching #Lack of proper caching mechanisms leading to slower performance.\nSolution #Configure caching settings appropriately in Nginx configuration.\nExample # Problem: Static content loads slowly. Solution: location ~* \\.(jpg|jpeg|png|gif|ico|css|js)$ { expires 30d; add_header Cache-Control \u0026#34;public, no-transform\u0026#34;; } Incorrect Rewrite Rules #Rewrite rules that do not work as intended, causing URL errors.\nSolution #Review and correct the rewrite directives in the Nginx configuration.\nExample # Problem: Permalinks not working in a WordPress installation. Solution: location / { try_files $uri $uri/ /index.php?$args; } Client Max Body Size Too Low #The client_max_body_size directive is set too low, leading to issues with uploading large files.\nSolution #Increase the client_max_body_size value in the Nginx configuration.\nExample # Problem: 413 Request Entity Too Large error when uploading files. Solution: Add client_max_body_size 100M; in the http, server, or location context. Incorrect FastCGI Parameters #Improper FastCGI parameters can lead to poor performance or errors in PHP applications.\nSolution #Configure the fastcgi_param directives correctly in the Nginx configuration.\nExample # Problem: PHP scripts not executing properly. Solution: location ~ \\.php$ { fastcgi_pass unix:/var/run/php/php-fpm.sock; fastcgi_index index.php; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; } Inadequate Worker Processes and Connections #Setting too few worker processes or worker connections, resulting in suboptimal performance.\nSolution #Adjust worker_processes and worker_connections based on the server\u0026rsquo;s hardware and workload.\nExample # Problem: Server unable to handle high traffic effectively. Solution: worker_processes auto; # Adjust based on CPU cores events { worker_connections 1024; # Adjust based on expected load } Misconfigured Gzip Compression #Gzip compression not properly set up or overly aggressive, affecting performance or security.\nSolution #Fine-tune the Gzip settings in the Nginx configuration.\nExample # Problem: Text-based resources are not compressed. Solution: gzip on; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; gzip_proxied any; Incorrect MIME Type Handling #MIME types are not correctly defined, causing files to be served or interpreted improperly.\nSolution #Define the correct MIME types in the Nginx configuration.\nExample # Problem: CSS files are not being loaded properly. Solution: http { include /etc/nginx/mime.types; default_type application/octet-stream; ... } Improper Load Balancing Configuration #Load balancing setup is inefficient or incorrectly configured.\nSolution #Configure the upstream directive properly for load balancing.\nExample # Problem: Load not properly distributed among backend servers. Solution: upstream backend { server backend1.example.com; server backend2.example.com; ... } server { location / { proxy_pass http://backend; } } While Nginx is a robust and efficient web server, its full potential is realized only when it\u0026rsquo;s configured correctly. By avoiding these common misconfigurations and adhering to best practices, you can ensure that your Nginx server is secure, stable, and performs at its best.\n","date":"1 January 0001","permalink":"/posts/nginx/common-issues-and-misconfigurations/","section":"Posts","summary":"Nginx is a popular web server known for its performance, stability, and rich feature set.","title":"Common Nginx Issues and Misconfigurations"},{"content":"","date":null,"permalink":"/tags/composer/","section":"Tags","summary":"","title":"Composer"},{"content":"Install #sudo apt install mariadb-server sudo mysql_secure_installation Create database and user #sudo mysql create database my_database; GRANT ALL PRIVILEGES ON my_database.* TO \u0026#39;my_user\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;my_password\u0026#39; WITH GRANT OPTION; flush privileges; ","date":"1 January 0001","permalink":"/posts/mariadb/setup/","section":"Posts","summary":"Install #sudo apt install mariadb-server sudo mysql_secure_installation Create database and user #sudo mysql create database my_database; GRANT ALL PRIVILEGES ON my_database.","title":"Create a database in MariaDB"},{"content":"RAID (Redundant Array of Inexpensive Disks) is a data storage virtualization technology that combines multiple physical disk drive components into one or more logical units for the purposes of data redundancy, performance improvement, or both.\nI create the raid on partitions instead of on disks. Here is why: https://unix.stackexchange.com/questions/320103/whats-the-difference-between-creating-mdadm-array-using-partitions-or-the-whole.\nThe following commands are ran as `root`, therefore `sudo` is omitted. fdisk #The type of the partitions will be Linux RAID (code 29 on GPT).\nCreate the partitions with fdisk:\nfdisk /dev/sda Welcome to fdisk (util-linux 2.36.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): g Created a new GPT disklabel (GUID: ...). Command (m for help): n Partition number (1-128, default 1): First sector (2048-976773134, default 2048): Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-976773134, default 976773134): Created a new partition 1 of type \u0026#39;Linux filesystem\u0026#39; and of size 465,8 GiB. Command (m for help): t Selected partition 1 Partition type or alias (type L to list all): 29 Changed type of partition \u0026#39;Linux filesystem\u0026#39; to \u0026#39;Linux RAID\u0026#39;. Command (m for help): w The partition table has been altered. Syncing disks. fdisk /dev/sdb Welcome to fdisk (util-linux 2.36.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): g Created a new GPT disklabel (GUID: 75F9C784-617F-0149-8227-7615469591AF). Command (m for help): n Partition number (1-128, default 1): First sector (2048-976773134, default 2048): Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-976773134, default 976773134): Created a new partition 1 of type \u0026#39;Linux filesystem\u0026#39; and of size 465,8 GiB. Command (m for help): t Selected partition 1 Partition type or alias (type L to list all): 29 Changed type of partition \u0026#39;Linux filesystem\u0026#39; to \u0026#39;Linux RAID\u0026#39;. Command (m for help): w The partition table has been altered. Syncing disks. Or a use these simple oneliners:\necho -e -n \u0026#34;g\\nn\\n\\n\\n\\nt\\n29\\nw\\n\u0026#34; | fdisk /dev/sda echo -e -n \u0026#34;g\\nn\\n\\n\\n\\nt\\n29\\nw\\n\u0026#34; | fdisk /dev/sdb mdadm #Create the RAID 0:\nmdadm --create /dev/md0 --level=0 --raid-devices=2 /dev/sda1 /dev/sdb1 Check the raid device:\ncat /proc/mdstat Personalities : [raid0] [linear] [multipath] [raid1] [raid6] [raid5] [raid4] [raid10] md0 : active raid0 sdb1[1] sda1[0] 976506880 blocks super 1.2 512k chunks unused devices: \u0026lt;none\u0026gt; Save the array:\nmdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf update-initramfs -u mkfs #Create the filesystem on the new raid device:\nmkfs.ext4 /dev/md0 fstab #To auto mount at boot, edit /etc/fstab:\necho \u0026#34;/dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0\u0026#34; \u0026gt;\u0026gt; /etc/fstab ","date":"1 January 0001","permalink":"/posts/mdadm/raid0/","section":"Posts","summary":"RAID (Redundant Array of Inexpensive Disks) is a data storage virtualization technology that combines multiple physical disk drive components into one or more logical units for the purposes of data redundancy, performance improvement, or both.","title":"Create RAID0 with mdadm"},{"content":"","date":null,"permalink":"/tags/daemon/","section":"Tags","summary":"","title":"Daemon"},{"content":"","date":null,"permalink":"/tags/database/","section":"Tags","summary":"","title":"Database"},{"content":"","date":null,"permalink":"/tags/db/","section":"Tags","summary":"","title":"Db"},{"content":"","date":null,"permalink":"/categories/debian/","section":"Categories","summary":"","title":"Debian"},{"content":"Create a self-sgined certificate #openssl req -x509 -nodes -newkey rsa:4096 -keyout /etc/ssl/private/nginx-key.pem -out /etc/ssl/private/nginx-cert.pem -days 1825 nginx #server { listen [::]:443 ssl http2; listen 443 ssl http2; server_name _; ssl_certificate /etc/ssl/private/nginx-cert.pem; ssl_certificate_key /etc/ssl/private/nginx-key.pem; return 444; } server { listen 80; listen [::]:80; server_name _; return 444; } Reload nginx:\nsystemctl reload nginx.service ","date":"1 January 0001","permalink":"/posts/nginx/default-server/","section":"Posts","summary":"Create a self-sgined certificate #openssl req -x509 -nodes -newkey rsa:4096 -keyout /etc/ssl/private/nginx-key.","title":"Default Server Settings for Nginx"},{"content":"","date":null,"permalink":"/tags/dns/","section":"Tags","summary":"","title":"Dns"},{"content":"","date":null,"permalink":"/categories/dns/","section":"Categories","summary":"","title":"Dns"},{"content":"","date":null,"permalink":"/tags/domain/","section":"Tags","summary":"","title":"Domain"},{"content":"","date":null,"permalink":"/categories/domain/","section":"Categories","summary":"","title":"Domain"},{"content":"This RFC describes the details of the domain system and protocol, and assumes that the reader is familiar with the concepts discussed in a companion RFC, \u0026ldquo;Domain Names - Concepts and Facilities\u0026rdquo; [RFC-1034].\nThe domain system is a mixture of functions and data types which are an official protocol and functions and data types which are still experimental. Since the domain system is intentionally extensible, new data types and experimental behavior should always be expected in parts of the system beyond the official protocol. The official protocol parts include standard queries, responses and the Internet class RR data formats (e.g., host addresses). Since the previous RFC set, several definitions have changed, so some previous definitions are obsolete.\nExperimental or obsolete features are clearly marked in these RFCs, and such information should be used with caution.\nThe reader is especially cautioned not to depend on the values which appear in examples to be current or complete, since their purpose is primarily pedagogical. Distribution of this memo is unlimited.\n2. INTRODUCTION #2.1. Overview #The goal of domain names is to provide a mechanism for naming resources in such a way that the names are usable in different hosts, networks, protocol families, internets, and administrative organizations.\nFrom the user\u0026rsquo;s point of view, domain names are useful as arguments to a local agent, called a resolver, which retrieves information associated with the domain name. Thus a user might ask for the host address or mail information associated with a particular domain name. To enable the user to request a particular type of information, an appropriate query type is passed to the resolver with the domain name. To the user, the domain tree is a single information space; the resolver is responsible for hiding the distribution of data among name servers from the user.\nFrom the resolver\u0026rsquo;s point of view, the database that makes up the domain space is distributed among various name servers. Different parts of the domain space are stored in different name servers, although a particular data item will be stored redundantly in two or more name servers. The resolver starts with knowledge of at least one name server. When the resolver processes a user query it asks a known name server for the information; in return, the resolver either receives the desired information or a referral to another name server. Using these referrals, resolvers learn the identities and contents of other name servers. Resolvers are responsible for dealing with the distribution of the domain space and dealing with the effects of name server failure by consulting redundant databases in other servers.\nName servers manage two kinds of data. The first kind of data held in sets called zones; each zone is the complete database for a particular \u0026ldquo;pruned\u0026rdquo; subtree of the domain space. This data is called authoritative. A name server periodically checks to make sure that its zones are up to date, and if not, obtains a new copy of updated zones from master files stored locally or in another name server. The second kind of data is cached data which was acquired by a local resolver. This data may be incomplete, but improves the performance of the retrieval process when non-local data is repeatedly accessed. Cached data is eventually discarded by a timeout mechanism.\nThis functional structure isolates the problems of user interface, failure recovery, and distribution in the resolvers and isolates the database update and refresh problems in the name servers.\n2.2. Common configurations #A host can participate in the domain name system in a number of ways, depending on whether the host runs programs that retrieve information from the domain system, name servers that answer queries from other hosts, or various combinations of both functions. The simplest, and perhaps most typical, configuration is shown below:\nLocal Host | Foreign | +---------+ +----------+ | +--------+ | | user queries | |queries | | | | User |--------------\u0026gt;| |---------|-\u0026gt;|Foreign | | Program | | Resolver | | | Name | | |\u0026lt;--------------| |\u0026lt;--------|--| Server | | | user responses| |responses| | | +---------+ +----------+ | +--------+ | A | cache additions | | references | V | | +----------+ | | cache | | +----------+ | User programs interact with the domain name space through resolvers; the format of user queries and user responses is specific to the host and its operating system. User queries will typically be operating system calls, and the resolver and its cache will be part of the host operating system. Less capable hosts may choose to implement the resolver as a subroutine to be linked in with every program that needs its services. Resolvers answer user queries with information they acquire via queries to foreign name servers and the local cache.\nNote that the resolver may have to make several queries to several different foreign name servers to answer a particular user query, and hence the resolution of a user query may involve several network accesses and an arbitrary amount of time. The queries to foreign name servers and the corresponding responses have a standard format described in this memo, and may be datagrams.\nDepending on its capabilities, a name server could be a stand alone program on a dedicated machine or a process or processes on a large timeshared host. A simple configuration might be:\nLocal Host | Foreign | +---------+ | / /| | +---------+ | +----------+ | +--------+ | | | | |responses| | | | | | | Name |---------|-\u0026gt;|Foreign | | Master |--------------\u0026gt;| Server | | |Resolver| | files | | | |\u0026lt;--------|--| | | |/ | | queries | +--------+ +---------+ +----------+ | Here a primary name server acquires information about one or more zones by reading master files from its local file system, and answers queries about those zones that arrive from foreign resolvers.\nThe DNS requires that all zones be redundantly supported by more than one name server. Designated secondary servers can acquire zones and check for updates from the primary server using the zone transfer protocol of the DNS. This configuration is shown below:\nLocal Host | Foreign | +---------+ | / /| | +---------+ | +----------+ | +--------+ | | | | |responses| | | | | | | Name |---------|-\u0026gt;|Foreign | | Master |--------------\u0026gt;| Server | | |Resolver| | files | | | |\u0026lt;--------|--| | | |/ | | queries | +--------+ +---------+ +----------+ | A |maintenance | +--------+ | +------------|-\u0026gt;| | | queries | |Foreign | | | | Name | +------------------|--| Server | maintenance responses | +--------+ In this configuration, the name server periodically establishes a virtual circuit to a foreign name server to acquire a copy of a zone or to check that an existing copy has not changed. The messages sent for these maintenance activities follow the same form as queries and responses, but the message sequences are somewhat different.\nThe information flow in a host that supports all aspects of the domain name system is shown below:\nLocal Host | Foreign | +---------+ +----------+ | +--------+ | | user queries | |queries | | | | User |--------------\u0026gt;| |---------|-\u0026gt;|Foreign | | Program | | Resolver | | | Name | | |\u0026lt;--------------| |\u0026lt;--------|--| Server | | | user responses| |responses| | | +---------+ +----------+ | +--------+ | A | cache additions | | references | V | | +----------+ | | Shared | | | database | | +----------+ | A | | +---------+ refreshes | | references | / /| | V | +---------+ | +----------+ | +--------+ | | | | |responses| | | | | | | Name |---------|-\u0026gt;|Foreign | | Master |--------------\u0026gt;| Server | | |Resolver| | files | | | |\u0026lt;--------|--| | | |/ | | queries | +--------+ +---------+ +----------+ | A |maintenance | +--------+ | +------------|-\u0026gt;| | | queries | |Foreign | | | | Name | +------------------|--| Server | maintenance responses | +--------+ The shared database holds domain space data for the local name server and resolver. The contents of the shared database will typically be a mixture of authoritative data maintained by the periodic refresh operations of the name server and cached data from previous resolver requests. The structure of the domain data and the necessity for synchronization between name servers and resolvers imply the general characteristics of this database, but the actual format is up to the local implementor.\nInformation flow can also be tailored so that a group of hosts act together to optimize activities. Sometimes this is done to offload less capable hosts so that they do not have to implement a full resolver. This can be appropriate for PCs or hosts which want to minimize the amount of new network code which is required. This scheme can also allow a group of hosts can share a small number of caches rather than maintaining a large number of separate caches, on the premise that the centralized caches will have a higher hit ratio. In either case, resolvers are replaced with stub resolvers which act as front ends to resolvers located in a recursive server in one or more name servers known to perform that service:\nLocal Hosts | Foreign | +---------+ | | | responses | | Stub |\u0026lt;--------------------+ | | Resolver| | | | |----------------+ | | +---------+ recursive | | | queries | | | V | | +---------+ recursive +----------+ | +--------+ | | queries | |queries | | | | Stub |--------------\u0026gt;| Recursive|---------|-\u0026gt;|Foreign | | Resolver| | Server | | | Name | | |\u0026lt;--------------| |\u0026lt;--------|--| Server | +---------+ responses | |responses| | | +----------+ | +--------+ | Central | | | cache | | +----------+ | In any case, note that domain components are always replicated for reliability whenever possible.\n2.3. Conventions #The domain system has several conventions dealing with low-level, but fundamental, issues. While the implementor is free to violate these conventions WITHIN HIS OWN SYSTEM, he must observe these conventions in ALL behavior observed from other hosts.\n2.3.1. Preferred name syntax #The DNS specifications attempt to be as general as possible in the rules for constructing domain names. The idea is that the name of any existing object can be expressed as a domain name with minimal changes.\nHowever, when assigning a domain name for an object, the prudent user will select a name which satisfies both the rules of the domain system and any existing rules for the object, whether these rules are published or implied by existing programs.\nFor example, when naming a mail domain, the user should satisfy both the rules of this memo and those in RFC-822. When creating a new host name, the old rules for HOSTS.TXT should be followed. This avoids problems when old software is converted to use domain names.\nThe following syntax will result in fewer problems with many\napplications that use domain names (e.g., mail, TELNET).\n\u0026lt;domain\u0026gt; ::= \u0026lt;subdomain\u0026gt; | \u0026#34; \u0026#34; \u0026lt;subdomain\u0026gt; ::= \u0026lt;label\u0026gt; | \u0026lt;subdomain\u0026gt; \u0026#34;.\u0026#34; \u0026lt;label\u0026gt; \u0026lt;label\u0026gt; ::= \u0026lt;letter\u0026gt; [ [ \u0026lt;ldh-str\u0026gt; ] \u0026lt;let-dig\u0026gt; ] \u0026lt;ldh-str\u0026gt; ::= \u0026lt;let-dig-hyp\u0026gt; | \u0026lt;let-dig-hyp\u0026gt; \u0026lt;ldh-str\u0026gt; \u0026lt;let-dig-hyp\u0026gt; ::= \u0026lt;let-dig\u0026gt; | \u0026#34;-\u0026#34; \u0026lt;let-dig\u0026gt; ::= \u0026lt;letter\u0026gt; | \u0026lt;digit\u0026gt; \u0026lt;letter\u0026gt; ::= any one of the 52 alphabetic characters A through Z in upper case and a through z in lower case \u0026lt;digit\u0026gt; ::= any one of the ten digits 0 through 9 Note that while upper and lower case letters are allowed in domain names, no significance is attached to the case. That is, two names with the same spelling but different case are to be treated as if identical.\nThe labels must follow the rules for ARPANET host names. They must start with a letter, end with a letter or digit, and have as interior characters only letters, digits, and hyphen. There are also some restrictions on the length. Labels must be 63 characters or less.\nFor example, the following strings identify hosts in the Internet:\nA.ISI.EDU XX.LCS.MIT.EDU SRI-NIC.ARPA 2.3.2. Data Transmission Order #The order of transmission of the header and data described in this document is resolved to the octet level. Whenever a diagram shows a group of octets, the order of transmission of those octets is the normal order in which they are read in English. For example, in the following diagram, the octets are transmitted in the order they are numbered.\n0 1 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | 1 | 2 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | 3 | 4 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | 5 | 6 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Whenever an octet represents a numeric quantity, the left most bit in the diagram is the high order or most significant bit. That is, the bit labeled 0 is the most significant bit. For example, the following diagram represents the value 170 (decimal).\n0 1 2 3 4 5 6 7 +-+-+-+-+-+-+-+-+ |1 0 1 0 1 0 1 0| +-+-+-+-+-+-+-+-+ Similarly, whenever a multi-octet field represents a numeric quantity the left most bit of the whole field is the most significant bit. When a multi-octet quantity is transmitted the most significant octet is transmitted first.\n2.3.3. Character Case #For all parts of the DNS that are part of the official protocol, all comparisons between character strings (e.g., labels, domain names, etc.) are done in a case-insensitive manner. At present, this rule is in force throughout the domain system without exception. However, future additions beyond current usage may need to use the full binary octet capabilities in names, so attempts to store domain names in 7-bit ASCII or use of special bytes to terminate labels, etc., should be avoided.\nWhen data enters the domain system, its original case should be preserved whenever possible. In certain circumstances this cannot be done. For example, if two RRs are stored in a database, one at x.y and one at X.Y, they are actually stored at the same place in the database, and hence only one casing would be preserved. The basic rule is that case can be discarded only when data is used to define structure in a database, and two names are identical when compared in a case insensitive manner.\nLoss of case sensitive data must be minimized. Thus while data for x.y and X.Y may both be stored under a single location x.y or X.Y, data for a.x and B.X would never be stored under A.x, A.X, b.x, or b.X. In general, this preserves the case of the first label of a domain name, but forces standardization of interior node labels.\nSystems administrators who enter data into the domain database should take care to represent the data they supply to the domain system in a case-consistent manner if their system is case-sensitive. The data distribution system in the domain system will ensure that consistent representations are preserved.\n2.3.4. Size limits #Various objects and parameters in the DNS have size limits. They are listed below. Some could be easily changed, others are more fundamental.\nlabels 63 octets or less\nnames 255 octets or less\nTTL positive values of a signed 32 bit number.\nUDP messages 512 octets or less\n3. DOMAIN NAME SPACE AND RR DEFINITIONS #3.1. Name space definitions #Domain names in messages are expressed in terms of a sequence of labels. Each label is represented as a one octet length field followed by that number of octets. Since every domain name ends with the null label of the root, a domain name is terminated by a length byte of zero. The high order two bits of every length octet must be zero, and the remaining six bits of the length field limit the label to 63 octets or less.\nTo simplify implementations, the total length of a domain name (i.e., label octets and label length octets) is restricted to 255 octets or less.\nAlthough labels can contain any 8 bit values in octets that make up a label, it is strongly recommended that labels follow the preferred syntax described elsewhere in this memo, which is compatible with existing host naming conventions. Name servers and resolvers must compare labels in a case-insensitive manner (i.e., A=a), assuming ASCII with zero parity. Non-alphabetic codes must match exactly.\n3.2. RR definitions #3.2.1. Format #All RRs have the same top level format shown below:\n1 1 1 1 1 1 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | | / / / NAME / | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | TYPE | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | CLASS | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | TTL | | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | RDLENGTH | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--| / RDATA / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nNAME an owner name, i.e., the name of the node to which this resource record pertains.\nTYPE two octets containing one of the RR TYPE codes.\nCLASS two octets containing one of the RR CLASS codes.\nTTL a 32 bit signed integer that specifies the time interval that the resource record may be cached before the source of the information should again be consulted. Zero values are interpreted to mean that the RR can only be used for the transaction in progress, and should not be cached. For example, SOA records are always distributed with a zero TTL to prohibit caching. Zero values can also be used for extremely volatile data.\nRDLENGTH an unsigned 16 bit integer that specifies the length in octets of the RDATA field.\nRDATA a variable length string of octets that describes the resource. The format of this information varies according to the TYPE and CLASS of the resource record.\n3.2.2. TYPE values #TYPE fields are used in resource records. Note that these types are a subset of QTYPEs.\nType Value Meaning A 1 A host address NS 2 An authoritative name server MD 3 A mail destination (Obsolete - use MX) MF 4 A mail forwarder (Obsolete - use MX) CNAME 5 The canonical name for an alias SOA 6 Marks the start of a zone of authority MB 7 A mailbox domain name (EXPERIMENTAL) MG 8 A mail group member (EXPERIMENTAL) MR 9 A mail rename domain name (EXPERIMENTAL) NULL 10 A null RR (EXPERIMENTAL) WKS 11 A well known service description PTR 12 A domain name pointer HINFO 13 host information MINFO 14 mailbox or mail list information MX 15 mail exchange TXT 16 text strings 3.2.3. QTYPE values #QTYPE fields appear in the question part of a query. QTYPES are a superset of TYPEs, hence all TYPEs are valid QTYPEs. In addition, the following QTYPEs are defined:\nType Value Meaning AXFR 252 A request for a transfer of an entire zone MAILB 253 A request for mailbox-related records (MB, MG or MR) MAILA 254 A request for mail agent RRs (Obsolete - see MX) * 255 A request for all records 3.2.4. CLASS values #CLASS fields appear in resource records. The following CLASS mnemonics and values are defined:\nType Value Meaning IN 1 The Internet CS 2 The CSNET class (Obsolete - used only for examples in some obsolete RFCs) CH 3 The CHAOS class HS 4 Hesiod [Dyer 87] 3.2.5. QCLASS values #QCLASS fields appear in the question section of a query. QCLASS values are a superset of CLASS values; every CLASS is a valid QCLASS. In addition to CLASS values, the following QCLASSes are defined:\nType Value Meaning * 255 Any class 3.3. Standard RRs #The following RR definitions are expected to occur, at least potentially, in all classes. In particular, NS, SOA, CNAME, and PTR will be used in all classes, and have the same format in all classes. Because their RDATA format is known, all domain names in the RDATA section of these RRs may be compressed.\n\u0026lt;domain-name\u0026gt; is a domain name represented as a series of labels, and terminated by a label with zero length. \u0026lt;character-string\u0026gt; is a single length octet followed by that number of characters. \u0026lt;character-string\u0026gt; is treated as binary information, and can be up to 256 characters in length (including the length octet).\n3.3.1. CNAME RDATA format # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / CNAME / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nCNAME: A \u0026lt;domain-name\u0026gt; which specifies the canonical or primary name for the owner. The owner name is an alias. CNAME RRs cause no additional section processing, but name servers may choose to restart the query at the canonical name in certain cases. See the description of name server logic in [RFC-1034] for details.\n3.3.2. HINFO RDATA format # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / CPU / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / OS / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nCPU: A \u0026lt;character-string\u0026gt; which specifies the CPU type. OS: A \u0026lt;character-string\u0026gt; which specifies the operating system type. Standard values for CPU and OS can be found in [RFC-1010].\nHINFO records are used to acquire general information about a host. The main use is for protocols such as FTP that can use special procedures when talking between machines or operating systems of the same type.\n3.3.3. MB RDATA format (EXPERIMENTAL) # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / MADNAME / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nMADNAME: A \u0026lt;domain-name\u0026gt; which specifies a host which has the specified mailbox. MB records cause additional section processing which looks up an A type RRs corresponding to MADNAME.\n3.3.4. MD RDATA format (Obsolete) # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / MADNAME / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nMADNAME A \u0026lt;domain-name\u0026gt; which specifies a host which has a mail agent for the domain which should be able to deliver mail for the domain.\nMD records cause additional section processing which looks up an A type record corresponding to MADNAME.\nMD is obsolete. See the definition of MX and [RFC-974] for details of the new scheme. The recommended policy for dealing with MD RRs found in a master file is to reject them, or to convert them to MX RRs with a preference of 0.\n3.3.5. MF RDATA format (Obsolete) # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / MADNAME / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nMADNAME A \u0026lt;domain-name\u0026gt; which specifies a host which has a mail agent for the domain which will accept mail for forwarding to the domain.\nMF records cause additional section processing which looks up an A type record corresponding to MADNAME.\nMF is obsolete. See the definition of MX and [RFC-974] for details ofw the new scheme. The recommended policy for dealing with MD RRs found in a master file is to reject them, or to convert them to MX RRs with a preference of 10.\n3.3.6. MG RDATA format (EXPERIMENTAL) # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / MGMNAME / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nMGMNAME A \u0026lt;domain-name\u0026gt; which specifies a mailbox which is a member of the mail group specified by the domain name.\nMG records cause no additional section processing.\n3.3.7. MINFO RDATA format (EXPERIMENTAL) # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / RMAILBX / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / EMAILBX / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nRMAILBX A \u0026lt;domain-name\u0026gt; which specifies a mailbox which is responsible for the mailing list or mailbox. If this domain name names the root, the owner of the MINFO RR is responsible for itself. Note that many existing mailing lists use a mailbox X-request for the RMAILBX field of mailing list X, e.g., Msgroup-request for Msgroup. This field provides a more general mechanism.\nEMAILBX A \u0026lt;domain-name\u0026gt; which specifies a mailbox which is to receive error messages related to the mailing list or mailbox specified by the owner of the MINFO RR (similar to the ERRORS-TO: field which has been proposed). If this domain name names the root, errors should be returned to the sender of the message.\nMINFO records cause no additional section processing. Although these records can be associated with a simple mailbox, they are usually used with a mailing list.\n3.3.8. MR RDATA format (EXPERIMENTAL) # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / NEWNAME / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nNEWNAME A \u0026lt;domain-name\u0026gt; which specifies a mailbox which is the proper rename of the specified mailbox.\nMR records cause no additional section processing. The main use for MR is as a forwarding entry for a user who has moved to a different mailbox.\n3.3.9. MX RDATA format # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | PREFERENCE | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / EXCHANGE / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nPREFERENCE A 16 bit integer which specifies the preference given to this RR among others at the same owner. Lower values are preferred.\nEXCHANGE A \u0026lt;domain-name\u0026gt; which specifies a host willing to act as a mail exchange for the owner name.\nMX records cause type A additional section processing for the host specified by EXCHANGE. The use of MX RRs is explained in detail in [RFC-974].\n3.3.10. NULL RDATA format (EXPERIMENTAL) # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / \u0026lt;anything\u0026gt; / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ Anything at all may be in the RDATA field so long as it is 65535 octets or less.\nNULL records cause no additional section processing. NULL RRs are not allowed in master files. NULLs are used as placeholders in some experimental extensions of the DNS.\n3.3.11. NS RDATA format # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / NSDNAME / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nNSDNAME A \u0026lt;domain-name\u0026gt; which specifies a host which should be authoritative for the specified class and domain.\nNS records cause both the usual additional section processing to locate a type A record, and, when used in a referral, a special search of the zone in which they reside for glue information.\nThe NS RR states that the named host should be expected to have a zone starting at owner name of the specified class. Note that the class may not indicate the protocol family which should be used to communicate with the host, although it is typically a strong hint. For example, hosts which are name servers for either Internet (IN) or Hesiod (HS) class information are normally queried using IN class protocols.\n3.3.12. PTR RDATA format # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / PTRDNAME / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nPTRDNAME A \u0026lt;domain-name\u0026gt; which points to some location in the domain name space.\nPTR records cause no additional section processing. These RRs are used in special domains to point to some other location in the domain space. These records are simple data, and don\u0026rsquo;t imply any special processing similar to that performed by CNAME, which identifies aliases. See the description of the IN-ADDR.ARPA domain for an example.\n3.3.13. SOA RDATA format # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / MNAME / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / RNAME / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | SERIAL | | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | REFRESH | | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | RETRY | | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | EXPIRE | | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | MINIMUM | | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nMNAME The \u0026lt;domain-name\u0026gt; of the name server that was the original or primary source of data for this zone.\nRNAME A \u0026lt;domain-name\u0026gt; which specifies the mailbox of the person responsible for this zone.\nSERIAL The unsigned 32 bit version number of the original copy of the zone. Zone transfers preserve this value. This value wraps and should be compared using sequence space arithmetic.\nREFRESH A 32 bit time interval before the zone should be refreshed.\nRETRY A 32 bit time interval that should elapse before a failed refresh should be retried.\nEXPIRE A 32 bit time value that specifies the upper limit on the time interval that can elapse before the zone is no longer authoritative.\nMINIMUM The unsigned 32 bit minimum TTL field that should be exported with any RR from this zone.\nSOA records cause no additional section processing.\nAll times are in units of seconds.\nMost of these fields are pertinent only for name server maintenance operations. However, MINIMUM is used in all query operations that retrieve RRs from a zone. Whenever a RR is sent in a response to a query, the TTL field is set to the maximum of the TTL field from the RR and the MINIMUM field in the appropriate SOA. Thus MINIMUM is a lower bound on the TTL field for all RRs in a zone. Note that this use of MINIMUM should occur when the RRs are copied into the response and not when the zone is loaded from a master file or via a zone transfer. The reason for this provison is to allow future dynamic update facilities to change the SOA RR with known semantics.\n3.3.14. TXT RDATA format # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ / TXT-DATA / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nTXT-DATA One or more \u0026lt;character-string\u0026gt;s.\nTXT RRs are used to hold descriptive text. The semantics of the text depends on the domain where it is found.\n3.4. Internet specific RRs #3.4.1. A RDATA format # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | ADDRESS | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nADDRESS A 32 bit Internet address.\nHosts that have multiple Internet addresses will have multiple A records.\nA records cause no additional section processing. The RDATA section of an A line in a master file is an Internet address expressed as four decimal numbers separated by dots without any imbedded spaces (e.g., \u0026ldquo;10.2.0.52\u0026rdquo; or \u0026ldquo;192.0.5.6\u0026rdquo;).\n3.4.2. WKS RDATA format # +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | ADDRESS | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | PROTOCOL | | +--+--+--+--+--+--+--+--+ | | | / BIT MAP / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nADDRESS An 32 bit Internet address\nPROTOCOL An 8 bit IP protocol number\nBIT MAP A variable length bit map. The bit map must be a multiple of 8 bits long.\nThe WKS record is used to describe the well known services supported by a particular protocol on a particular internet address. The PROTOCOL field specifies an IP protocol number, and the bit map has one bit per port of the specified protocol. The first bit corresponds to port 0, the second to port 1, etc. If the bit map does not include a bit for a protocol of interest, that bit is assumed zero. The appropriate values and mnemonics for ports and protocols are specified in [RFC-1010].\nFor example, if PROTOCOL=TCP (6), the 26th bit corresponds to TCP port 25 (SMTP). If this bit is set, a SMTP server should be listening on TCP port 25; if zero, SMTP service is not supported on the specified address.\nThe purpose of WKS RRs is to provide availability information for servers for TCP and UDP. If a server supports both TCP and UDP, or has multiple Internet addresses, then multiple WKS RRs are used.\nWKS RRs cause no additional section processing.\nIn master files, both ports and protocols are expressed using mnemonics or decimal numbers.\n3.5. IN-ADDR.ARPA domain #The Internet uses a special domain to support gateway location and Internet address to host mapping. Other classes may employ a similar strategy in other domains. The intent of this domain is to provide a guaranteed method to perform host address to host name mapping, and to facilitate queries to locate all gateways on a particular network in the Internet.\nNote that both of these services are similar to functions that could be performed by inverse queries; the difference is that this part of the domain name space is structured according to address, and hence can guarantee that the appropriate data can be located without an exhaustive search of the domain space.\nThe domain begins at IN-ADDR.ARPA and has a substructure which follows the Internet addressing structure.\nDomain names in the IN-ADDR.ARPA domain are defined to have up to four labels in addition to the IN-ADDR.ARPA suffix. Each label represents one octet of an Internet address, and is expressed as a character string for a decimal value in the range 0-255 (with leading zeros omitted except in the case of a zero octet which is represented by a single zero).\nHost addresses are represented by domain names that have all four labels specified. Thus data for Internet address 10.2.0.52 is located at domain name 52.0.2.10.IN-ADDR.ARPA. The reversal, though awkward to read, allows zones to be delegated which are exactly one network of address space. For example, 10.IN-ADDR.ARPA can be a zone containing data for the ARPANET, while 26.IN-ADDR.ARPA can be a separate zone for MILNET. Address nodes are used to hold pointers to primary host names in the normal domain space.\nNetwork numbers correspond to some non-terminal nodes at various depths in the IN-ADDR.ARPA domain, since Internet network numbers are either 1, 2, or 3 octets. Network nodes are used to hold pointers to the primary host names of gateways attached to that network. Since a gateway is, by definition, on more than one network, it will typically have two or more network nodes which point at it. Gateways will also have host level pointers at their fully qualified addresses.\nBoth the gateway pointers at network nodes and the normal host pointers at full address nodes use the PTR RR to point back to the primary domain names of the corresponding hosts.\nFor example, the IN-ADDR.ARPA domain will contain information about the ISI gateway between net 10 and 26, an MIT gateway from net 10 to MIT\u0026rsquo;s net 18, and hosts A.ISI.EDU and MULTICS.MIT.EDU. Assuming that ISI gateway has addresses 10.2.0.22 and 26.0.0.103, and a name MILNET- GW.ISI.EDU, and the MIT gateway has addresses 10.0.0.77 and 18.10.0.4 and a name GW.LCS.MIT.EDU, the domain database would contain:\n10.IN-ADDR.ARPA. PTR MILNET-GW.ISI.EDU. 10.IN-ADDR.ARPA. PTR GW.LCS.MIT.EDU. 18.IN-ADDR.ARPA. PTR GW.LCS.MIT.EDU. 26.IN-ADDR.ARPA. PTR MILNET-GW.ISI.EDU. 22.0.2.10.IN-ADDR.ARPA. PTR MILNET-GW.ISI.EDU. 103.0.0.26.IN-ADDR.ARPA. PTR MILNET-GW.ISI.EDU. 77.0.0.10.IN-ADDR.ARPA. PTR GW.LCS.MIT.EDU. 4.0.10.18.IN-ADDR.ARPA. PTR GW.LCS.MIT.EDU. 103.0.3.26.IN-ADDR.ARPA. PTR A.ISI.EDU. 6.0.0.10.IN-ADDR.ARPA. PTR MULTICS.MIT.EDU. Thus a program which wanted to locate gateways on net 10 would originate a query of the form QTYPE=PTR, QCLASS=IN, QNAME=10.IN-ADDR.ARPA. It would receive two RRs in response:\n10.IN-ADDR.ARPA. PTR MILNET-GW.ISI.EDU. 10.IN-ADDR.ARPA. PTR GW.LCS.MIT.EDU. The program could then originate QTYPE=A, QCLASS=IN queries for MILNET- GW.ISI.EDU. and GW.LCS.MIT.EDU. to discover the Internet addresses of these gateways.\nA resolver which wanted to find the host name corresponding to Internet host address 10.0.0.6 would pursue a query of the form QTYPE=PTR, QCLASS=IN, QNAME=6.0.0.10.IN-ADDR.ARPA, and would receive:\n6.0.0.10.IN-ADDR.ARPA. PTR MULTICS.MIT.EDU. Several cautions apply to the use of these services:\nSince the IN-ADDR.ARPA special domain and the normal domain for a particular host or gateway will be in different zones, the possibility exists that that the data may be inconsistent. Gateways will often have two names in separate domains, only one of which can be primary. Systems that use the domain database to initialize their routing tables must start with enough gateway information to guarantee that they can access the appropriate name server. The gateway data only reflects the existence of a gateway in a manner equivalent to the current HOSTS.TXT file. It doesn\u0026rsquo;t replace the dynamic availability information from GGP or EGP. 3.6. Defining new types, classes, and special namespaces #The previously defined types and classes are the ones in use as of the date of this memo. New definitions should be expected. This section makes some recommendations to designers considering additions to the existing facilities. The mailing list NAMEDROPPERS@SRI-NIC.ARPA is the forum where general discussion of design issues takes place.\nIn general, a new type is appropriate when new information is to be added to the database about an existing object, or we need new data formats for some totally new object. Designers should attempt to define types and their RDATA formats that are generally applicable to all classes, and which avoid duplication of information. New classes are appropriate when the DNS is to be used for a new protocol, etc which requires new class-specific data formats, or when a copy of the existing name space is desired, but a separate management domain is necessary.\nNew types and classes need mnemonics for master files; the format of the master files requires that the mnemonics for type and class be disjoint.\nTYPE and CLASS values must be a proper subset of QTYPEs and QCLASSes respectively.\nThe present system uses multiple RRs to represent multiple values of a type rather than storing multiple values in the RDATA section of a single RR. This is less efficient for most applications, but does keep RRs shorter. The multiple RRs assumption is incorporated in some experimental work on dynamic update methods.\nThe present system attempts to minimize the duplication of data in the database in order to insure consistency. Thus, in order to find the address of the host for a mail exchange, you map the mail domain name to a host name, then the host name to addresses, rather than a direct mapping to host address. This approach is preferred because it avoids the opportunity for inconsistency.\nIn defining a new type of data, multiple RR types should not be used to create an ordering between entries or express different formats for equivalent bindings, instead this information should be carried in the body of the RR and a single type used. This policy avoids problems with caching multiple types and defining QTYPEs to match multiple types.\nFor example, the original form of mail exchange binding used two RR types one to represent a \u0026ldquo;closer\u0026rdquo; exchange (MD) and one to represent a \u0026ldquo;less close\u0026rdquo; exchange (MF). The difficulty is that the presence of one RR type in a cache doesn\u0026rsquo;t convey any information about the other because the query which acquired the cached information might have used a QTYPE of MF, MD, or MAILA (which matched both). The redesigned\nservice used a single type (MX) with a \u0026ldquo;preference\u0026rdquo; value in the RDATA section which can order different RRs. However, if any MX RRs are found in the cache, then all should be there.\n4. MESSAGES #4.1. Format #All communications inside of the domain protocol are carried in a single format called a message. The top level format of message is divided into 5 sections (some of which are empty in certain cases) shown below:\n+---------------------+ | Header | +---------------------+ | Question | the question for the name server +---------------------+ | Answer | RRs answering the question +---------------------+ | Authority | RRs pointing toward an authority +---------------------+ | Additional | RRs holding additional information +---------------------+ The header section is always present. The header includes fields that specify which of the remaining sections are present, and also specify whether the message is a query or a response, a standard query or some other opcode, etc.\nThe names of the sections after the header are derived from their use in standard queries. The question section contains fields that describe a question to a name server. These fields are a query type (QTYPE), a query class (QCLASS), and a query domain name (QNAME). The last three sections have the same format: a possibly empty list of concatenated resource records (RRs). The answer section contains RRs that answer the question; the authority section contains RRs that point toward an authoritative name server; the additional records section contains RRs which relate to the query, but are not strictly answers for the question.\n4.1.1. Header section format #The header contains the following fields:\n1 1 1 1 1 1 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | ID | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ |QR| Opcode |AA|TC|RD|RA| Z | RCODE | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | QDCOUNT | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | ANCOUNT | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | NSCOUNT | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | ARCOUNT | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nID A 16 bit identifier assigned by the program that generates any kind of query. This identifier is copied the corresponding reply and can be used by the requester to match up replies to outstanding queries.\nQR A one bit field that specifies whether this message is a query (0), or a response (1).\nOPCODE A four bit field that specifies kind of query in this message. This value is set by the originator of a query and copied into the response. The values are:\n0 a standard query (QUERY) 1 an inverse query (IQUERY) 2 a server status request (STATUS) 3-15 reserved for future use AA Authoritative Answer - this bit is valid in responses, and specifies that the responding name server is an authority for the domain name in question section.\nNote that the contents of the answer section may have multiple owner names because of aliases. The AA bit corresponds to the name which matches the query name, or the first owner name in the answer section. TC TrunCation - specifies that this message was truncated due to length greater than that permitted on the transmission channel.\nRD Recursion Desired - this bit may be set in a query and is copied into the response. If RD is set, it directs the name server to pursue the query recursively. Recursive query support is optional.\nRA Recursion Available - this be is set or cleared in a response, and denotes whether recursive query support is available in the name server.\nZ Reserved for future use. Must be zero in all queries and responses.\nRCODE Response code - this 4 bit field is set as part of responses. The values have the following interpretation:\n0 No error condition 1 Format error - The name server was unable to interpret the query. 2 Server failure - The name server was unable to process this query due to a problem with the name server. 3 Name Error - Meaningful only for responses from an authoritative name server, this code signifies that the domain name referenced in the query does not exist. 4 Not Implemented - The name server does not support the requested kind of query. 5 Refused - The name server refuses to perform the specified operation for policy reasons. For example, a name server may not wish to provide the information to the particular requester, or a name server may not wish to perform a particular operation (e.g., zone transfer) for particular data. 6-15 Reserved for future use. QDCOUNT an unsigned 16 bit integer specifying the number of entries in the question section.\nANCOUNT an unsigned 16 bit integer specifying the number of resource records in the answer section.\nNSCOUNT an unsigned 16 bit integer specifying the number of name server resource records in the authority records section.\nARCOUNT an unsigned 16 bit integer specifying the number of resource records in the additional records section.\n4.1.2. Question section format #The question section is used to carry the \u0026ldquo;question\u0026rdquo; in most queries, i.e., the parameters that define what is being asked. The section contains QDCOUNT (usually 1) entries, each of the following format:\n1 1 1 1 1 1 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | | / QNAME / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | QTYPE | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | QCLASS | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nQNAME a domain name represented as a sequence of labels, where each label consists of a length octet followed by that number of octets. The domain name terminates with the zero length octet for the null label of the root. Note that this field may be an odd number of octets; no padding is used.\nQTYPE a two octet code which specifies the type of the query. The values for this field include all codes valid for a TYPE field, together with some more general codes which can match more than one type of RR.\nQCLASS a two octet code that specifies the class of the query. For example, the QCLASS field is IN for the Internet.\n4.1.3. Resource record format #The answer, authority, and additional sections all share the same format: a variable number of resource records, where the number of records is specified in the corresponding count field in the header. Each resource record has the following format:\n1 1 1 1 1 1 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | | / / / NAME / | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | TYPE | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | CLASS | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | TTL | | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | RDLENGTH | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--| / RDATA / / / +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ where:\nNAME a domain name to which this resource record pertains.\nTYPE two octets containing one of the RR type codes. This field specifies the meaning of the data in the RDATA field.\nCLASS two octets which specify the class of the data in the RDATA field.\nTTL a 32 bit unsigned integer that specifies the time interval (in seconds) that the resource record may be cached before it should be discarded. Zero values are interpreted to mean that the RR can only be used for the transaction in progress, and should not be cached.\nRDLENGTH an unsigned 16 bit integer that specifies the length in octets of the RDATA field.\nRDATA a variable length string of octets that describes the resource. The format of this information varies according to the TYPE and CLASS of the resource record. For example, the if the TYPE is A and the CLASS is IN, the RDATA field is a 4 octet ARPA Internet address.\n4.1.4. Message compression #In order to reduce the size of messages, the domain system utilizes a compression scheme which eliminates the repetition of domain names in a message. In this scheme, an entire domain name or a list of labels at the end of a domain name is replaced with a pointer to a prior occurence of the same name.\nThe pointer takes the form of a two octet sequence:\n+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ | 1 1| OFFSET | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ The first two bits are ones. This allows a pointer to be distinguished from a label, since the label must begin with two zero bits because labels are restricted to 63 octets or less. (The 10 and 01 combinations are reserved for future use.) The OFFSET field specifies an offset from the start of the message (i.e., the first octet of the ID field in the domain header). A zero offset specifies the first byte of the ID field, etc.\nThe compression scheme allows a domain name in a message to be represented as either:\na sequence of labels ending in a zero octet a pointer a sequence of labels ending with a pointer Pointers can only be used for occurences of a domain name where the format is not class specific. If this were not the case, a name server or resolver would be required to know the format of all RRs it handled. As yet, there are no such cases, but they may occur in future RDATA formats.\nIf a domain name is contained in a part of the message subject to a length field (such as the RDATA section of an RR), and compression is used, the length of the compressed name is used in the length calculation, rather than the length of the expanded name.\nPrograms are free to avoid using pointers in messages they generate, although this will reduce datagram capacity, and may cause truncation. However all programs are required to understand arriving messages that contain pointers.\nFor example, a datagram might need to use the domain names F.ISI.ARPA, FOO.F.ISI.ARPA, ARPA, and the root. Ignoring the other fields of the message, these domain names might be represented as:\n+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 20 | 1 | F | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 22 | 3 | I | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 24 | S | I | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 26 | 4 | A | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 28 | R | P | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 30 | A | 0 | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 40 | 3 | F | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 42 | O | O | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 44 | 1 1| 20 | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 64 | 1 1| 26 | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ 92 | 0 | | +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ The domain name for F.ISI.ARPA is shown at offset 20. The domain name FOO.F.ISI.ARPA is shown at offset 40; this definition uses a pointer to concatenate a label for FOO to the previously defined F.ISI.ARPA. The domain name ARPA is defined at offset 64 using a pointer to the ARPA component of the name F.ISI.ARPA at 20; note that this pointer relies on ARPA being the last label in the string at 20. The root domain name is defined by a single octet of zeros at 92; the root domain name has no labels.\n4.2. Transport #The DNS assumes that messages will be transmitted as datagrams or in a byte stream carried by a virtual circuit. While virtual circuits can be used for any DNS activity, datagrams are preferred for queries due to their lower overhead and better performance. Zone refresh activities must use virtual circuits because of the need for reliable transfer.\nThe Internet supports name server access using TCP [RFC-793] on server port 53 (decimal) as well as datagram access using UDP [RFC-768] on UDP port 53 (decimal).\n4.2.1. UDP usage #Messages sent using UDP user server port 53 (decimal).\nMessages carried by UDP are restricted to 512 bytes (not counting the IP or UDP headers). Longer messages are truncated and the TC bit is set in the header.\nUDP is not acceptable for zone transfers, but is the recommended method for standard queries in the Internet. Queries sent using UDP may be lost, and hence a retransmission strategy is required. Queries or their responses may be reordered by the network, or by processing in name servers, so resolvers should not depend on them being returned in order.\nThe optimal UDP retransmission policy will vary with performance of the Internet and the needs of the client, but the following are recommended:\nThe client should try other servers and server addresses before repeating a query to a specific address of a server. The retransmission interval should be based on prior statistics if possible. Too aggressive retransmission can easily slow responses for the community at large. Depending on how well connected the client is to its expected servers, the minimum retransmission interval should be 2-5 seconds. More suggestions on server selection and retransmission policy can be found in the resolver section of this memo.\n4.2.2. TCP usage #Messages sent over TCP connections use server port 53 (decimal). The message is prefixed with a two byte length field which gives the message length, excluding the two byte length field. This length field allows the low-level processing to assemble a complete message before beginning to parse it.\nSeveral connection management policies are recommended:\nThe server should not block other activities waiting for TCP data. The server should support multiple connections. The server should assume that the client will initiate connection closing, and should delay closing its end of the connection until all outstanding client requests have been satisfied. If the server needs to close a dormant connection to reclaim resources, it should wait until the connection has been idle for a period on the order of two minutes. In particular, the server should allow the SOA and AXFR request sequence (which begins a refresh operation) to be made on a single connection. Since the server would be unable to answer queries anyway, a unilateral close or reset may be used instead of a graceful close. 5. MASTER FILES #Master files are text files that contain RRs in text form. Since the contents of a zone can be expressed in the form of a list of RRs a master file is most often used to define a zone, though it can be used to list a cache\u0026rsquo;s contents. Hence, this section first discusses the format of RRs in a master file, and then the special considerations when a master file is used to create a zone in some name server.\n5.1. Format #The format of these files is a sequence of entries. Entries are predominantly line-oriented, though parentheses can be used to continue a list of items across a line boundary, and text literals can contain CRLF within the text. Any combination of tabs and spaces act as a delimiter between the separate items that make up an entry. The end of any line in the master file can end with a comment. The comment starts with a \u0026ldquo;;\u0026rdquo; (semicolon).\nThe following entries are defined:\n\u0026lt;blank\u0026gt;[\u0026lt;comment\u0026gt;] $ORIGIN \u0026lt;domain-name\u0026gt; [\u0026lt;comment\u0026gt;] $INCLUDE \u0026lt;file-name\u0026gt; [\u0026lt;domain-name\u0026gt;] [\u0026lt;comment\u0026gt;] \u0026lt;domain-name\u0026gt;\u0026lt;rr\u0026gt; [\u0026lt;comment\u0026gt;] \u0026lt;blank\u0026gt;\u0026lt;rr\u0026gt; [\u0026lt;comment\u0026gt;] Blank lines, with or without comments, are allowed anywhere in the file.\nTwo control entries are defined: $ORIGIN and $INCLUDE. $ORIGIN is followed by a domain name, and resets the current origin for relative domain names to the stated name. $INCLUDE inserts the named file into the current file, and may optionally specify a domain name that sets the relative domain name origin for the included file. $INCLUDE may also have a comment. Note that a $INCLUDE entry never changes the relative origin of the parent file, regardless of changes to the relative origin made within the included file.\nThe last two forms represent RRs. If an entry for an RR begins with a blank, then the RR is assumed to be owned by the last stated owner. If an RR entry begins with a \u0026lt;domain-name\u0026gt;, then the owner name is reset.\n\u0026lt;rr\u0026gt; contents take one of the following forms:\n[\u0026lt;TTL\u0026gt;] [\u0026lt;class\u0026gt;] \u0026lt;type\u0026gt; \u0026lt;RDATA\u0026gt; [\u0026lt;class\u0026gt;] [\u0026lt;TTL\u0026gt;] \u0026lt;type\u0026gt; \u0026lt;RDATA\u0026gt; The RR begins with optional TTL and class fields, followed by a type and RDATA field appropriate to the type and class. Class and type use the standard mnemonics, TTL is a decimal integer. Omitted class and TTL values are default to the last explicitly stated values. Since type and class mnemonics are disjoint, the parse is unique. (Note that this order is different from the order used in examples and the order used in the actual RRs; the given order allows easier parsing and defaulting.)\n\u0026lt;domain-name\u0026gt;s make up a large share of the data in the master file. The labels in the domain name are expressed as character strings and separated by dots. Quoting conventions allow arbitrary characters to be stored in domain names. Domain names that end in a dot are called absolute, and are taken as complete. Domain names which do not end in a dot are called relative; the actual domain name is the concatenation of the relative part with an origin specified in a $ORIGIN, $INCLUDE, or as an argument to the master file loading routine. A relative name is an error when no origin is available.\n\u0026lt;character-string\u0026gt; is expressed in one or two ways: as a contiguous set of characters without interior spaces, or as a string beginning with a \u0026quot; and ending with a \u0026ldquo;. Inside a \u0026quot; delimited string any character can occur, except for a \u0026quot; itself, which must be quoted using \\ (back slash).\nBecause these files are text files several special encodings are necessary to allow arbitrary data to be loaded. In particular:\nof the root. @ A free standing @ is used to denote the current origin.\n\\X where X is any character other than a digit (0-9), is used to quote that character so that its special meaning does not apply. For example, \u0026ldquo;.\u0026rdquo; can be used to place a dot character in a label.\n\\DDD where each D is a digit is the octet corresponding to the decimal number described by DDD. The resulting octet is assumed to be text and is not checked for special meaning.\n( ) Parentheses are used to group data that crosses a line boundary. In effect, line terminations are not recognized within parentheses.\n; Semicolon is used to start a comment; the remainder of the line is ignored.\n5.2. Use of master files to define zones\nWhen a master file is used to load a zone, the operation should be suppressed if any errors are encountered in the master file. The rationale for this is that a single error can have widespread consequences. For example, suppose that the RRs defining a delegation have syntax errors; then the server will return authoritative name errors for all names in the subzone (except in the case where the subzone is also present on the server).\nSeveral other validity checks that should be performed in addition to insuring that the file is syntactically correct:\nAll RRs in the file should have the same class. Exactly one SOA RR should be present at the top of the zone. If delegations are present and glue information is required, it should be present. Information present outside of the authoritative nodes in the zone should be glue information, rather than the result of an origin or similar error. 5.3. Master file example #The following is an example file which might be used to define the ISI.EDU zone.and is loaded with an origin of ISI.EDU:\n@ IN SOA VENERA Action\\.domains ( 20 ; SERIAL 7200 ; REFRESH 600 ; RETRY 3600000; EXPIRE 60) ; MINIMUM NS A.ISI.EDU. NS VENERA NS VAXA MX 10 VENERA MX 20 VAXA A A 26.3.0.103 VENERA A 10.1.0.52 A 128.9.0.32 VAXA A 10.2.0.27 A 128.9.0.33 $INCLUDE `SUBSYS`ISI-MAILBOXES.TXT Where the file SUBSYSISI-MAILBOXES.TXT is:\nMOE MB A.ISI.EDU. LARRY MB A.ISI.EDU. CURLEY MB A.ISI.EDU. STOOGES MG MOE MG LARRY MG CURLEY Note the use of the \\ character in the SOA RR to specify the responsible person mailbox \u0026ldquo;Action.domains@E.ISI.EDU\u0026rdquo;.\n6. NAME SERVER IMPLEMENTATION #6.1. Architecture #The optimal structure for the name server will depend on the host operating system and whether the name server is integrated with resolver operations, either by supporting recursive service, or by sharing its database with a resolver. This section discusses implementation considerations for a name server which shares a database with a resolver, but most of these concerns are present in any name server.\n6.1.1. Control #A name server must employ multiple concurrent activities, whether they are implemented as separate tasks in the host\u0026rsquo;s OS or multiplexing inside a single name server program. It is simply not acceptable for a name server to block the service of UDP requests while it waits for TCP data for refreshing or query activities. Similarly, a name server should not attempt to provide recursive service without processing such requests in parallel, though it may choose to serialize requests from a single client, or to regard identical requests from the same client as duplicates. A name server should not substantially delay requests while it reloads a zone from master files or while it incorporates a newly refreshed zone into its database.\n6.1.2. Database #While name server implementations are free to use any internal data structures they choose, the suggested structure consists of three major parts:\nA \u0026ldquo;catalog\u0026rdquo; data structure which lists the zones available to this server, and a \u0026ldquo;pointer\u0026rdquo; to the zone data structure. The main purpose of this structure is to find the nearest ancestor zone, if any, for arriving standard queries. Separate data structures for each of the zones held by the name server. A data structure for cached data. (or perhaps separate caches for different classes) All of these data structures can be implemented an identical tree structure format, with different data chained off the nodes in different parts: in the catalog the data is pointers to zones, while in the zone and cache data structures, the data will be RRs. In designing the tree framework the designer should recognize that query processing will need to traverse the tree using case-insensitive label comparisons; and that in real data, a few nodes have a very high branching factor (100-1000 or more), but the vast majority have a very low branching factor (0-1).\nOne way to solve the case problem is to store the labels for each node in two pieces: a standardized-case representation of the label where all ASCII characters are in a single case, together with a bit mask that denotes which characters are actually of a different case. The branching factor diversity can be handled using a simple linked list for a node until the branching factor exceeds some threshold, and transitioning to a hash structure after the threshold is exceeded. In any case, hash structures used to store tree sections must insure that hash functions and procedures preserve the casing conventions of the DNS.\nThe use of separate structures for the different parts of the database is motivated by several factors:\nThe catalog structure can be an almost static structure that need change only when the system administrator changes the zones supported by the server. This structure can also be used to store parameters used to control refreshing activities.\nThe individual data structures for zones allow a zone to be replaced simply by changing a pointer in the catalog. Zone refresh operations can build a new structure and, when complete, splice it into the database via a simple pointer replacement. It is very important that when a zone is refreshed, queries should not use old and new data simultaneously.\nWith the proper search procedures, authoritative data in zones will always \u0026ldquo;hide\u0026rdquo;, and hence take precedence over, cached data.\nErrors in zone definitions that cause overlapping zones, etc., may cause erroneous responses to queries, but problem determination is simplified, and the contents of one \u0026ldquo;bad\u0026rdquo; zone can\u0026rsquo;t corrupt another.\nSince the cache is most frequently updated, it is most vulnerable to corruption during system restarts. It can also become full of expired RR data. In either case, it can easily be discarded without disturbing zone data.\nA major aspect of database design is selecting a structure which allows the name server to deal with crashes of the name server\u0026rsquo;s host. State information which a name server should save across system crashes includes the catalog structure (including the state of refreshing for each zone) and the zone data itself.\n6.1.3. Time #Both the TTL data for RRs and the timing data for refreshing activities depends on 32 bit timers in units of seconds. Inside the database, refresh timers and TTLs for cached data conceptually \u0026ldquo;count down\u0026rdquo;, while data in the zone stays with constant TTLs.\nA recommended implementation strategy is to store time in two ways: as a relative increment and as an absolute time. One way to do this is to use positive 32 bit numbers for one type and negative numbers for the other. The RRs in zones use relative times; the refresh timers and cache data use absolute times. Absolute numbers are taken with respect to some known origin and converted to relative values when placed in the response to a query. When an absolute TTL is negative after conversion to relative, then the data is expired and should be ignored.\n6.2. Standard query processing #The major algorithm for standard query processing is presented in [RFC-1034].\nWhen processing queries with QCLASS=*, or some other QCLASS which matches multiple classes, the response should never be authoritative unless the server can guarantee that the response covers all classes.\nWhen composing a response, RRs which are to be inserted in the additional section, but duplicate RRs in the answer or authority sections, may be omitted from the additional section.\nWhen a response is so long that truncation is required, the truncation should start at the end of the response and work forward in the datagram. Thus if there is any data for the authority section, the answer section is guaranteed to be unique.\nThe MINIMUM value in the SOA should be used to set a floor on the TTL of data distributed from a zone. This floor function should be done when the data is copied into a response. This will allow future dynamic update protocols to change the SOA MINIMUM field without ambiguous semantics.\n6.3. Zone refresh and reload processing #In spite of a server\u0026rsquo;s best efforts, it may be unable to load zone data from a master file due to syntax errors, etc., or be unable to refresh a zone within the its expiration parameter. In this case, the name server should answer queries as if it were not supposed to possess the zone.\nIf a master is sending a zone out via AXFR, and a new version is created during the transfer, the master should continue to send the old version if possible. In any case, it should never send part of one version and part of another. If completion is not possible, the master should reset the connection on which the zone transfer is taking place.\n6.4. Inverse queries (Optional) #Inverse queries are an optional part of the DNS. Name servers are not required to support any form of inverse queries. If a name server receives an inverse query that it does not support, it returns an error response with the \u0026ldquo;Not Implemented\u0026rdquo; error set in the header. While inverse query support is optional, all name servers must be at least able to return the error response.\n6.4.1. The contents of inverse queries and responses Inverse queries reverse the mappings performed by standard query operations; while a standard query maps a domain name to a resource, an inverse query maps a resource to a domain name. For example, a standard query might bind a domain name to a host address; the corresponding inverse query binds the host address to a domain name.\nInverse queries take the form of a single RR in the answer section of the message, with an empty question section. The owner name of the query RR and its TTL are not significant. The response carries questions in the question section which identify all names possessing the query RR WHICH THE NAME SERVER KNOWS. Since no name server knows about all of the domain name space, the response can never be assumed to be complete. Thus inverse queries are primarily useful for database management and debugging activities. Inverse queries are NOT an acceptable method of mapping host addresses to host names; use the IN- ADDR.ARPA domain instead.\nWhere possible, name servers should provide case-insensitive comparisons for inverse queries. Thus an inverse query asking for an MX RR of \u0026ldquo;Venera.isi.edu\u0026rdquo; should get the same response as a query for \u0026ldquo;VENERA.ISI.EDU\u0026rdquo;; an inverse query for HINFO RR \u0026ldquo;IBM-PC UNIX\u0026rdquo; should produce the same result as an inverse query for \u0026ldquo;IBM-pc unix\u0026rdquo;. However, this cannot be guaranteed because name servers may possess RRs that contain character strings but the name server does not know that the data is character.\nWhen a name server processes an inverse query, it either returns:\nzero, one, or multiple domain names for the specified resource as QNAMEs in the question section\nan error code indicating that the name server doesn\u0026rsquo;t support inverse mapping of the specified resource type.\nWhen the response to an inverse query contains one or more QNAMEs, the owner name and TTL of the RR in the answer section which defines the inverse query is modified to exactly match an RR found at the first QNAME.\nRRs returned in the inverse queries cannot be cached using the same mechanism as is used for the replies to standard queries. One reason for this is that a name might have multiple RRs of the same type, and only one would appear. For example, an inverse query for a single address of a multiply homed host might create the impression that only one address existed.\n6.4.2. Inverse query and response example The overall structure of an inverse query for retrieving the domain name that corresponds to Internet address 10.1.0.52 is shown below:\n+-----------------------------------------+ Header | OPCODE=IQUERY, ID=997 | +-----------------------------------------+ Question | \u0026lt;empty\u0026gt; | +-----------------------------------------+ Answer | \u0026lt;anyname\u0026gt; A IN 10.1.0.52 | +-----------------------------------------+ Authority | \u0026lt;empty\u0026gt; | +-----------------------------------------+ Additional | \u0026lt;empty\u0026gt; | +-----------------------------------------+ This query asks for a question whose answer is the Internet style address 10.1.0.52. Since the owner name is not known, any domain name can be used as a placeholder (and is ignored). A single octet of zero, signifying the root, is usually used because it minimizes the length of the message. The TTL of the RR is not significant. The response to this query might be:\n+-----------------------------------------+ Header | OPCODE=RESPONSE, ID=997 | +-----------------------------------------+ Question |QTYPE=A, QCLASS=IN, QNAME=VENERA.ISI.EDU | +-----------------------------------------+ Answer | VENERA.ISI.EDU A IN 10.1.0.52 | +-----------------------------------------+ Authority | \u0026lt;empty\u0026gt; | +-----------------------------------------+ Additional | \u0026lt;empty\u0026gt; | +-----------------------------------------+ Note that the QTYPE in a response to an inverse query is the same as the TYPE field in the answer section of the inverse query. Responses to inverse queries may contain multiple questions when the inverse is not unique. If the question section in the response is not empty, then the RR in the answer section is modified to correspond to be an exact copy of an RR at the first QNAME.\n6.4.3. Inverse query processing #Name servers that support inverse queries can support these operations through exhaustive searches of their databases, but this becomes impractical as the size of the database increases. An alternative approach is to invert the database according to the search key.\nFor name servers that support multiple zones and a large amount of data, the recommended approach is separate inversions for each zone. When a particular zone is changed during a refresh, only its inversions need to be redone.\nSupport for transfer of this type of inversion may be included in future versions of the domain system, but is not supported in this version.\n6.5. Completion queries and responses #The optional completion services described in RFC-882 and RFC-883 have been deleted. Redesigned services may become available in the future.\n7. RESOLVER IMPLEMENTATION #The top levels of the recommended resolver algorithm are discussed in [RFC-1034]. This section discusses implementation details assuming the database structure suggested in the name server implementation section of this memo.\n7.1. Transforming a user request into a query #The first step a resolver takes is to transform the client\u0026rsquo;s request, stated in a format suitable to the local OS, into a search specification for RRs at a specific name which match a specific QTYPE and QCLASS. Where possible, the QTYPE and QCLASS should correspond to a single type and a single class, because this makes the use of cached data much simpler. The reason for this is that the presence of data of one type in a cache doesn\u0026rsquo;t confirm the existence or non-existence of data of other types, hence the only way to be sure is to consult an authoritative source. If QCLASS=* is used, then authoritative answers won\u0026rsquo;t be available.\nSince a resolver must be able to multiplex multiple requests if it is to perform its function efficiently, each pending request is usually represented in some block of state information. This state block will typically contain:\nA timestamp indicating the time the request began. The timestamp is used to decide whether RRs in the database can be used or are out of date. This timestamp uses the absolute time format previously discussed for RR storage in zones and caches. Note that when an RRs TTL indicates a relative time, the RR must be timely, since it is part of a zone. When the RR has an absolute time, it is part of a cache, and the TTL of the RR is compared against the timestamp for the start of the request.\nNote that using the timestamp is superior to using a current time, since it allows RRs with TTLs of zero to be entered in the cache in the usual manner, but still used by the current request, even after intervals of many seconds due to system load, query retransmission timeouts, etc.\nSome sort of parameters to limit the amount of work which will be performed for this request.\nThe amount of work which a resolver will do in response to a client request must be limited to guard against errors in the database, such as circular CNAME references, and operational problems, such as network partition which prevents the resolver from accessing the name servers it needs. While local limits on the number of times a resolver will retransmit a particular query to a particular name server address are essential, the resolver should have a global per-request counter to limit work on a single request. The counter should be set to some initial value and decremented whenever the resolver performs any action (retransmission timeout, retransmission, etc.) If the counter passes zero, the request is terminated with a temporary error.\nNote that if the resolver structure allows one request to start others in parallel, such as when the need to access a name server for one request causes a parallel resolve for the name server\u0026rsquo;s addresses, the spawned request should be started with a lower counter. This prevents circular references in the database from starting a chain reaction of resolver activity.\nThe SLIST data structure discussed in [RFC-1034].\nThis structure keeps track of the state of a request if it must wait for answers from foreign name servers.\n7.2. Sending the queries #As described in [RFC-1034], the basic task of the resolver is to formulate a query which will answer the client\u0026rsquo;s request and direct that query to name servers which can provide the information. The resolver will usually only have very strong hints about which servers to ask, in the form of NS RRs, and may have to revise the query, in response to CNAMEs, or revise the set of name servers the resolver is asking, in response to delegation responses which point the resolver to name servers closer to the desired information. In addition to the information requested by the client, the resolver may have to call upon its own services to determine the address of name servers it wishes to contact.\nIn any case, the model used in this memo assumes that the resolver is multiplexing attention between multiple requests, some from the client, and some internally generated. Each request is represented by some state information, and the desired behavior is that the resolver transmit queries to name servers in a way that maximizes the probability that the request is answered, minimizes the time that the request takes, and avoids excessive transmissions. The key algorithm uses the state information of the request to select the next name server address to query, and also computes a timeout which will cause the next action should a response not arrive. The next action will usually be a transmission to some other server, but may be a temporary error to the client.\nThe resolver always starts with a list of server names to query (SLIST). This list will be all NS RRs which correspond to the nearest ancestor zone that the resolver knows about. To avoid startup problems, the resolver should have a set of default servers which it will ask should it have no current NS RRs which are appropriate. The resolver then adds to SLIST all of the known addresses for the name servers, and may start parallel requests to acquire the addresses of the servers when the resolver has the name, but no addresses, for the name servers.\nTo complete initialization of SLIST, the resolver attaches whatever history information it has to the each address in SLIST. This will usually consist of some sort of weighted averages for the response time of the address, and the batting average of the address (i.e., how often the address responded at all to the request). Note that this information should be kept on a per address basis, rather than on a per name server basis, because the response time and batting average of a particular server may vary considerably from address to address. Note also that this information is actually specific to a resolver address / server address pair, so a resolver with multiple addresses may wish to keep separate histories for each of its addresses. Part of this step must deal with addresses which have no such history; in this case an expected round trip time of 5-10 seconds should be the worst case, with lower estimates for the same local network, etc.\nNote that whenever a delegation is followed, the resolver algorithm reinitializes SLIST.\nThe information establishes a partial ranking of the available name server addresses. Each time an address is chosen and the state should be altered to prevent its selection again until all other addresses have been tried. The timeout for each transmission should be 50-100% greater than the average predicted value to allow for variance in response.\nSome fine points:\nThe resolver may encounter a situation where no addresses are available for any of the name servers named in SLIST, and where the servers in the list are precisely those which would normally be used to look up their own addresses. This situation typically occurs when the glue address RRs have a smaller TTL than the NS RRs marking delegation, or when the resolver caches the result of a NS search. The resolver should detect this condition and restart the search at the next ancestor zone, or alternatively at the root.\nIf a resolver gets a server error or other bizarre response from a name server, it should remove it from SLIST, and may wish to schedule an immediate transmission to the next candidate server address.\n7.3. Processing responses #The first step in processing arriving response datagrams is to parse the response. This procedure should include:\nCheck the header for reasonableness. Discard datagrams which are queries when responses are expected.\nParse the sections of the message, and insure that all RRs are correctly formatted.\nAs an optional step, check the TTLs of arriving data looking for RRs with excessively long TTLs. If a RR has an excessively long TTL, say greater than 1 week, either discard the whole response, or limit all TTLs in the response to 1 week.\nThe next step is to match the response to a current resolver request. The recommended strategy is to do a preliminary matching using the ID field in the domain header, and then to verify that the question section corresponds to the information currently desired. This requires that the transmission algorithm devote several bits of the domain ID field to a request identifier of some sort. This step has several fine points:\nSome name servers send their responses from different addresses than the one used to receive the query. That is, a resolver cannot rely that a response will come from the same address which it sent the corresponding query to. This name server bug is typically encountered in UNIX systems.\nIf the resolver retransmits a particular request to a name server it should be able to use a response from any of the transmissions. However, if it is using the response to sample the round trip time to access the name server, it must be able to determine which transmission matches the response (and keep transmission times for each outgoing message), or only calculate round trip times based on initial transmissions.\nA name server will occasionally not have a current copy of a zone which it should have according to some NS RRs. The resolver should simply remove the name server from the current SLIST, and continue.\n7.4. Using the cache #In general, we expect a resolver to cache all data which it receives in responses since it may be useful in answering future client requests. However, there are several types of data which should not be cached:\nWhen several RRs of the same type are available for a particular owner name, the resolver should either cache them all or none at all. When a response is truncated, and a resolver doesn\u0026rsquo;t know whether it has a complete set, it should not cache a possibly partial set of RRs.\nCached data should never be used in preference to authoritative data, so if caching would cause this to happen the data should not be cached.\nThe results of an inverse query should not be cached.\nThe results of standard queries where the QNAME contains \u0026ldquo;*\u0026rdquo; labels if the data might be used to construct wildcards. The reason is that the cache does not necessarily contain existing RRs or zone boundary information which is necessary to restrict the application of the wildcard RRs.\nRR data in responses of dubious reliability. When a resolver receives unsolicited responses or RR data other than that requested, it should discard it without caching it. The basic implication is that all sanity checks on a packet should be performed before any of it is cached.\nIn a similar vein, when a resolver has a set of RRs for some name in a response, and wants to cache the RRs, it should check its cache for already existing RRs. Depending on the circumstances, either the data in the response or the cache is preferred, but the two should never be combined. If the data in the response is from authoritative data in the answer section, it is always preferred.\n8. MAIL SUPPORT #The domain system defines a standard for mapping mailboxes into domain names, and two methods for using the mailbox information to derive mail routing information. The first method is called mail exchange binding and the other method is mailbox binding. The mailbox encoding standard and mail exchange binding are part of the DNS official protocol, and are the recommended method for mail routing in the Internet. Mailbox binding is an experimental feature which is still under development and subject to change.\nThe mailbox encoding standard assumes a mailbox name of the form \u0026lt;local-part\u0026gt;@\u0026lt;mail-domain\u0026gt;. While the syntax allowed in each of these sections varies substantially between the various mail internets, the preferred syntax for the ARPA Internet is given in [RFC-822].\nThe DNS encodes the \u0026lt;local-part\u0026gt; as a single label, and encodes the \u0026lt;mail-domain\u0026gt; as a domain name. The single label from the \u0026lt;local-part\u0026gt; is prefaced to the domain name from \u0026lt;mail-domain\u0026gt; to form the domain name corresponding to the mailbox. Thus the mailbox HOSTMASTER@SRI- NIC.ARPA is mapped into the domain name HOSTMASTER.SRI-NIC.ARPA. If the \u0026lt;local-part\u0026gt; contains dots or other special characters, its representation in a master file will require the use of backslash quoting to ensure that the domain name is properly encoded. For example, the mailbox Action.domains@ISI.EDU would be represented as Action.domains.ISI.EDU.\n8.1. Mail exchange binding #Mail exchange binding uses the \u0026lt;mail-domain\u0026gt; part of a mailbox specification to determine where mail should be sent. The \u0026lt;local-part\u0026gt; is not even consulted. [RFC-974] specifies this method in detail, and should be consulted before attempting to use mail exchange support.\nOne of the advantages of this method is that it decouples mail destination naming from the hosts used to support mail service, at the cost of another layer of indirection in the lookup function. However, the addition layer should eliminate the need for complicated \u0026ldquo;%\u0026rdquo;, \u0026ldquo;!\u0026rdquo;, etc encodings in \u0026lt;local-part\u0026gt;.\nThe essence of the method is that the \u0026lt;mail-domain\u0026gt; is used as a domain name to locate type MX RRs which list hosts willing to accept mail for \u0026lt;mail-domain\u0026gt;, together with preference values which rank the hosts according to an order specified by the administrators for \u0026lt;mail-domain\u0026gt;.\nIn this memo, the \u0026lt;mail-domain\u0026gt; ISI.EDU is used in examples, together with the hosts VENERA.ISI.EDU and VAXA.ISI.EDU as mail exchanges for ISI.EDU. If a mailer had a message for Mockapetris@ISI.EDU, it would route it by looking up MX RRs for ISI.EDU. The MX RRs at ISI.EDU name VENERA.ISI.EDU and VAXA.ISI.EDU, and type A queries can find the host addresses.\n8.2. Mailbox binding (Experimental) #In mailbox binding, the mailer uses the entire mail destination specification to construct a domain name. The encoded domain name for the mailbox is used as the QNAME field in a QTYPE=MAILB query.\nSeveral outcomes are possible for this query:\nThe query can return a name error indicating that the mailbox does not exist as a domain name.\nIn the long term, this would indicate that the specified mailbox doesn\u0026rsquo;t exist. However, until the use of mailbox binding is universal, this error condition should be interpreted to mean that the organization identified by the global part does not support mailbox binding. The appropriate procedure is to revert to exchange binding at this point.\nThe query can return a Mail Rename (MR) RR.\nThe MR RR carries new mailbox specification in its RDATA field. The mailer should replace the old mailbox with the new one and retry the operation.\nThe query can return a MB RR.\nThe MB RR carries a domain name for a host in its RDATA field. The mailer should deliver the message to that host via whatever protocol is applicable, e.g., b,SMTP.\nThe query can return one or more Mail Group (MG) RRs.\nThis condition means that the mailbox was actually a mailing list or mail group, rather than a single mailbox. Each MG RR has a RDATA field that identifies a mailbox that is a member of the group. The mailer should deliver a copy of the message to each member.\nThe query can return a MB RR as well as one or more MG RRs.\nThis condition means the the mailbox was actually a mailing list. The mailer can either deliver the message to the host specified by the MB RR, which will in turn do the delivery to all members, or the mailer can use the MG RRs to do the expansion itself.\nIn any of these cases, the response may include a Mail Information (MINFO) RR. This RR is usually associated with a mail group, but is legal with a MB. The MINFO RR identifies two mailboxes. One of these identifies a responsible person for the original mailbox name. This mailbox should be used for requests to be added to a mail group, etc. The second mailbox name in the MINFO RR identifies a mailbox that should receive error messages for mail failures. This is particularly appropriate for mailing lists when errors in member names should be reported to a person other than the one who sends a message to the list.\n9. REFERENCES and BIBLIOGRAPHY #[Dyer 87] S. Dyer, F. Hsu, \u0026ldquo;Hesiod\u0026rdquo;, Project Athena Technical Plan - Name Service, April 1987, version 1.9.\nDescribes the fundamentals of the Hesiod name service. [IEN-116] J. Postel, \u0026ldquo;Internet Name Server\u0026rdquo;, IEN-116, USC/Information Sciences Institute, August 1979.\nA name service obsoleted by the Domain Name System, but still in use. [Quarterman 86] J. Quarterman, and J. Hoskins, \u0026ldquo;Notable Computer Networks\u0026rdquo;, Communications of the ACM, October 1986, volume 29, number 10.\n[RFC-742] K. Harrenstien, \u0026ldquo;NAME/FINGER\u0026rdquo;, RFC-742, Network Information Center, SRI International, December 1977.\n[RFC-768] J. Postel, \u0026ldquo;User Datagram Protocol\u0026rdquo;, RFC-768, USC/Information Sciences Institute, August 1980.\n[RFC-793] J. Postel, \u0026ldquo;Transmission Control Protocol\u0026rdquo;, RFC-793, USC/Information Sciences Institute, September 1981.\n[RFC-799] D. Mills, \u0026ldquo;Internet Name Domains\u0026rdquo;, RFC-799, COMSAT, September 1981.\nSuggests introduction of a hierarchy in place of a flat name space for the Internet. [RFC-805] J. Postel, \u0026ldquo;Computer Mail Meeting Notes\u0026rdquo;, RFC-805, USC/Information Sciences Institute, February 1982.\n[RFC-810] E. Feinler, K. Harrenstien, Z. Su, and V. White, \u0026ldquo;DOD Internet Host Table Specification\u0026rdquo;, RFC-810, Network Information Center, SRI International, March 1982.\nObsolete. See RFC-952. [RFC-811] K. Harrenstien, V. White, and E. Feinler, \u0026ldquo;Hostnames Server\u0026rdquo;, RFC-811, Network Information Center, SRI International, March 1982.\nObsolete. See RFC-953. [RFC-812] K. Harrenstien, and V. White, \u0026ldquo;NICNAME/WHOIS\u0026rdquo;, RFC-812, Network Information Center, SRI International, March 1982.\n[RFC-819] Z. Su, and J. Postel, \u0026ldquo;The Domain Naming Convention for Internet User Applications\u0026rdquo;, RFC-819, Network Information Center, SRI International, August 1982.\nEarly thoughts on the design of the domain system. Current implementation is completely different. [RFC-821] J. Postel, \u0026ldquo;Simple Mail Transfer Protocol\u0026rdquo;, RFC-821, USC/Information Sciences Institute, August 1980.\n[RFC-830] Z. Su, \u0026ldquo;A Distributed System for Internet Name Service\u0026rdquo;, RFC-830, Network Information Center, SRI International, October 1982.\nEarly thoughts on the design of the domain system. Current implementation is completely different. [RFC-882] P. Mockapetris, \u0026ldquo;Domain names - Concepts and Facilities,\u0026rdquo; RFC-882, USC/Information Sciences Institute, November 1983.\nSuperceeded by this memo. [RFC-883] P. Mockapetris, \u0026ldquo;Domain names - Implementation and Specification,\u0026rdquo; RFC-883, USC/Information Sciences Institute, November 1983.\nSuperceeded by this memo. [RFC-920] J. Postel and J. Reynolds, \u0026ldquo;Domain Requirements\u0026rdquo;, RFC-920, USC/Information Sciences Institute, October 1984.\nExplains the naming scheme for top level domains. [RFC-952] K. Harrenstien, M. Stahl, E. Feinler, \u0026ldquo;DoD Internet Host Table Specification\u0026rdquo;, RFC-952, SRI, October 1985.\nSpecifies the format of HOSTS.TXT, the host/address table replaced by the DNS. [RFC-953] K. Harrenstien, M. Stahl, E. Feinler, \u0026ldquo;HOSTNAME Server\u0026rdquo;, RFC-953, SRI, October 1985.\nThis RFC contains the official specification of the hostname server protocol, which is obsoleted by the DNS. This TCP based protocol accesses information stored in the RFC-952 format, and is used to obtain copies of the host table. [RFC-973] P. Mockapetris, \u0026ldquo;Domain System Changes and Observations\u0026rdquo;, RFC-973, USC/Information Sciences Institute, January 1986.\nDescribes changes to RFC-882 and RFC-883 and reasons for them. [RFC-974] C. Partridge, \u0026ldquo;Mail routing and the domain system\u0026rdquo;, RFC-974, CSNET CIC BBN Labs, January 1986.\nDescribes the transition from HOSTS.TXT based mail addressing to the more powerful MX system used with the domain system. [RFC-1001] NetBIOS Working Group, \u0026ldquo;Protocol standard for a NetBIOS service on a TCP/UDP transport: Concepts and Methods\u0026rdquo;, RFC-1001, March 1987.\nThis RFC and RFC-1002 are a preliminary design for NETBIOS on top of TCP/IP which proposes to base NetBIOS name service on top of the DNS. [RFC-1002] NetBIOS Working Group, \u0026ldquo;Protocol standard for a NetBIOS service on a TCP/UDP transport: Detailed Specifications\u0026rdquo;, RFC-1002, March 1987.\n[RFC-1010] J. Reynolds, and J. Postel, \u0026ldquo;Assigned Numbers\u0026rdquo;, RFC-1010, USC/Information Sciences Institute, May 1987.\nContains socket numbers and mnemonics for host names, operating systems, etc. [RFC-1031] W. Lazear, \u0026ldquo;MILNET Name Domain Transition\u0026rdquo;, RFC-1031, November 1987.\nDescribes a plan for converting the MILNET to the DNS. [RFC-1032] M. Stahl, \u0026ldquo;Establishing a Domain - Guidelines for Administrators\u0026rdquo;, RFC-1032, November 1987.\nDescribes the registration policies used by the NIC to administer the top level domains and delegate subzones. [RFC-1033] M. Lottor, \u0026ldquo;Domain Administrators Operations Guide\u0026rdquo;, RFC-1033, November 1987.\nA cookbook for domain administrators. [Solomon 82] M. Solomon, L. Landweber, and D. Neuhengen, \u0026ldquo;The CSNET Name Server\u0026rdquo;, Computer Networks, vol 6, nr 3, July 1982.\nDescribes a name service for CSNET which is independent from the DNS and DNS use in the CSNET. ","date":"1 January 0001","permalink":"/posts/protocols/dns/implementation-and-specification/","section":"Posts","summary":"This RFC describes the details of the domain system and protocol, and assumes that the reader is familiar with the concepts discussed in a companion RFC, \u0026ldquo;Domain Names - Concepts and Facilities\u0026rdquo; [RFC-1034].","title":"Domain Names: Implementation and Specification"},{"content":"","date":null,"permalink":"/tags/email-campaigns/","section":"Tags","summary":"","title":"Email-Campaigns"},{"content":"","date":null,"permalink":"/tags/email-marketing/","section":"Tags","summary":"","title":"Email-Marketing"},{"content":"","date":null,"permalink":"/tags/encryption/","section":"Tags","summary":"","title":"Encryption"},{"content":"","date":null,"permalink":"/categories/fail2ban/","section":"Categories","summary":"","title":"Fail2ban"},{"content":"","date":null,"permalink":"/tags/filesystem/","section":"Tags","summary":"","title":"Filesystem"},{"content":"","date":null,"permalink":"/tags/firewall/","section":"Tags","summary":"","title":"Firewall"},{"content":"","date":null,"permalink":"/tags/ghost/","section":"Tags","summary":"","title":"Ghost"},{"content":"","date":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git"},{"content":"","date":null,"permalink":"/tags/gitea/","section":"Tags","summary":"","title":"Gitea"},{"content":"","date":null,"permalink":"/tags/gnupg/","section":"Tags","summary":"","title":"Gnupg"},{"content":"","date":null,"permalink":"/tags/hardening/","section":"Tags","summary":"","title":"Hardening"},{"content":"","date":null,"permalink":"/categories/hardening/","section":"Categories","summary":"","title":"Hardening"},{"content":"","date":null,"permalink":"/tags/homelab/","section":"Tags","summary":"","title":"Homelab"},{"content":"Fail2Ban is a vital security tool for Linux servers, particularly useful in protecting SSH services against brute-force attacks. It monitors service logs for malicious activity and bans offending IPs for a specified duration.\nInstalling Fail2Ban #Fail2Ban is included in Debian’s default repositories, making it easy to install:\nUpdate your package listings:\nsudo apt update Install Fail2Ban:\nsudo apt install fail2ban After installation, the Fail2Ban service starts automatically. Verify it with:\nsudo systemctl status fail2ban Configuring Fail2Ban #Configuration involves editing .local files that override the default .conf files:\nCreate a .local Configuration File: Copy jail.conf to jail.local:\nsudo cp /etc/fail2ban/jail.{conf,local} Edit the jail.local File: Open the file:\nsudo nano /etc/fail2ban/jail.local Here, you can set various parameters.\nImportant Parameters # Whitelisting IP Addresses: Add trusted IPs to the ignoreip directive:\nignoreip = 127.0.0.1/8 ::1 [Trusted IPs] Setting Ban Conditions\nbantime: Duration to ban the IP (default is 10 minutes). findtime: Time window in which failures must occur. maxretry: Number of failures before banning. Example settings:\nbantime = 1d findtime = 10m maxretry = 5 Email Notifications\nConfigure to receive email alerts on banning events:\naction = %(action_mw)s destemail = your-email@example.com sender = server-email@example.com Configuring SSH Jail #Fail2Ban uses \u0026lsquo;jails\u0026rsquo; for each service. For SSH, enable and configure the SSH jail in jail.local:\n[sshd] enabled = true maxretry = 5 findtime = 12h bantime = 1d ignoreip = 127.0.0.1/8 [Other Trusted IPs] Restarting Fail2Ban #After changes, restart Fail2Ban to apply:\nsudo systemctl restart fail2ban Using fail2ban-client #Manage Fail2Ban with fail2ban-client. Common commands include:\nChecking server status: sudo fail2ban-client status Unbanning an IP: sudo fail2ban-client set sshd unbanip [IP Address] Explore more options with fail2ban-client -h.\n","date":"1 January 0001","permalink":"/posts/fail2ban/install/","section":"Posts","summary":"Fail2Ban is a vital security tool for Linux servers, particularly useful in protecting SSH services against brute-force attacks.","title":"Install and Configure Fail2Ban for SSH on Debian"},{"content":"Create user #Create a new user for CoreDNS to run as an unprivileged user.\nadduser --system --group --shell \u0026#34;/usr/sbin/nologin\u0026#34; --comment \u0026#34;CoreDNS\u0026#34; --home \u0026#34;/etc/coredns\u0026#34; coredns Install binary # Download the latest binary from the releases. wget https://github.com/coredns/coredns/releases/download/v1.11.1/coredns_1.11.1_linux_arm64.tgz wget https://github.com/coredns/coredns/releases/download/v1.11.1/coredns_1.11.1_linux_arm64.tgz.sha256 Check the SHA256 sum of the downloaded file. sha256sum -c coredns_1.11.1_linux_arm64.tgz.sha256 Extract the the binary from the downloaded archive: tar -xvf coredns_1.11.1_linux_arm64.tgz Install the binary: install coredns /usr/bin/ Corefile # Open /etc/coredns/Corefile: nano /etc/coredns/Corefile Write the lines below for a basic configuration: . { forward . 1.1.1.1 8.8.8.8 9.9.9.9 log } systemd service #coredns.service #[Unit] Description=CoreDNS Server Documentation=https://coredns.io/manual/ After=network-online.target Wants=network-online.target [Service] User=coredns Group=coredns AmbientCapabilities=CAP_NET_BIND_SERVICE Restart=always WorkingDirectory=/etc/coredns ExecStart=/usr/bin/coredns ExecReload=/usr/bin/kill -USR1 $MAINPID [Install] WantedBy=multi-user.target Create service # Open /etc/systemd/system/coredns.service: nano /etc/systemd/system/coredns.service Write the lines found under coredns.service. Start the service # Reload systemd systemctl daemon-reload Start coredns.service: systemctl start coredns.service Enable CoreDNS #To start CoreDNS at system startup, enable it:\nsystemctl enable coredns.service Firewall #nftables #Below is an example for nftables:\n#!/usr/sbin/nft -f flush ruleset table inet filter { chain inbound_ipv4 { icmp type echo-request limit rate 5/second accept } chain inbound_ipv6 { icmpv6 type { nd-neighbor-solicit, nd-router-advert, nd-neighbor-advert } accept icmpv6 type echo-request limit rate 5/second accept } chain input { type filter hook input priority 0; policy drop; ct state { established, related } accept iifname lo accept meta protocol vmap { ip : jump inbound_ipv4, ip6 : jump inbound_ipv6 } tcp dport 22 accept tcp dport 53 accept udp dport 53 accept } chain forward { type filter hook forward priority 0; policy drop; } chain output { type filter hook output priority 0; } } ","date":"1 January 0001","permalink":"/posts/coredns/install/","section":"Posts","summary":"Install CoreDNS from Binary on Debian 12 server.","title":"Install CoreDNS from Binary on Debian 12"},{"content":"Docker has become an essential tool in the world of modern software development. If you\u0026rsquo;re using Debian 12 and want to take advantage of Docker\u0026rsquo;s capabilities, this guide will walk you through the installation process.\nUpdate System Packages #Begin by updating your system’s package index:\nsudo apt update sudo apt install -y ca-certificates curl gnupg This ensures that you have the necessary packages to securely install Docker.\nAdd Docker’s Official GPG Key #Docker’s GPG key ensures the authenticity of the software packages. Add it with:\nsudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg Then, add the Docker repository to your system:\necho \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null This ensures you get the latest version of Docker.\nInstall Docker Engine #Now, install the Docker Engine, CLI, and other necessary components:\nsudo apt update sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y After installation, the Docker service starts automatically.\nVerify the Installation #To verify Docker is installed correctly, run a test image:\nsudo docker run hello-world If everything is set up correctly, this command will pull a test image and run a container that prints an informational message.\nEnable Docker Command for Non-root Users #By default, running Docker commands requires root privileges. To allow a non-root user to execute Docker commands, add them to the docker group:\nsudo usermod -aG docker $USER newgrp docker ","date":"1 January 0001","permalink":"/posts/docker/install/","section":"Posts","summary":"Docker has become an essential tool in the world of modern software development.","title":"Install Docker Engine on Debian 12"},{"content":"Create user for Ghost #adduser [GHOSTUSER] usermod -aG sudo [GHOSTUSER] Requirements #Nginx #Install nginx:\napt install nginx -y MariaDB #Install MariaDB\napt install mariadb-server mariadb-client -y Initialize MariaDB:\nmysql_secure_installation Create database for Ghost:\nmysql -u root -p CREATE USER [GHOSTUSER]@localhost IDENTIFIED BY \u0026#34;Str0ngP4ss\u0026#34;; CREATE DATABASE [GHOSTDB]; GRANT ALL ON [GHOSTDB].* TO [GHOSTUSER]@localhost; FLUSH PRIVILEGES; QUIT; NodeJS 12.x #Install NodeJS 12.x:\ncurl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash apt install nodejs -y Create directory #mkdir -p /var/www/ghost chown [GHOSTUSER]:[GHOSTUSER] /var/www/ghost chmod 775 /var/www/ghost Ghost CLI #npm install ghost-cli@latest -g Ghost #Change user to [GHOSTUSER]:\nsu - [GHOSTUSER] Install our Ghost:\ncd /var/www/ghost ghost install ","date":"1 January 0001","permalink":"/posts/ghost/install/","section":"Posts","summary":"Create user for Ghost #adduser [GHOSTUSER] usermod -aG sudo [GHOSTUSER] Requirements #Nginx #Install nginx:","title":"Install Ghost CMS on Debian 10"},{"content":"MariaDB #Install MariaDB:\napt install mariadb-server Initialize MariaDB:\nmysql_secure_installation Create database for Gitea:\nmysql -u root SET old_passwords=0; CREATE USER \u0026#39;gitea\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;S3cureP4ss\u0026#39;; CREATE DATABASE giteadb CHARACTER SET \u0026#39;utf8mb4\u0026#39; COLLATE \u0026#39;utf8mb4_unicode_ci\u0026#39;; GRANT ALL PRIVILEGES ON giteadb.* TO \u0026#39;gitea\u0026#39;@\u0026#39;localhost\u0026#39;; FLUSH PRIVILEGES; Git #Install git:\napt install git Gitea #Download binary:\nwget -O /usr/bin/gitea https://dl.gitea.io/gitea/1.12.1/gitea-1.12.1-linux-amd64 chmod +x /usr/bin/gitea Verify the binary:\ngpg --keyserver keys.openpgp.org --recv 7C9E68152594688862D62AF62D9AE806EC1592E2 wget https://dl.gitea.io/gitea/1.12.1/gitea-1.12.1-linux-amd64.asc gpg --verify /usr/bin/gitea gitea-1.12.1-linux-amd64.asc User #Create the user for Gitea:\nadduser --system --group --disabled-password git /home/git will be the work directory.\nDirectory structure #mkdir -p /home/git/{custom,data,log} chown -R git:git /home/git chmod -R 750 /home/git Systemd service #[Unit] Description=Gitea (Git with a cup of tea) After=syslog.target After=network.target Requires=mariadb.service [Service] RestartSec=2s Type=simple User=git Group=git WorkingDirectory=/home/git ExecStart=/usr/bin/gitea web --config /home/git/app.ini Restart=always Environment=USER=git HOME=/home/git GITEA_WORK_DIR=/home/git [Install] WantedBy=multi-user.target Copy the code above and create the service:\nnano /etc/systemd/system/gitea.service Enable and start Gitea:\nsystemctl enable --now gitea.service Check Gitea:\nsystemctl status gitea.service Nginx #Install Nginx:\napt install nginx Example config:\n# https server { # Enable SSL and HTTP2 listen [::]:443 ssl http2; listen 443 ssl http2; # Set certificate path ssl_certificate /etc/letsencrypt/live/git.icoman.hu/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/git.icoman.hu/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/git.icoman.hu/fullchain.pem; server_name git.icoman.hu; # Reverse proxy location / { proxy_pass http://127.0.0.1:3000; } # Disable unused methods if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 405; } } # http server { listen 80; listen [::]:80; server_name git.icoman.hu; # Add HSTS header add_header Strict-Transport-Security \u0026#34;max-age=63072000; includeSubdomains\u0026#34; always; # Redirect http to https return 301 https://$host$request_uri; } Certbot #Install certbot:\napt install certbot python-certbot-nginx Get a cert:\ncertbot certonly --nginx -d example.com --rsa-key-size 4096 Configure #The config file is /home/git/app.ini.\nSMTP #Use my mail server with StartTLS to send notifications:\n[mailer] ENABLED = true FROM = git@example.com MAILER_TYPE = smtp HOST = mail.example.com:587 USER = git@example.com PASSWD = `S3cureP4ss` Require login to see the repos #[service] REQUIRE_SIGNIN_VIEW = true ","date":"1 January 0001","permalink":"/posts/gitea/install/","section":"Posts","summary":"MariaDB #Install MariaDB:","title":"Install Gitea on Debian 10"},{"content":"Install repository for PHP 8.1 #Mautic 5.0 requires PHP 8.0 or 8.1.\nInstall Sury\u0026rsquo;s Debian repository:\nsudo apt install -y lsb-release apt-transport-https ca-certificates curl \u0026amp;\u0026amp; \\ sudo wget -O \u0026#34;/etc/apt/trusted.gpg.d/php.gpg\u0026#34; \u0026#34;https://packages.sury.org/php/apt.gpg\u0026#34; \u0026amp;\u0026amp; \\ echo \u0026#34;deb https://packages.sury.org/php/ $(lsb_release -sc) main\u0026#34; | sudo tee \u0026#34;/etc/apt/sources.list.d/php.list\u0026#34; \u0026amp;\u0026amp; \\ sudo apt update Install repository for NodeJS / NPM #NPM will be required by Composer.\nInstall the LTS (20.x) NodeJS Debian repository:\ncurl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - Install required packages #Install the dependencies:\napt install apache2 mariadb-server php8.1 php8.1-{fpm,xml,mysql,imap,zip,intl,curl,gd,mbstring,bcmath} nodejs unzip git Configure MariaDB #mysql_secure_installation Create the DB and the user:\nGenerate a random password for the database and store it in an environment variable:\nMYSQL_PASSWD=$(echo $RANDOM | md5sum | head -c 20) To print the database password:\necho $MYSQL_PASSWD Create the database and the user:\nmysql --execute=\u0026#34;CREATE DATABASE mautic; GRANT ALL PRIVILEGES ON mautic.* TO \u0026#39;mautic\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;${MYSQL_PASSWD}\u0026#39; WITH GRANT OPTION; FLUSH PRIVILEGES;\u0026#34; Composer #Install the latest Composer:\nphp -r \u0026#34;copy(\u0026#39;https://getcomposer.org/installer\u0026#39;, \u0026#39;composer-setup.php\u0026#39;);\u0026#34; \u0026amp;\u0026amp; \\ php -r \u0026#34;if (hash_file(\u0026#39;sha384\u0026#39;, \u0026#39;composer-setup.php\u0026#39;) === \u0026#39;dac665fdc30fdd8ec78b38b9800061b4150413ff2e3b6f88543c636f7cd84f6db9189d43a81e5503cda447da73c7e5b6\u0026#39;) { echo \u0026#39;Installer verified\u0026#39;; } else { echo \u0026#39;Installer corrupt\u0026#39;; unlink(\u0026#39;composer-setup.php\u0026#39;); } echo PHP_EOL;\u0026#34; \u0026amp;\u0026amp; \\ php composer-setup.php \u0026amp;\u0026amp; \\ php -r \u0026#34;unlink(\u0026#39;composer-setup.php\u0026#39;);\u0026#34; \u0026amp;\u0026amp; \\ sudo mv composer.phar /usr/local/bin/composer Configure PHP-FPM #Configure the recommended settings for PHP-FPM:\nnano +c/date.timezone /etc/php/8.1/fpm/php.ini date.timezone = Europe/Budapest :::warning Modify the values below to your needs! :::\nsed -i \u0026#39;s/memory_limit = 128M/memory_limit = 512M/\u0026#39; /etc/php/8.1/fpm/php.ini \u0026amp;\u0026amp; \\ sed -i \u0026#39;s/upload_max_filesize = 2M/upload_max_filesize = 100M/\u0026#39; /etc/php/8.1/fpm/php.ini \u0026amp;\u0026amp; \\ sed -i \u0026#39;s/max_execution_time = 30/max_execution_time = 600/\u0026#39; /etc/php/8.1/fpm/php.ini \u0026amp;\u0026amp; \\ sed -i \u0026#39;s/post_max_size = 8M/post_max_size = 64M/\u0026#39; /etc/php/8.1/fpm/php.ini Restart the PHP-FPM service to apply the settings:\nsystemctl restart php8.1-fpm.service Apache #Create the site config:\nnano /etc/apache2/sites-available/mautic.conf \u0026lt;VirtualHost *:80\u0026gt; ServerName mautic.example.com DocumentRoot /var/www/mautic/docroot/ \u0026lt;Directory /\u0026gt; Options FollowSymLinks AllowOverride All \u0026lt;/Directory\u0026gt; \u0026lt;Directory /var/www/mautic/docroot/\u0026gt; Options FollowSymLinks MultiViews AllowOverride All Order allow,deny allow from all \u0026lt;/Directory\u0026gt; ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined \u0026lt;/VirtualHost\u0026gt; Disable mpm_prefork:\nsudo a2dismod mpm_prefork Enable the required Apache modules:\na2enmod rewrite mpm_event proxy_fcgi setenvif Enable PHP-FPM for Apache:\na2enconf php8.1-fpm Enable the site:\na2ensite mautic.conf Apply settings for Apache:\nsystemctl restart apache2 Install Mautic #Install Mautic to /var/www/mautic/:\nCOMPOSER_ALLOW_SUPERUSER=1 composer create-project mautic/recommended-project:^5.0 /var/www/mautic --no-interaction Change the owner of the files:\nchown -R www-data:www-data /var/www/mautic ","date":"1 January 0001","permalink":"/posts/mautic/install-with-composer/","section":"Posts","summary":"Install repository for PHP 8.","title":"Install Mautic 5 with Composer on Debian 12"},{"content":"Install repository for PHP 8.1 #Mautic 5.0 requires PHP 8.0 or 8.1.\nInstall Sury\u0026rsquo;s Debian repository:\nsudo apt install -y lsb-release apt-transport-https ca-certificates curl \u0026amp;\u0026amp; \\ sudo wget -O \u0026#34;/etc/apt/trusted.gpg.d/php.gpg\u0026#34; \u0026#34;https://packages.sury.org/php/apt.gpg\u0026#34; \u0026amp;\u0026amp; \\ echo \u0026#34;deb https://packages.sury.org/php/ $(lsb_release -sc) main\u0026#34; | sudo tee \u0026#34;/etc/apt/sources.list.d/php.list\u0026#34; \u0026amp;\u0026amp; \\ sudo apt update Install required packages #Install the dependencies:\napt install apache2 mariadb-server php8.1 php8.1-{fpm,xml,mysql,imap,zip,intl,curl,gd,mbstring,bcmath} unzip Configure MariaDB #mysql_secure_installation Create the DB and the user:\nGenerate a random password for the database and store it in an environment variable:\nMYSQL_PASSWD=$(echo $RANDOM | md5sum | head -c 20) To print the database password:\necho $MYSQL_PASSWD Create the database and the user:\nmysql --execute=\u0026#34;CREATE DATABASE mautic; GRANT ALL PRIVILEGES ON mautic.* TO \u0026#39;mautic\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;${MYSQL_PASSWD}\u0026#39; WITH GRANT OPTION; FLUSH PRIVILEGES;\u0026#34; Configure PHP-FPM #Configure the recommended settings for PHP-FPM:\nnano +c/date.timezone /etc/php/8.1/fpm/php.ini date.timezone = Europe/Budapest :::warning Modify the values below to your needs! :::\nsed -i \u0026#39;s/memory_limit = 128M/memory_limit = 512M/\u0026#39; /etc/php/8.1/fpm/php.ini \u0026amp;\u0026amp; \\ sed -i \u0026#39;s/upload_max_filesize = 2M/upload_max_filesize = 100M/\u0026#39; /etc/php/8.1/fpm/php.ini \u0026amp;\u0026amp; \\ sed -i \u0026#39;s/max_execution_time = 30/max_execution_time = 600/\u0026#39; /etc/php/8.1/fpm/php.ini \u0026amp;\u0026amp; \\ sed -i \u0026#39;s/post_max_size = 8M/post_max_size = 64M/\u0026#39; /etc/php/8.1/fpm/php.ini Restart the PHP-FPM service to apply the settings:\nsystemctl restart php8.1-fpm.service Apache #Create the site config:\nnano /etc/apache2/sites-available/mautic.conf \u0026lt;VirtualHost *:80\u0026gt; ServerName mautic.example.com DocumentRoot /var/www/mautic/ \u0026lt;Directory /\u0026gt; Options FollowSymLinks AllowOverride All \u0026lt;/Directory\u0026gt; \u0026lt;Directory /var/www/mautic/\u0026gt; Options FollowSymLinks MultiViews AllowOverride All Order allow,deny allow from all \u0026lt;/Directory\u0026gt; ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined \u0026lt;/VirtualHost\u0026gt; Disable mpm_prefork:\nsudo a2dismod mpm_prefork Enable the required Apache modules:\na2enmod rewrite mpm_event proxy_fcgi setenvif Enable PHP-FPM for Apache:\na2enconf php8.1-fpm Enable the site:\na2ensite mautic.conf Apply settings for Apache:\nsystemctl restart apache2 Install Mautic #Download the latest archive:\nwget https://github.com/mautic/mautic/releases/download/5.0.4/5.0.4.zip Create the directory for Mautic:\nmkdir /var/www/mautic Extract the zip archive:\nunzip -d /var/www/mautic/ 5.0.4.zip Change the owner of the files:\nchown -R www-data:www-data /var/www/mautic ","date":"1 January 0001","permalink":"/posts/mautic/install/","section":"Posts","summary":"Install repository for PHP 8.","title":"Install Mautic using the Production Package on Debian 12"},{"content":"import Tabs from \u0026lsquo;@theme/Tabs\u0026rsquo;; import TabItem from \u0026lsquo;@theme/TabItem\u0026rsquo;;\nRequirements #sudo apt-get install gnupg curl Configure apt #Import MongoDB publis GPG key:\ncurl -fsSL https://www.mongodb.org/static/pgp/server-7.0.asc | sudo gpg -o /usr/share/keyrings/mongodb-server-7.0.gpg --dearmor Create apt list:\n```bash echo \"deb [ signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] http://repo.mongodb.org/apt/debian bookworm/mongodb-org/7.0 main\" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list ``` ```bash echo \"deb [ signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] http://repo.mongodb.org/apt/debian bullseye/mongodb-org/7.0 main\" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list ``` Update apt package database:\napt update Install the latest version:\napt install -y mongodb-org ","date":"1 January 0001","permalink":"/posts/mongodb/install/","section":"Posts","summary":"import Tabs from \u0026lsquo;@theme/Tabs\u0026rsquo;; import TabItem from \u0026lsquo;@theme/TabItem\u0026rsquo;;","title":"Install MongoDB Community Edition"},{"content":"Requirements #Install Node.js 18 or above.\nCreate user nad group #groupadd --system n8n sudo useradd --system --gid n8n --create-home --home-dir /opt/n8n --shell /usr/sbin/nologin n8n Install #Install n8n globally with npm:\nnpm install n8n -g Start automatically #Configure a systemd service to start automatically at boot.\nnano /etc/systemd/system/n8n.service [Unit] Description=n8n servce After=network.target network-online.target Requires=network-online.target [Service] User=n8n Group=n8n #WorkingDirectory= Type=exec Restart=always RestartSec=1 ExecStart=/usr/bin/n8n start [Install] WantedBy=multi-user.target ","date":"1 January 0001","permalink":"/posts/n8n/install/","section":"Posts","summary":"Requirements #Install Node.","title":"Install n8n"},{"content":"Source: https://github.com/louislam/uptime-kuma\nInstall #Install Uptime Kuma with Nginx and systemd.\nDependencies #NodeJS\ncurl -fsSL https://deb.nodesource.com/setup_18.x | bash - apt-get install -y nodejs Install Git, Nginx and Certbot:\napt install git nginx python3-certbot-nginx Create a user for Uptime Kuma:\nadduser --disabled-password --disabled-login --gecos \u0026#34;\u0026#34; uptime Setup #cd /var/www git clone https://github.com/louislam/uptime-kuma.git uptime.example.com Change the owner/group of the files:\nchown -R uptime:uptime uptime.example.com Change the current user:\nsudo -u uptime /bin/bash Run the setup:\nnpm run setup Get a certificate from Let\u0026rsquo;s Encrypt:\ncertbot certonly --nginx -d uptime.example.com --rsa-key-size 4096 Configure Nginx:\n# https server { # Enable SSL and HTTP2 listen 443 ssl http2; server_name uptime.example.com; access_log /var/log/nginx/access.log; # Set certificate path ssl_certificate /etc/letsencrypt/live/uptime.example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/uptime.example.com/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/uptime.example.com/fullchain.pem; # Enable OCSP ssl_stapling on; ssl_stapling_verify on; resolver 1.1.1.1 1.0.0.1; resolver_timeout 5s; # Add security headers add_header X-Frame-Options \u0026#34;SAMEORIGIN\u0026#34; always; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34; always; add_header X-Content-Type-Options \u0026#34;nosniff\u0026#34; always; add_header Referrer-Policy \u0026#39;strict-origin\u0026#39; always; add_header Strict-Transport-Security \u0026#34;max-age=63072000\u0026#34; always; # Reverse proxy location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; proxy_pass http://127.0.0.1:3001; } } # http server { listen 80; server_name uptime.example.com; # Redirect http to https return 301 https://$host$request_uri; } Create a systemd service:\nnano /etc/systemd/system/uptime.service [Unit] Description=Uptime-Kuma - A free and open source uptime monitoring solution Documentation=https://github.com/louislam/uptime-kuma After=network.target [Service] Type=simple User=uptime Group=uptime WorkingDirectory=/var/www/uptime.example.com ExecStart=/usr/bin/npm run start-server Restart=on-failure [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl enable --now uptime.service :::tip Dont forget the default nginx configurations :::\n","date":"1 January 0001","permalink":"/posts/uptime-kuma/install-from-source/","section":"Posts","summary":"Source: https://github.","title":"Install Uptime Kuma from Source on Debian 12"},{"content":"","date":null,"permalink":"/tags/iptables/","section":"Tags","summary":"","title":"Iptables"},{"content":"","date":null,"permalink":"/tags/lfcs/","section":"Tags","summary":"","title":"Lfcs"},{"content":"Commands needed for Linux Foundation Certified Sysadmin.\nProcesses #ulimit # man page get/set the resource limits of processes restrict: processes cant exhaust the system\u0026rsquo;s resource expand: set enough resource to run a propgram properly hard limit: the possible maximum of resource, set by root soft limit: the possible maximum of resource for user, cant exceed hard limit users and root has different limits the settings are valid for the current shell, to modify persistent, write to /etc/security/limits.conf get all limit: ulimit -a set the limit of open files: ulimit -n 2048 ps # man page show current processes list all processes: ps -elf or ps -aux nice # man page set the starting process priority level higher nice level means lower priority range: -20 to 19 run a script with lower priority: nice -n 10 ./script or nice -10 ./script run a script with higher priority: nice -n -10 ./script or nice --10 ./script renice # man page set an already runnning process priority level increase a PID\u0026rsquo;s priority level: renice -n 10 2000 or renice +10 2000 lower a PID\u0026rsquo;s priorty level: renice -n -10 2000 or renice -10 2000 ldd # man page list the shared libraries needed to a binary list the shared libraries need by ls: ldd /bin/ls ldconfig # man page generally runs at boot time used to build a cached database of shared libraries ipcs # man page get informations about IPC facilities to list facilites with PID: ipcs -p Signals #kill # man page send a signal to a process list signals: kill -l SIGTERM is the default signal, if the number ommited only accept PID! kill process using number: kill -n 9 2000 or kill -9 2000 kill process using name: kill -s SIGKILL 2000 or kill -SIGKILL 2000 killall # man page kill all processes (those that the caller user can kill) with the given name the default signal is SIGTERM kill every firefox instance with number: killall -9 firefox kill every firefox instance with name: killall -SIGKILL firefox pkill # man page send signal to a process with a criteria kill very firefox instance of user g0rbe: pkill -u g0rbe firefox ","date":"1 January 0001","permalink":"/posts/lfcs/commands/","section":"Posts","summary":"Commands needed for Linux Foundation Certified Sysadmin.","title":"LFCS Commands"},{"content":"","date":null,"permalink":"/categories/linux/","section":"Categories","summary":"","title":"Linux"},{"content":"UNIX-based operating systems uses one big file system tree, started with the root (/) directory. This filesystem can contain many distinct filesystems, mounted at various points, which appear as subdirectories.\nData distinctions #Shareable vs non-shareable # shareable: can be shared between different hosts, eg.: user home directory non-shareable: specific to a particular host, eg.: device lock files variable vs static # variable: may change without sysadmins help, eg.: process files static: does not change without admin, eg.: binaries, libraries Filesystem Hierarchy Standard (FHS) # maintained by Linux Foundation specifies the main directories that need to be present and describe their purposes simplifies predictions of file locations additional directories not violates the standard components in directories other than the standard describe is violate FHS documentation flowchart LR / --\u0026gt; bin / --\u0026gt; boot / --\u0026gt; dev / --\u0026gt; etc / --\u0026gt; home / --\u0026gt; lib / --\u0026gt; lib64 / --\u0026gt; media / --\u0026gt; mnt / --\u0026gt; opt / --\u0026gt; proc / --\u0026gt; sys / --\u0026gt; root / --\u0026gt; sbin / --\u0026gt; srv / --\u0026gt; tmp / --\u0026gt; usr / --\u0026gt; var / --\u0026gt; run / # primary directory of the filesystem must contain all essential files required to boot and mount other filesystems according to FHS, no application should create a new subdirectory of the root only root user can write to this directory /bin # /binary contains all essential command binaries that needed for all user must contain all tools that needed in singel user mode or in recovery mode non-essential commands are placed in /usr/bin instead of /bin, like commands required only by non-root users recent distros do not separate /bin/ and /usr/bin, instead uses a symbolic link to /usr/bin /boot # contains static files needed to boot the system often a separate partition contains: kernel, initramfs images, boot configuration files and bootloader vmlinuz: compressed Linux kernel initramfs/initrd: initial RAM filesystem / initial RAM disk, mounted before the real root filesystem become available config: kernel compilation parameters System.map: kernel symbol table, used for debugging on EFI systems this is the EFI System Partition /dev # /devices contains special device files (device nodes) pseudo-filesystem old systems uses devfs, moderns uses udev as its filesystem files represents devices in your system contains character devices (byte-stream, eg.: /dev/hwrng) and block devices (eg.: /dev/sda) used to interact with hardwares and softwares on modern distros, udev is responsible for dynamically modifying files in /dev if devices are found (at boot time or on the fly) or removed network interfaces are too complex to be placed in /dev /dev is empty when the computer powered off /etc # /etcetera host specific system-wide configuration files applications may pre-populate this directory with its vendor-supplied configuartion files /etc/resolv.conf: the system\u0026rsquo;s DNS server /etc/passwd: user database /etc/shadow: users encrypted passwords /etc/group: list of groups and its users /etc/skel: template for new users /etc/init.d: contains daemon scripts for SysV /home # users home directories regular users probably use this for its home directory, eg.: /home/g0rbe for user g0rbe here is stored the user specific configurations, files and scripts shorthands to get logged in user\u0026rsquo;s home directory: ~ and $HOME /lib # /library contains essential shared libraries and kernel modules these libraries is needed to execute binaries in /bin and /sbin kernel modules and drivers stored in /lib/modules/ PAM modules stored in /lib/security/ recent distros uses symlink to /usr/lib /lib64 # essential libraries for 64bit system executables used when both 32 and 64 bit executables supported by the system /media # mount point for removable media when automatic mount is enabled, udev creates a folder and mount the filesystem there /mnt # /mount mount point for temporary filesystems /opt # /optional optional application packages that not part of the system distribution, but from an independent source used by packages to keep all of their files in one isolated folder instead of placing files to their proper place, eg.: configs in /etc, binaries in /bin, etc\u0026hellip; /proc # /process virtual pseudo-filesystem called procfs used to give information about the system and the processes files anf folders in /proc are resides only in the memory every process have a subdirectory named as the process\u0026rsquo;s PID and contains information about the process, eg.: PID, name, parent process, resources used, etc\u0026hellip; most of the file\u0026rsquo;s size is 0 while containing data like /dev, the /proc is empty on a non-running system /proc/sys is used to get and alter system configurations /sys # /system virtual pseudo-filesystem called sysfs used to give information about the system (devices, drivers, kernel modules, system configuration structures, etc\u0026hellip;) and to alter system settings files and folders in /sys are resides only in the memory like /dev and /proc, the /sys is also empty when computer turned off strict standards about what can contain most files are contains only one line or value /root # home directory of the root user root specific configurations, files and executables located outside of /home in order to make sure the root user may log in even without /home being available /sbin # /system binary essential system binaries for booting, restoring, recovering and/or repairing the system and mounting other filesystems recent distros uses symlink to /usr/sbin /srv # /service data for services provided by this system rarely used /tmp # /temporary used to store temporary files (eg.: lock files) probably a ramdisk in memory called tmpfs probably flushed across a reboot can be accessed by anyone, the permissions are 0777 should not used to store large files /usr # /user or todays: /User System Resources multi-user (user-land) applications, utilities and datas stored here are not needed to boot the system contains a secondary hierarchy (/usr/bin, /usr/lib, etc\u0026hellip;) typically a read-only directory /usr/share/man: man pages stored here /usr/lib: C and C++ API header file of system libraries /var # /variable variable datas that changes during system operations must be writeable stored here: log files (/var/log) spool file for further processing (/var/spool) administrative data files transient and temporary files, like cache (/var/cache) user\u0026rsquo;s mailbox (/var/mail) root for websites (/var/www) /run # /runtime used to store runtime data required by udev a pseudo-filesystem stored in memory, called tmpfs ","date":"1 January 0001","permalink":"/posts/linux/filesystem-hierarchy/","section":"Posts","summary":"UNIX-based operating systems uses one big file system tree, started with the root (/) directory.","title":"Linux Filesystem Hierarchy"},{"content":"Program # a set of instructions that uses internal and/or external data internal data: strings, integers, etc\u0026hellip; external data: databases, files, etc\u0026hellip; Process vs thread #Process # an executing instance of a program each process has its own resource the same program maybe executing more than once simultaneously every process has one or more thread multi-threaded process: multiple flow of execution, every resources are shared between threads heavy weight process: a process with its own resources light weight process: a thread of a process with shared resources with other threads Thread # started from a process can share resources (eg.: memory) each thread is considered individually, as a standalone process each thread has the same process ID (thread group ID) and different thread ID Processes in details # has attributes, eg.: command: command that executed to start the process state: running: executing or in the run queue sleeping: waiting on a request stopped: suspended zombie: exit state not properly handled PID: Process ID PPID: Parent Process ID PGID: Process Group ID environment: environment where the process running UID: which user called the process allocated memory init is the first process, the parent of all processes, except kernel initiated processes (marked with [] in ps) if the parent dies before the child: without systemd: the child\u0026rsquo;s PPID will set to 1, init will be the parent with systemd: the PPID will set to 2, kthreadd will be the parent zombie process: the parent process is not programmed properly to handle the die of the child process, all resources are released, just the child are stick around in memory init process is kills gracefully every adopted zombie processes processes are controlled by Linux Process Scheduler, a component of the kernel which decides which proccess to run next the maximum number of PIDs can be viewed or modified in /proc/sys/kernel/pid_max when the PID number reaches the maximum, the kernel starts to assign from the released PIDs from 300 context: information about the process (eg.: state of the CPU, environment, content of the memory, etc\u0026hellip;) setuid programs: marked with an \u0026ldquo;s\u0026rdquo; execute bit, runs the program as the owner of the program, not the caller (eg.: sudo, passwd) processes do not have direct access to the hardware, they have to use system calls execution modes: Ring 3/user mode: lesser privileges isolated process resources (eg.: not able to read/write other process\u0026rsquo;s memory) programs with root privileges also run in user mode limited access to hardwares: processes has to use system calls to access the hardware applications never runs in kernel mode Ring 0/system/kernel mode: full access to hardwares only kernel codes are running in Ring 0 daemon: process running in the background mostly used to provide services to the user only running when needed mostly ends with a \u0026ldquo;d\u0026rdquo; (eg.: sshd) may respond to events (systemd-udevd) or ellapsed time (crond) often do not have controlling terminal or I/O devices provides better security control managed by a deamon manager (eg.: systemd, OpenRC, SysV) daemon scripts stored under /etc/init.d fork(): creates a new process (child) by duplicating the calling process exec(): replace the existing process with the new process a command executed in a shell (foreground process): a new shell forked from the shell puts the parent shell to sleep, waiting for the child to exit replacing the parent shell with the child shell command loaded onto the child with exec, replaces the child shell the command exit with exit() system call, the child process dies the parent shell re-awakened everything starts from the beginning background process: add an \u0026ldquo;\u0026amp;\u0026rdquo; to the end of the command, child process forked to the background, the parent shell and the child process running parallel shell\u0026rsquo;s built in commands (eg.: echo) do not uses the above method, because no program files involved process priority: nicer processes runs later use nice and renice commands to set priority priority is used when no resource available, and the scheduler needs to select the next process static libraries: libraries built into the code at compile time shared libraries / Dynamic Link Libraries: librarties used in runtime more efficient than static libraries (eg.: better load time) suffix/extension: .so carefully versioned ldd command is used to list the shared libraries needed to a binary LD_LIBRARY_PATH environment variable is used to search libraries here before ldconfig\u0026rsquo;s cache Inter Process Communication (IPC): how processes can communicate with each other shared memory message passing ipcs is used to list these IPC facilities Reference # LFS201 (this is just my note from LFS201, not meant to replace the original, which is explain better the above) ","date":"1 January 0001","permalink":"/posts/linux/processes-and-threads/","section":"Posts","summary":"Program # a set of instructions that uses internal and/or external data internal data: strings, integers, etc\u0026hellip; external data: databases, files, etc\u0026hellip; Process vs thread #Process # an executing instance of a program each process has its own resource the same program maybe executing more than once simultaneously every process has one or more thread multi-threaded process: multiple flow of execution, every resources are shared between threads heavy weight process: a process with its own resources light weight process: a thread of a process with shared resources with other threads Thread # started from a process can share resources (eg.","title":"Linux processes and threads"},{"content":"Signals # signals are used to notify processes about events in Inter Process Communication signal is an asynchronous event: not expected expected, but the time is not know signals are sent from the kernel or from a user process via system call with kill user can send signal to his own processes root can send signal to any process signals can be handled differently by the programmer or resbond acording to the system defaults two signal always use the system default: SIGKILL and SIGSTOP signal has a type and the type is indicate the meaning of the signal signals handle: exceptions detected by the hardware exceptions generated by the environment when signal sent from the kernel: the meaning attached to the signal The full list if signals is here SIGTERM: kills the process gracefully SIGKILL: kills the process immediately SIGRTMIN: no predefined purpose can be stacked, handled in FIFO Reference # LFS201 (this is just my note from LFS201, not meant to replace the original, which is explain better the above) ","date":"1 January 0001","permalink":"/posts/linux/signals/","section":"Posts","summary":"Signals # signals are used to notify processes about events in Inter Process Communication signal is an asynchronous event: not expected expected, but the time is not know signals are sent from the kernel or from a user process via system call with kill user can send signal to his own processes root can send signal to any process signals can be handled differently by the programmer or resbond acording to the system defaults two signal always use the system default: SIGKILL and SIGSTOP signal has a type and the type is indicate the meaning of the signal signals handle: exceptions detected by the hardware exceptions generated by the environment when signal sent from the kernel: the meaning attached to the signal The full list if signals is here SIGTERM: kills the process gracefully SIGKILL: kills the process immediately SIGRTMIN: no predefined purpose can be stacked, handled in FIFO Reference # LFS201 (this is just my note from LFS201, not meant to replace the original, which is explain better the above) ","title":"Linux signals"},{"content":"A Record # The Address record. Maps domain names to IPv4 addresses. www.gorbe.io A 128.140.77.237 :::info The @ symbol is indicates the root domain (eg.: gorbe.io). :::\nAAAA Record # Maps domain names to IPv6 addresses. www.gorbe.io AAAA 2a01:4f8:1c1b:5fb9::1 CNAME Record # Redirects a domain to a different domain. www.gorbe.io CNAME gorbe.io TXT Record # Provides any type of descriptive information in text format for the given domain. gorbe.io TXT \u0026#34;v=spf1 mx -all\u0026#34; List # TYPE Value Meaning Reference Template Registration Date Reserved 0 RFC6895 2021-03-08 A 1 A host address RFC1035 NS 2 An authoritative name server RFC1035 MD 3 A mail destination (OBSOLETE - use MX) RFC1035 MF 4 A mail forwarder (OBSOLETE - use MX) RFC1035 CNAME 5 the canonical name for an alias RFC1035 SOA 6 marks the start of a zone of authority RFC1035 MB 7 a mailbox domain name (EXPERIMENTAL) RFC1035 MG 8 a mail group member (EXPERIMENTAL) RFC1035 MR 9 a mail rename domain name (EXPERIMENTAL) RFC1035 NULL 10 a null RR (EXPERIMENTAL) RFC1035 WKS 11 a well known service description RFC1035 PTR 12 a domain name pointer RFC1035 HINFO 13 host information RFC1035 MINFO 14 mailbox or mail list information RFC1035 MX 15 mail exchange RFC1035 TXT 16 text strings RFC1035 RP 17 for Responsible Person RFC1183 AFSDB 18 for AFS Data Base location RFC1183, RFC5864 X25 19 for X.25 PSDN address RFC1183 ISDN 20 for ISDN address RFC1183 RT 21 for Route Through RFC1183 NSAP 22 For NSAP address, NSAP style A record (DEPRECATED) RFC1706 [status-change-int-tlds-to-historic] NSAP-PTR 23 For domain name pointer, NSAP style (DEPRECATED) RFC1706 [status-change-int-tlds-to-historic] SIG 24 for security signature RFC2536 [RFC2931] [RFC3110] [RFC4034] KEY 25 for security key RFC2536 [RFC2539] [RFC3110] [RFC4034] PX 26 X.400 mail mapping information [RFC2163] GPOS 27 Geographical Position [RFC1712] AAAA 28 IP6 Address [RFC3596] LOC 29 Location Information [RFC1876] NXT 30 Next Domain (OBSOLETE) [RFC2535][RFC3755] EID 31 Endpoint Identifier [Michael_Patton][http://ana-3.lcs.mit.edu/~jnc/nimrod/dns.txt] 1995-06 NIMLOC 32 Nimrod Locator [1][Michael_Patton][http://ana-3.lcs.mit.edu/~jnc/nimrod/dns.txt] 1995-06 SRV 33 Server Selection [1][RFC2782] ATMA 34 ATM Address ATM Forum Technical Committee, \u0026ldquo;ATM Name System, V2.0\u0026rdquo;, Doc ID: AF-DANS-0152.000, July 2000. Available from and held in escrow by IANA. NAPTR 35 Naming Authority Pointer [RFC3403] KX 36 Key Exchanger [RFC2230] CERT 37 CERT [RFC4398] A6 38 A6 (OBSOLETE - use AAAA) [RFC2874][RFC3226][RFC6563] DNAME 39 DNAME [RFC6672] SINK 40 SINK [Donald_E_Eastlake][draft-eastlake-kitchen-sink] 1997-11 OPT 41 OPT [RFC3225][RFC6891] APL 42 APL [RFC3123] DS 43 Delegation Signer [RFC4034] SSHFP 44 SSH Key Fingerprint [RFC4255] IPSECKEY 45 IPSECKEY [RFC4025] RRSIG 46 RRSIG [RFC4034] NSEC 47 NSEC [RFC4034][RFC9077] DNSKEY 48 DNSKEY [RFC4034] DHCID 49 DHCID [RFC4701] NSEC3 50 NSEC3 [RFC5155][RFC9077] NSEC3PARAM 51 NSEC3PARAM [RFC5155] TLSA 52 TLSA [RFC6698] SMIMEA 53 S/MIME cert association [RFC8162] SMIMEA/smimea-completed-template 2015-12-01 Unassigned 54 HIP 55 Host Identity Protocol [RFC8005] NINFO 56 NINFO [Jim_Reid] NINFO/ninfo-completed-template 2008-01-21 RKEY 57 RKEY [Jim_Reid] RKEY/rkey-completed-template 2008-01-21 TALINK 58 Trust Anchor LINK [Wouter_Wijngaards] TALINK/talink-completed-template 2010-02-17 CDS 59 Child DS [RFC7344] CDS/cds-completed-template 2011-06-06 CDNSKEY 60 DNSKEY(s) the Child wants reflected in DS [RFC7344] 2014-06-16 OPENPGPKEY 61 OpenPGP Key [RFC7929] OPENPGPKEY/openpgpkey-completed-template 2014-08-12 CSYNC 62 Child-To-Parent Synchronization [RFC7477] 2015-01-27 ZONEMD 63 Message Digest Over Zone Data [RFC8976] ZONEMD/zonemd-completed-template 2018-12-12 SVCB 64 General-purpose service binding [RFC9460] SVCB/svcb-completed-template 2020-06-30 HTTPS 65 SVCB-compatible type for use with HTTP [RFC9460] HTTPS/https-completed-template 2020-06-30 Unassigned 66-98 SPF 99 [RFC7208] UINFO 100 [IANA-Reserved] UID 101 [IANA-Reserved] GID 102 [IANA-Reserved] UNSPEC 103 [IANA-Reserved] NID 104 [RFC6742] ILNP/nid-completed-template L32 105 [RFC6742] ILNP/l32-completed-template L64 106 [RFC6742] ILNP/l64-completed-template LP 107 [RFC6742] ILNP/lp-completed-template EUI48 108 an EUI-48 address [RFC7043] EUI48/eui48-completed-template 2013-03-27 EUI64 109 an EUI-64 address [RFC7043] EUI64/eui64-completed-template 2013-03-27 Unassigned 110-248 TKEY 249 Transaction Key [RFC2930] TSIG 250 Transaction Signature [RFC8945] IXFR 251 incremental transfer [RFC1995] AXFR 252 transfer of an entire zone RFC1035[RFC5936] MAILB 253 Mailbox-related RRs (MB, MG or MR) RFC1035 MAILA 254 mail agent RRs (OBSOLETE - see MX) RFC1035 * 255 A request for some or all records the server has available RFC1035[RFC6895][RFC8482] URI 256 URI [RFC7553] URI/uri-completed-template 2011-02-22 CAA 257 Certification Authority Restriction [RFC8659] CAA/caa-completed-template 2011-04-07 AVC 258 Application Visibility and Control [Wolfgang_Riedel] AVC/avc-completed-template 2016-02-26 DOA 259 Digital Object Architecture [draft-durand-doa-over-dns] DOA/doa-completed-template 2017-08-30 AMTRELAY 260 Automatic Multicast Tunneling Relay [RFC8777] AMTRELAY/amtrelay-completed-template 2019-02-06 RESINFO 261 Resolver Information as Key/Value Pairs [draft-ietf-add-resolver-info-06] RESINFO/resinfo-completed-template 2023-11-02 Unassigned 262-32767 TA 32768 DNSSEC Trust Authorities Sam_Weiler: Deploying DNSSEC Without a Signed Root. Technical Report 1999-19 , Information Networking Institute, Carnegie Mellon University, April 2004. 2005-12-13 DLV 32769 DNSSEC Lookaside Validation (OBSOLETE) [RFC8749][RFC4431] Unassigned 32770-65279 Private use 65280-65534 Reserved 65535 ","date":"1 January 0001","permalink":"/posts/protocols/dns/record-types/","section":"Posts","summary":"A Record # The Address record.","title":"List of DNS Record Types"},{"content":"","date":null,"permalink":"/tags/log/","section":"Tags","summary":"","title":"Log"},{"content":"Spoofing MAC address is possible with Network Manager since 1.4.0. The device is sending probe requests while searching for known Wi-Fi. This broadcast contains the SSID, the devices MAC address and the signal strength, thus the device can be tracked.\nNetwork Manager has setting for this, this setting is enabled by default:\nwifi.scan-rand-mac-address=yes When the device is connected to a network, the MAC address is restored to its original.\nThis configuration is responsible to change MAC at connection.\nethernet.cloned-mac-address= wifi.cloned-mac-address= The possible options:\npermanent: use the devices MAC preserver: dont change the devices MAC at activation random: random MAC at each connection stable: associate a MAC to a network, the MAC will be randomized for each network, means if you reconnect to those network, the MAC address will the same as before To use these settings, create a new config file in /etc/NetworkManager/conf.d\nnano /etc/NetworkManager/conf.d/10-mac.conf Copy to the file:\n[device-mac-randomization] wifi.scan-rand-mac-address=yes [connection-mac-randomization] ethernet.cloned-mac-address=random wifi.cloned-mac-address=random Change random to another if you want.\nRestart Network Manager:\nsystemctl restart NetworkManager The fullpost can be found on Thomas Haller\u0026rsquo;s Blog\n","date":"1 January 0001","permalink":"/posts/network-manager/mac-address-spoofing/","section":"Posts","summary":"Spoofing MAC address is possible with Network Manager since 1.","title":"MAC Address Spoofing with Network Manager"},{"content":"","date":null,"permalink":"/tags/mariadb/","section":"Tags","summary":"","title":"Mariadb"},{"content":"","date":null,"permalink":"/tags/marketing/","section":"Tags","summary":"","title":"Marketing"},{"content":"","date":null,"permalink":"/tags/marketing-automation/","section":"Tags","summary":"","title":"Marketing-Automation"},{"content":"","date":null,"permalink":"/tags/marketing-tools/","section":"Tags","summary":"","title":"Marketing-Tools"},{"content":"","date":null,"permalink":"/tags/mautic/","section":"Tags","summary":"","title":"Mautic"},{"content":"","date":null,"permalink":"/tags/misconfiguration/","section":"Tags","summary":"","title":"Misconfiguration"},{"content":"","date":null,"permalink":"/tags/monitor/","section":"Tags","summary":"","title":"Monitor"},{"content":"","date":null,"permalink":"/tags/monitoring/","section":"Tags","summary":"","title":"Monitoring"},{"content":"","date":null,"permalink":"/tags/mysql/","section":"Tags","summary":"","title":"MySQL"},{"content":"","date":null,"permalink":"/tags/networkmanager/","section":"Tags","summary":"","title":"NetworkManager"},{"content":"","date":null,"permalink":"/tags/newsletter/","section":"Tags","summary":"","title":"Newsletter"},{"content":"","date":null,"permalink":"/tags/nginx/","section":"Tags","summary":"","title":"Nginx"},{"content":"Create directory for caching:\nmkdir /var/cache/nginx Edit /etc/nginx/conf.d/cache.conf:\n# Cache config proxy_cache_path /var/cache/nginx levels=1:2 use_temp_path=off keys_zone=cache:10m inactive=14d max_size=8G; # Cached item is valid for 10 minutes #proxy_cache_valid 10m; # use proxy if upstream not working #proxy_cache_use_stale error timeout updating http_502 http_503 http_504 http_429; # Update in the background #proxy_cache_revalidate on; proxy_cache_background_update on; #Enable caching proxy_cache cache; proxy_cache_lock on; proxy_cache_lock_age 20s; proxy_cache_lock_timeout 5s; ","date":"1 January 0001","permalink":"/posts/nginx/caching/","section":"Posts","summary":"Create directory for caching:","title":"Nginx Caching Configurations"},{"content":"Security configurations #TLS #Get a certificate from Let\u0026rsquo;s Encrypt:\ncertbot certonly --nginx -d example.com --key-type rsa --rsa-key-size 4096 Set TLS ciphers in Nginx server context:\nssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/example.com/fullchain.pem; Self signed certificate #Generate a self-signed certificate for 5 years:\nmkdir /etc/nginx/default_ssl openssl req -x509 -nodes -newkey rsa:4096 -keyout /etc/nginx/default_ssl/key.pem -out /etc/nginx/default_ssl/cert.pem -days 1825 Configure the certificate in server context:\nssl_certificate /etc/nginx/default_ssl/cert.pem; ssl_certificate_key /etc/nginx/default_ssl/key.pem; Diffie-Hellman parameters #openssl dhparam -out /etc/nginx/dhparam.pem 4096 Ciphers #List available ciphers:\nopenssl ciphers -ciphersuites `openssl ciphers -s -tls1_3` Strongest ciphers\nTLS_AES_256_GCM_SHA384 TLS_CHACHA20_POLY1305_SHA256 ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-CHACHA20-POLY1305 DHE-RSA-AES256-GCM-SHA384 DHE-RSA-CHACHA20-POLY1305 Important:\nPriority: AES over ChaCha Keysize must be \u0026gt;= 256 Configure TLS ciphers in http or server context:\nssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305; ssl_prefer_server_ciphers on; OpenSSL #If Nginx version \u0026gt;= 1.19.4:\nssl_conf_command Options ServerPreference; ssl_conf_command Ciphersuites TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256; Below Nginx 1.19.4, edit /etc/ssl/openssl.cnf:\nOptions = ServerPreference Ciphersuites = TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256 Basic authentication #apt install apache2-utils htpasswd -c /etc/nginx/.htpasswd user Use it in a location context:\nlocation /admin { auth_basic \u0026#34;Message\u0026#34;; auth_basic_user_file /etc/nginx/.htpasswd; } Sample configs #nginx.conf #user www-data; worker_processes auto; pid /run/nginx.pid; include /etc/nginx/modules-enabled/*.conf; events { worker_connections 1024; } http { # Basic Settings sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # Logging Settings access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; # Gzip Settings gzip off; # Virtual Host Configs include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } sites-available/example.com ## https server { # Enable SSL and HTTP2 listen [::]:443 ssl http2; listen 443 ssl http2; server_name example.com; # Set certificate path ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/example.com/fullchain.pem; # Enable OCSP ssl_stapling on; ssl_stapling_verify on; resolver 1.1.1.1 1.0.0.1; resolver_timeout 5s; # Add security headers add_header X-Frame-Options \u0026#34;SAMEORIGIN\u0026#34; always; add_header X-Content-Type-Options \u0026#34;nosniff\u0026#34; always; add_header Referrer-Policy \u0026#39;strict-origin\u0026#39; always; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34; always; add_header Strict-Transport-Security \u0026#34;max-age=63072000; includeSubdomains\u0026#34; always; # Set root path root /var/www/html; index index.php index.html index.htm; location / { try_files $uri $uri/ =404; } # Set basic authentication to /admin location /admin { # Basic authentication auth_basic \u0026#34;Message\u0026#34;; auth_basic_user_file /etc/nginx/.htpasswd; } # Set FastCGI location ~ \\.php$ { include snippets/fastcgi-php.conf; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; fastcgi_pass unix:/var/run/php/php-fpm.sock; } # Reverse proxy location /proxy { proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; proxy_ssl_trusted_certificate /etc/nginx/ssl/cert.pem; proxy_ssl_verify on; proxy_ssl_verify_depth 2; proxy_ssl_session_reuse on; proxy_pass http://127.0.0.1:8080; } # Disable accessing hidden files except .well-known location ~ /\\.(?!well-known).* { deny all; } # Disable unused methods if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 405; } # Custom error pages error_page 404 /404.html; error_page 500 /500.html; } # http server { listen 80; listen [::]:80; server_name example.com; # Redirect http to https return 301 https://$host$request_uri; } sites-enabled/default #server { listen [::]:443 ssl http2; listen 443 ssl http2; server_name _; ssl_certificate /etc/nginx/default_ssl/cert.pem; ssl_certificate_key /etc/nginx/default_ssl/key.pem; return 444; } server { listen 80; listen [::]:80; server_name _; return 444; } conf.d/security.conf ## Do not send server version server_tokens off; # Set TLS ciphers ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305; ssl_prefer_server_ciphers on; # Diffie-Hellman parameters ssl_dhparam /etc/nginx/dhparam.pem; ssl_ecdh_curve secp521r1:secp384r1; # SSL session reuse ssl_session_cache shared:SSL:10m; ssl_session_timeout 1d; ssl_session_tickets off; # Reduce Time To First Byte ssl_buffer_size 4k; Basic reverse proxy template ## https server { # Enable SSL and HTTP2 listen 443 ssl http2; server_name example.com; # Set certificate path ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/example.com/fullchain.pem; # Enable OCSP ssl_stapling on; ssl_stapling_verify on; resolver 1.1.1.1 1.0.0.1; resolver_timeout 5s; # Add security headers add_header X-Frame-Options \u0026#34;SAMEORIGIN\u0026#34; always; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34; always; add_header X-Content-Type-Options \u0026#34;nosniff\u0026#34; always; add_header Referrer-Policy \u0026#39;strict-origin\u0026#39; always; add_header Strict-Transport-Security \u0026#34;max-age=63072000\u0026#34; always; location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://127.0.0.1:8080; } } # http server { listen 80; server_name example.com; # Redirect http to https return 301 https://$host$request_uri; } Useful links # SSL Test OWASP Secure Headers Project Security Headers Mozilla Observatory GIXY SSL Configuration generator ","date":"1 January 0001","permalink":"/posts/nginx/configurations/","section":"Posts","summary":"Security configurations #TLS #Get a certificate from Let\u0026rsquo;s Encrypt:","title":"Nginx Configurations"},{"content":"Format #Combined #:::note This is the default log format in Nginx. :::\nlog_format combined \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#39; \u0026#39;\u0026#34;$request\u0026#34; $status $body_bytes_sent \u0026#39; \u0026#39;\u0026#34;$http_referer\u0026#34; \u0026#34;$http_user_agent\u0026#34;\u0026#39;; Vhost Combined #log_format vhost_combined \u0026#39;$host $remote_addr - $remote_user [$time_local] \u0026#39; \u0026#39;\u0026#34;$request\u0026#34; $status $body_bytes_sent \u0026#39; \u0026#39;\u0026#34;$http_referer\u0026#34; \u0026#34;$http_user_agent\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log vhost_combined; error_log /var/log/nginx/error.log; ","date":"1 January 0001","permalink":"/posts/nginx/logging/","section":"Posts","summary":"Format #Combined #:::note This is the default log format in Nginx.","title":"Nginx Logging Configurations"},{"content":"","date":null,"permalink":"/tags/node.js/","section":"Tags","summary":"","title":"Node.js"},{"content":"Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them. After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use. LTS release status is \u0026ldquo;long-term support\u0026rdquo;, which typically guarantees that critical bugs will be fixed for a total of 30 months. Production applications should only use Active LTS or Maintenance LTS releases.\n:::info Full details regarding Node.js release schedule are available on GitHub. :::\nEnd-of-Life Releases # Release Status Codename Initial Release Active LTS Start Maintenance LTS Start End-of-life v0.10.x End-of-Life - 2013-03-11 - 2015-10-01 2016-10-31 v0.12.x End-of-Life - 2015-02-06 - 2016-04-01 2016-12-31 4.x End-of-Life Argon 2015-09-08 2015-10-01 2017-04-01 2018-04-30 5.x End-of-Life 2015-10-29 - 2016-06-30 6.x End-of-Life Boron 2016-04-26 2016-10-18 2018-04-30 2019-04-30 7.x End-of-Life 2016-10-25 - 2017-06-30 8.x End-of-Life Carbon 2017-05-30 2017-10-31 2019-01-01 2019-12-31 9.x End-of-Life 2017-10-01 - 2018-06-30 10.x End-of-Life Dubnium 2018-04-24 2018-10-30 2020-05-19 2021-04-30 11.x End-of-Life 2018-10-23 - 2019-06-01 12.x End-of-Life Erbium 2019-04-23 2019-10-21 2020-11-30 2022-04-30 13.x End-of-Life 2019-10-22 - 2020-06-01 14.x End-of-Life Fermium 2020-04-21 2020-10-27 2021-10-19 2023-04-30 15.x End-of-Life 2020-10-20 - 2021-06-01 16.x End-of-Life Gallium 2021-04-20 2021-10-26 2022-10-18 2023-09-11 17.x End-of-Life 2021-10-19 - 2022-06-01 19.x End-of-Life 2022-10-18 - 2023-06-01 ","date":"1 January 0001","permalink":"/posts/nodejs/release-schedule/","section":"Posts","summary":"Major Node.","title":"Node.js Release Schedule"},{"content":"","date":null,"permalink":"/tags/nosql/","section":"Tags","summary":"","title":"Nosql"},{"content":"","date":null,"permalink":"/tags/npm/","section":"Tags","summary":"","title":"Npm"},{"content":"","date":null,"permalink":"/tags/openproject/","section":"Tags","summary":"","title":"OpenProject"},{"content":"","date":null,"permalink":"/tags/openssh/","section":"Tags","summary":"","title":"OpenSSH"},{"content":"","date":null,"permalink":"/tags/performance/","section":"Tags","summary":"","title":"Performance"},{"content":"","date":null,"permalink":"/tags/php/","section":"Tags","summary":"","title":"Php"},{"content":"","date":null,"permalink":"/tags/pinentry/","section":"Tags","summary":"","title":"Pinentry"},{"content":"Introduction #This manual documents how to use the PINENTRY and its protocol.\nThe PINENTRY is a small GUI application used to enter PINs or passphrases. It is usually invoked by GPG-AGENT (*note Invoking the gpg-agent: (gnupg)Invoking GPG-AGENT, for details).\nPINENTRY comes in several flavors to fit the look and feel of the used GUI toolkit: A GTK+ based one named pinentry-gtk; a QT based one named pinentry-qt; and, two non-graphical ones pinentry-curses, which uses curses, and pinentry-tty, which doesn\u0026rsquo;t require anything more than a simple terminal. Not all of them are necessarily available on your installation. If curses is supported on your system, the GUI-based flavors fall back to curses when the DISPLAY variable is not set.\nHow to use the PINENTRY #You may run PINENTRY directly from the command line and pass the commands according to the Assuan protocol via stdin/stdout.\nHere is a list of options supported by all flavors of pinentry:\n--version: Print the program version and licensing information.\n--help: Print a usage message summarizing the most useful command line options.\n--debug -d: Turn on some debugging. Mostly useful for the maintainers. Note that this may reveal sensitive information like the entered passphrase.\n--no-global-grab -g: Grab the keyboard only when the window is focused. Use this option if you are debugging software using the PINENTRY; otherwise you may not be able to to access your X session anymore (unless you have other means to connect to the machine to kill the PINENTRY).\n--parent-wid N: Use window ID N as the parent window for positioning the window. Note, that this is not fully supported by all flavors of PINENTRY.\n--timeout SECONDS: Give up waiting for input from the user after the specified number of seconds and return an error. The error returned is the same as if the Cancel button was selected. To disable the timeout and wait indefinitely, set this to 0, which is the default.\n--display STRING --ttyname STRING --ttytype STRING --lc-ctype STRING --lc-messages STRING: These options are used to pass localization information to PINENTRY. They are required because PINENTRY is usually called by some background process which does not have any information about the locale and terminal to use. It is also possible to pass these options using Assuan protocol options.\nFront Ends #There are several different flavors of PINENTRY. Concretely, there are Gtk+2, Qt 4/5, TQt, EFL, FLTK, Gnome 3, Emacs, curses and tty variants. These different implementations provide higher levels of integration with a specific environment. For instance, the Gnome 3 PINENTRY uses Gnome 3 widgets to display the prompts. For Gnome 3 users, this higher level of integration provides a more consistent aesthetic. However, this comes at a cost. Because this PINENTRY uses so many components, there is a larger chance of a failure. In particular, there is a larger chance that the passphrase is saved in memory and that memory is exposed to an attacker (consider the OpenSSL Heartbeat vulnerability).\nTo understand how many components touch the passphrase, consider again the Gnome 3 implementation. When a user presses a button on the keyboard, the key is passed from the kernel to the X server to the toolkit (Gtk+) and to the actual text entry widget. Along the way, the key is saved in memory and processed. In fact, the key presses are probably read using standard C library functions, which buffer the input. None of this code is careful to make sure the contents of the memory are not leaked by keeping the data in unpagable memory and wiping it when the buffer is freed. However, even if they did, there is still the problem that when a computer hibernates, the system writes unpagable memory to disk anyway. Further, many installations are virtualized (e.g., running on Xen) and have little control over their actual environment.\nThe curses variant uses a significant smaller software stack and the tty variant uses an even smaller one. However, if they are run in an X terminal, then a similar number of components are handling the passphrase as in the Gnome 3 case! Thus, to be most secure, you need to direct GPG Agent to use a fixed virtual console. Since you need to remain logged in for GPG Agent to use that console, you should run there and have screen or tmux lock the tty.\nThe Emacs pinentry implementation interacts with a running Emacs session and directs the Emacs instance to display the passphrase prompt. Since this doesn\u0026rsquo;t work very well if there is no Emacs running, the generic PINENTRY backend checks if a PINENTRY-enabled Emacs should be used. Specifically, it looks to see if the INSIDE_EMACS variable is set and then attempts to establish a connection to the specified address. If this is the case, then instead of, e.g., pinentry-gtk2 displaying a Gtk+2 pinentry, it interacts with the Emacs session. This functionality can be explicitly disabled by passing --disable-inside-emacs to configure when building PINENTRY.\nHaving Emacs get the passphrase is convenient, however, it is a significant security risk. Emacs is a huge program, which doesn\u0026rsquo;t provide any process isolation to speak of. As such, having it handle the passphrase adds a huge chunk of code to the user\u0026rsquo;s trusted computing base. Because of this concern, Emacs doesn\u0026rsquo;t enable this by default, unless the allow-emacs-pinentry option is explicitly set in his or her .gnupg/gpg-agent.conf file.\nSimilar to the inside-emacs check, the PINENTRY frontends check whether the DISPLAY variable is set and a working X server is available. If this is not the case, then they fallback to the curses front end. This can also be disabled by passing --disable-fallback-curses to configure at build time.\nPINENTRY\u0026rsquo;s Assuan Protocol #The PINENTRY should never service more than one connection at once. It is reasonable to exec the PINENTRY prior to a request.\nThe PINENTRY does not need to stay in memory because the GPG-AGENT has the ability to cache passphrases. The usual way to run the PINENTRY is by setting up a pipe (not a socket) and then fork/exec the PINENTRY. The communication is then done by means of the protocol described here until the client is satisfied with the result.\nAlthough it is called a PINENTRY, it allows entering reasonably long strings (strings that are up to 2048 characters long are supported by every pinentry). The client using the PINENTRY has to check for correctness.\nNote that all strings are expected to be encoded as UTF-8; PINENTRY takes care of converting it to the locally used codeset. To include linefeeds or other special characters, you may percent-escape them (e.g., a line feed is encoded as %0A, the percent sign itself is encoded as %25, etc.).\nThe following is a list of supported commands:\nSet the timeout before returning an error # C: SETTIMEOUT 30 S: OK Set the descriptive text to display # C: SETDESC Enter PIN for Richard Nixon \u0026lt;nobody@trickydicky.gov\u0026gt; S: OK Set the prompt to show #When asking for a PIN, set the text just before the widget for passphrase entry.\nC: SETPROMPT PIN: S: OK You should use an underscore in the text only if you know that a modern version of pinentry is used. Modern versions underline the next character after the underscore and use the first such underlined character as a keyboard accelerator. Use a double underscore to escape an underscore.\nSet the window title #This command may be used to change the default window title. When using this feature you should take care that the window is still identifiable as the pinentry.\nC: SETTITLE Tape Recorder Room S: OK Set the button texts #There are three texts which should be used to override the English defaults:\nTo set the text for the button signaling confirmation (in UTF-8). See SETPROMPT on how to use an keyboard accelerator.\nC: SETOK Yes S: OK To set the text for the button signaling cancellation or disagreement (in UTF-8). See SETPROMPT on how to use an keyboard accelerator.\nC: SETCANCEL No S: OK In case three buttons are required, use the following command to set the text (UTF-8) for the non-affirmative response button. The affirmative button text is still set using SETOK and the CANCEL button text with SETCANCEL. See SETPROMPT on how to use an keyboard accelerator.\nC: SETNOTOK Do not do this S: OK Set the Error text #This is used by the client to display an error message. In contrast to the other commands, the error message is automatically reset with a GETPIN or CONFIRM, and is only displayed when asking for a PIN.\nC: SETERROR Invalid PIN entered - please try again S: OK Enable a passphrase quality indicator #Adds a quality indicator to the GETPIN window. This indicator is updated as the passphrase is typed. The clients needs to implement an inquiry named \u0026ldquo;QUALITY\u0026rdquo; which gets passed the current passphrase (percent-plus escaped) and should send back a string with a single numerical value between -100 and 100. Negative values will be displayed in red.\nC: SETQUALITYBAR S: OK If a custom label for the quality bar is required, just add that label as an argument as a percent-escaped string. You will need this feature to translate the label because PINENTRY has no internal gettext except for stock strings from the toolkit library.\nIf you want to show a tooltip for the quality bar, you may use\nC: SETQUALITYBAR_TT string S: OK With STRING being a percent escaped string shown as the tooltip.\nEnable enforcement of passphrase constraints #This will make the pinentry check whether the new passphrase entered by the user satisfies the passphrase constraints before passing the passphrase to gpg-agent and closing the pinentry. This gives the user the chance to modify the passphrase until the constraints are satisfied without retyping the passphrase.\nC: OPTION constraints-enforce S: OK To inform the user about the constraints a short hint and a longer hint can be set using\nC: OPTION constraints-hint-short=At least 8 characters S: OK C: OPTION constraints-hint-long=The passphrase must \u0026hellip; S: OK Additionally, a title for the dialog showing details in case of unsatisfied constraints can be set using\nC: OPTION constraints-error-title=Passphrase Not Allowed S: OK All strings have to be percent escaped.\nEnable an action for generating a passphrase #Adds an action for generating a random passphrase to the GETPIN window. The action is only available when asking for a new passphrase, i.e. if SETREPEAT has been called.\nC: SETGENPIN Suggest S: OK If you want to provide a tooltip for the action, you may use\nC: SETGENPIN_TT Suggest a random passphrase S: OK Enable passphrase formatting #Passphrase formatting will group the characters of the passphrase into groups of five characters separated by non-breaking spaces or a similar separator. This is useful in combination with passphrase generation to make the generated passphrase easier readable.\nC: OPTION formatted-passphrase S: OK Note: If passphrase formatting is enabled, then, depending on the concrete pinentry, all occurrences of the character used as separator may be stripped from the entered passphrase.\nTo provide a hint for the user that is shown if passphrase formatting is enabled use\nC: OPTION formatted-passphrase-hint=Blanks are not part of the passphrase. S: OK Ask for a PIN #The meat of this tool is to ask for a passphrase of PIN, it is done with this command:\nC: GETPIN S: D no more tapes S: OK Note that the passphrase is transmitted in clear using standard data responses. Expect it to be in UTF-8.\nAsk for confirmation #To ask for a confirmation (yes or no), you can use this command:\nC: CONFIRM S: OK The client should use SETDESC to set an appropriate text before issuing this command, and may use SETPROMPT to set the button texts. The value returned is either OK for YES or the error code\nASSUAN_Not_Confirmed. #Show a message #To show a message, you can use this command:\nC: MESSAGE S: OK alternatively you may add an option to confirm:\nC: CONFIRM \u0026ndash;one-button S: OK The client should use SETDESC to set an appropriate text before issuing this command, and may use SETOK to set the text for the dismiss button. The value returned is OK or an error message.\nSet the output device #When using X, the PINENTRY program must be invoked with an appropriateDISPLAYenvironment variable or the`\u0026ndash;display' option.\nWhen using a text terminal:\nC: OPTION ttyname=/dev/tty3 S: OK C: OPTION ttytype=vt100 S: OK C: OPTION lc-ctype=de_DE.UTF-8 S: OK The client should use thettynameoption to set the output TTY file name, thettytypeoption to theTERMvariable appropriate for this tty andlc-ctypeto the locale which defines the character set to use for this terminal.\nSet the default strings #To avoid having translations in Pinentry proper, the caller may set certain translated strings which are used by PINENTRY as default strings.\nC: OPTION default-ok=_Korrekt S: OK C: OPTION default-cancel=Abbruch S: OK C: OPTION default-prompt=PIN eingeben: S: OK The strings are subject to accelerator marking, see SETPROMPT for details.\nPassphrase caching #Some environments, such as GNOME, cache passwords and passphrases. The PINENTRY should only use an external cache if the allow-external-password-cacheoption was set and a stable key identifier (using SETKEYINFO) was provided. In this case, if the passphrase was read from the cache, the PINENTRY should send the PASSWORD_FROM_CACHE status message before returning the passphrase. This indicates to GPG Agent that it should not increment the passphrase retry counter.\nC: OPTION allow-external-password-cache S: OK C: SETKEYINFO key-grip S: OK C: getpin S: S PASSWORD_FROM_CACHE S: D 1234 S: OK Note: ifallow-external-password-cacheis not specified, an external password cache must not be used: this can lead to subtle bugs. In particular, if this option is not specified, then GPG Agent does not recognize thePASSWORD_FROM_CACHEstatus message and will count trying a cached password against the password retry count. If the password retry count is 1, then the user will never have the opportunity to correct the cached password.\nNote: it is strongly recommended that a pinentry supporting this feature provide the user an option to enable it manually. That is, saving a passphrase in an external password manager should be opt-in.\nThe key identifier provided SETKEYINFO must be considered opaque and may change in the future. It currently has the form X/HEXSTRING where X is eithern,s, oru. In the former two cases, the HEXSTRING corresponds to the key grip. The key grip is not the OpenPGP Key ID, but it can be mapped to the key using the following:\ngpg2 --with-keygrip --list-secret-keys and searching the output for the key grip. The same command-line options can also be used with gpgsm.\nImplementation Details #The pinentry source code can be divided into three categories. There is a backend module, which lives inpinentry/, there are utility functions, e.g., insecmem/, and there are various frontends.\nAll of the low-level logic lives in the backend. This frees the frontends from having to implement, e.g., the Assuan protocol. When the backend receives an option, it updates the state in apinentry_t struct. The frontend is called when the client either callsGETPIN, CONFIRM or MESSAGE. In these cases, the backend invokes the pinentry_cmd_handler, which is passed thepinentry_tstruct.\nWhen the callback is invoked, the frontend should create a window based on the state in thepinentry_tstruct. For instance, the title to use for the dialog\u0026rsquo;s window (if any) is stored in thetitlefield. If the isNULL, the frontend should choose a reasonable default value. (Default is not always provided, because different tool kits and environments have different reasonable defaults.)\nThe widget needs to support a number of different interactions with the user. Each of them is described below.\nPassphrase Confirmation #When creating a new key, the passphrase should be entered twice. The client (typically GPG Agent) indicates this to the PINENTRY by invokingSETREPEAT. In this case, the backend sets the repeat_passphrase field to a copy of the passed string. The value of this field should be used to label a second text input.\nIt is the frontend\u0026rsquo;s responsibility to check that the passwords match. If they don\u0026rsquo;t match, the frontend should display an error message and continue to prompt the user.\nIf the passwords do match, then, when the user presses the okay button, therepeat_okayfield should be set to1(this causes the backend to emit theS PIN_REPEATEDstatus message).\nMessage Box #Sometimes GPG Agent needs to display a message. In this case, the pin variable isNULL.\nAt the Assuan level, this mode is selected by using either the MESSAGE or the CONFIRMcommand instead of theGETPINcommand. TheMESSAGEcommand never shows the cancel or an other button. The same holds forCONFIRMif it was passed the \u0026ldquo;-one-button\u0026rdquo; argument. IfCONFIRMwas not passed this argument, the dialog forCONFIRMshould show both theokand thecancelbuttons and optionally thenotokbutton. The frontend can determine whether the dialog is a one-button dialog by inspecting the one_button variable.\nPassphrase Entry #If neither of the above cases holds, then GPG Agent is simply requesting the passphrase. In this case, theokand`cancel' buttons should be displayed.\nThe layout of the three variants is quite similar. Here are the relevant elements that describe the layout:\ntitle #The window\u0026rsquo;s title.\ndescription #The reason for the dialog. When requesting a passphrase, this describes the key. When showing a message box, this is the message to show.\nerror #If GPG Agent determines that the passphrase was incorrect, it will callGETPINagain (up to a configurable number of times) to again prompt the user. In this case, this variable contains a description of the error message. This text should typically be highlighted in someway.\nprompt, default-prompt #The string to associate with the passphrase entry box.\nThere is a subtle difference betweenpromptanddefault-prompt. default-promptmeans that a stylized prompt (e.g., an icon suggesting a prompt) may be used. promptmeans that the entry\u0026rsquo;s meaning is not consistent with such a style and, as such, no icon should be used.\nIf both variables are set, thepromptvariant takes precedence.\nrepeat_passphrase #The string to associate with the second passphrase entry box. The second passphrase entry box should only be shown if this is not NULL.\nok, default-ok #The string to show in theokbutton.\nIf there are any_characters, the following character should be used as an accelerator. (A double underscore means a plain underscore should be shown.) If the frontend does not support accelerators, then the underscores should be removed manually.\nThere is a subtle difference betweenokanddefault-ok. default-ok means that a stylized OK button should be used. For instance, it could include a check mark. okmeans that the button\u0026rsquo;s meaning is not consistent with such an icon and, as such, no icon should be used. Thus, if theokbutton should have the text \u0026ldquo;No password required\u0026rdquo; thenokshould be used because a check mark icon doesn\u0026rsquo;t make sense.\nIf this variable isNULL, the frontend should choose a reasonable default.\nIf both variables are set, theokvariant takes precedence.\ncancel, default-cancel #Like theokanddefault-okbuttons except these strings are used for the cancel button.\nThis button should not be shown ifone_buttonis set.\ndefault-notokLike thedefault-okbutton except this string is used for the other button.\nThis button should only be displayed when showing a message box. If these variables areNULLorone_buttonis set, this button should not be displayed.\nquality_bar #If this is set, a widget should be used to show the password\u0026rsquo;s quality. The value of this field is a label for the widget.\nNote: to update the password quality, whenever the password changes, call thepinentry_inq_qualityfunction and then update the password quality widget correspondingly.\nquality_bar_tt #A tooltip for the quality bar.\nconstraints_enforce #If this is not 0, then passphrase constraints are enforced by gpg-agent. In this case pinentry can use the pinentry_inq_checkpinfunction for checking whether the new passphrase satisfies the constraints before passing it to gpg-agent.\nconstraints_hint_short #A short translated hint for the user with the constraints for new passphrases to be displayed near the passphrase input field.\nconstraints_hint_short #A longer translated hint for the user with the constraints for new passphrases to be displayed for example as tooltip.\nconstraints_error_title #A short translated title for an error dialog informing the user about unsatisfied passphrase constraints.\ngenpin_label #If this is set, a generate action should be shown. The value of this field is a label for the action.\nNote: Call thepinentry_inq_genpinfunction to request a randomly generated passphrase.\ngenpin_tt #The tooltip for the generate action.\nformatted_passphrase #If this is not 0, then passphrase formatting should be enabled. If it is enabled, then the unmasked passphrase should be grouped into groups of five characters separated by non-breaking spaces or a similar separator.\nTo simplify the implementation all occurrences of the character used as separator can be stripped from the entered passphrase, if formatting is enabled.\nformatted_passphrase_hint #A hint to be shown if passphrase formatting is enabled. It should be shown near the passphrase input field.\ndefault_pwmngr #Ifmay_cache_passwordandkeyinfoare set and the user consents, then the PINENTRY may cache the password with an external manager. Note: getting the user\u0026rsquo;s consent is essential, because password managers often provide a different level of security. If the above condition is true andtried_password_cacheis false, then a check box with the specified string should be displayed. The check box must default to off.\ndefault-cf-visi #The string to show with a question if you want to confirm that the user wants to change the visibility of the password.\ndefault-tt-visi #Tooltip for an action that would reveal the entered password.\ndefault-tt-hide #Tooltip for an action that would hide the password revealed by the action labeld withdefault-tt-visi\ndefault-capshint #A hint to be shown if Caps Lock is on.\nWhen the handler is done, it should store the passphrase inpin, if appropriate. This variable is allocated in secure memory. Use pinentry_setbufferlento size the buffer.\nThe actual return code is dependent on whether the dialog is in message mode or in passphrase mode.\nIf the dialog is in message mode and the user pressed ok, return 1. Otherwise, return 0. If an error occurred, indicate this by setting it inspecific_error settinglocale_errto1(for locale specific errors). If the dialog was canceled, then the handler should set the canceledvariable to1. If the not ok button was pressed, don\u0026rsquo;t do anything else.\nIf the dialog is in passphrase mode return1if the user entered a password and pressed ok. If an error occurred, return-1and set specific_err or locale_err, as above. If the user canceled the dialog box, return-1.\nIf the window was closed, then the handler should set the close_button variable and otherwise act as if the cancel button was pressed.\n:::note\nThis wall of text is a Markdown formatted copy of the original documentation.\n:::\n","date":"1 January 0001","permalink":"/posts/gnupg/pinentry/documentation/","section":"Posts","summary":"Introduction #This manual documents how to use the PINENTRY and its protocol.","title":"Pinentry Documentation"},{"content":"","date":null,"permalink":"/tags/privacy/","section":"Tags","summary":"","title":"Privacy"},{"content":"","date":null,"permalink":"/tags/proxy/","section":"Tags","summary":"","title":"Proxy"},{"content":"","date":null,"permalink":"/tags/raid/","section":"Tags","summary":"","title":"Raid"},{"content":"","date":null,"permalink":"/tags/self-hosted/","section":"Tags","summary":"","title":"Self-Hosted"},{"content":"","date":null,"permalink":"/tags/selfhosted/","section":"Tags","summary":"","title":"Selfhosted"},{"content":"","date":null,"permalink":"/tags/service/","section":"Tags","summary":"","title":"Service"},{"content":"TL;DR #nano /etc/systemd/system/\u0026lt;name\u0026gt;.service [Unit] Description= After= [Service] User= Group= WorkingDirectory= Type= Restart=always RestartSec=1 ExecStart= ExecStop= [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl enable ... systemctl start ... Directories # /usr/lib/systemd/system/: units provided by installed packages /etc/systemd/system/: units installed by the system administrator systemctl #Reload new/modified unit files:\nsystemctl daemon-reload Start unit file at boot:\nsystemctl enable example.service Start unit:\nsystemctl start example.service Options #Type= #Configures the mechanism via which the service notifies the manager that the service start-up has finished. One of simple, exec, forking, oneshot, dbus, notify, notify-reload, or idle:\nsimple #If set to simple (the default if ExecStart= is specified but neither Type= nor BusName= are), the service manager will consider the unit started immediately after the main service process has been forked off (i.e. immediately after fork(), and before various process attributes have been configured and in particular before the new process has called execve() to invoke the actual service binary). Typically, Type=exec is the better choice, see below.\nIt is expected that the process configured with ExecStart= is the main process of the service. In this mode, if the process offers functionality to other processes on the system, its communication channels should be installed before the service is started up (e.g. sockets set up by systemd, via socket activation), as the service manager will immediately proceed starting follow-up units, right after creating the main service process, and before executing the service\u0026rsquo;s binary. Note that this means systemctl start command lines for simple services will report success even if the service\u0026rsquo;s binary cannot be invoked successfully (for example because the selected User= doesn\u0026rsquo;t exist, or the service binary is missing).\nexec #The exec type is similar to simple, but the service manager will consider the unit started immediately after the main service binary has been executed. The service manager will delay starting of follow-up units until that point. (Or in other words: simple proceeds with further jobs right after fork() returns, while exec will not proceed before both fork() and execve() in the service process succeeded.) Note that this means systemctl start command lines for exec services will report failure when the service\u0026rsquo;s binary cannot be invoked successfully (for example because the selected User= doesn\u0026rsquo;t exist, or the service binary is missing).\nforking #If set to forking, the manager will consider the unit started immediately after the binary that forked off by the manager exits. The use of this type is discouraged, use notify, notify-reload, or dbus instead.\nIt is expected that the process configured with ExecStart= will call fork() as part of its start-up. The parent process is expected to exit when start-up is complete and all communication channels are set up. The child continues to run as the main service process, and the service manager will consider the unit started when the parent process exits. This is the behavior of traditional UNIX services. If this setting is used, it is recommended to also use the PIDFile= option, so that systemd can reliably identify the main process of the service. The manager will proceed with starting follow-up units after the parent process exits.\noneshot #Behavior of oneshot is similar to simple; however, the service manager will consider the unit up after the main process exits. It will then start follow-up units. RemainAfterExit= is particularly useful for this type of service. Type=oneshot is the implied default if neither Type= nor ExecStart= are specified. Note that if this option is used without RemainAfterExit= the service will never enter \u0026ldquo;active\u0026rdquo; unit state, but will directly transition from \u0026ldquo;activating\u0026rdquo; to \u0026ldquo;deactivating\u0026rdquo; or \u0026ldquo;dead\u0026rdquo;, since no process is configured that shall run continuously. In particular this means that after a service of this type ran (and which has RemainAfterExit= not set) it will not show up as started afterwards, but as dead.\ndbus #Behavior of dbus is similar to simple; however, units of this type must have the BusName= specified and the service manager will consider the unit up when the specified bus name has been acquired. This type is the default if BusName= is specified.\nService units with this option configured implicitly gain dependencies on the dbus.socket unit. A service unit of this type is considered to be in the activating state until the specified bus name is acquired. It is considered activated while the bus name is taken. Once the bus name is released the service is considered being no longer functional which has the effect that the service manager attempts to terminate any remaining processes belonging to the service. Services that drop their bus name as part of their shutdown logic thus should be prepared to receive a SIGTERM (or whichever signal is configured in KillSignal=) as result.\nnotify #Behavior of notify is similar to exec; however, it is expected that the service sends a \u0026ldquo;READY=1\u0026rdquo; notification message via sd_notify(3) or an equivalent call when it has finished starting up. systemd will proceed with starting follow-up units after this notification message has been sent. If this option is used, NotifyAccess= (see below) should be set to open access to the notification socket provided by systemd. If NotifyAccess= is missing or set to none, it will be forcibly set to main.\nIf the service supports reloading, and uses a signal to start the reload, using notify-reload instead is recommended.\nnotify-reload #Behavior of notify-reload is similar to notify, with one difference: the SIGHUP UNIX process signal is sent to the service\u0026rsquo;s main process when the service is asked to reload and the manager will wait for a notification about the reload being finished.\nWhen initiating the reload process the service is expected to reply with a notification message via sd_notify(3) that contains the \u0026ldquo;RELOADING=1\u0026rdquo; field in combination with \u0026ldquo;MONOTONIC_USEC=\u0026rdquo; set to the current monotonic time (i.e. CLOCK_MONOTONIC in clock_gettime(2)) in μs, formatted as decimal string. Once reloading is complete another notification message must be sent, containing \u0026ldquo;READY=1\u0026rdquo;. Using this service type and implementing this reload protocol is an efficient alternative to providing an ExecReload= command for reloading of the service\u0026rsquo;s configuration.\nThe signal to send can be tweaked via ReloadSignal=, see below.\nidle #Behavior of idle is very similar to simple; however, actual execution of the service program is delayed until all active jobs are dispatched. This may be used to avoid interleaving of output of shell services with the status output on the console. Note that this type is useful only to improve console output, it is not useful as a general unit ordering tool, and the effect of this service type is subject to a 5s timeout, after which the service program is invoked anyway.\nIt is recommended to use Type=exec for long-running services, as it ensures that process setup errors (e.g. errors such as a missing service executable, or missing user) are properly tracked. However, as this service type won\u0026rsquo;t propagate the failures in the service\u0026rsquo;s own startup code (as opposed to failures in the preparatory steps the service manager executes before execve()) and doesn\u0026rsquo;t allow ordering of other units against completion of initialization of the service code itself (which for example is useful if clients need to connect to the service through some form of IPC, and the IPC channel is only established by the service itself — in contrast to doing this ahead of time through socket or bus activation or similar), it might not be sufficient for many cases. If so, notify, notify-reload, or dbus (the latter only in case the service provides a D-Bus interface) are the preferred options as they allow service program code to precisely schedule when to consider the service started up successfully and when to proceed with follow-up units. The notify/notify-reload service types require explicit support in the service codebase (as sd_notify() or an equivalent API needs to be invoked by the service at the appropriate time) — if it\u0026rsquo;s not supported, then forking is an alternative: it supports the traditional heavy-weight UNIX service start-up protocol. Note that using any type other than simple possibly delays the boot process, as the service manager needs to wait for at least some service initialization to complete. (Also note it is generally not recommended to use idle or oneshot for long-running services.)\nNote that various service settings (e.g. User=, Group= through libc NSS) might result in \u0026ldquo;hidden\u0026rdquo; blocking IPC calls to other services when used. Sometimes it might be advisable to use the simple service type to ensure that the service manager\u0026rsquo;s transaction logic is not affected by such potentially slow operations and hidden dependencies, as this is the only service type where the service manager will not wait for such service execution setup operations to complete before proceeding.\nExitType= #Specifies when the manager should consider the service to be finished. One of main or cgroup:\nmain #If set to main (the default), the service manager will consider the unit stopped when the main process, which is determined according to the Type=, exits. Consequently, it cannot be used with Type=oneshot.\ncgroup #If set to cgroup, the service will be considered running as long as at least one process in the cgroup has not exited.\nIt is generally recommended to use ExitType=main when a service has a known forking model and a main process can reliably be determined. ExitType= cgroup is meant for applications whose forking model is not known ahead of time and which might not have a specific main process. It is well suited for transient or automatically generated services, such as graphical applications inside of a desktop environment.\nAdded in version 250.\nRemainAfterExit= #Takes a boolean value that specifies whether the service shall be considered active even when all its processes exited. Defaults to no.\nGuessMainPID= #Takes a boolean value that specifies whether systemd should try to guess the main PID of a service if it cannot be determined reliably. This option is ignored unless Type=forking is set and PIDFile= is unset because for the other types or with an explicitly configured PID file, the main PID is always known. The guessing algorithm might come to incorrect conclusions if a daemon consists of more than one process. If the main PID cannot be determined, failure detection and automatic restarting of a service will not work reliably. Defaults to yes.\nPIDFile= #Takes a path referring to the PID file of the service. Usage of this option is recommended for services where Type= is set to forking. The path specified typically points to a file below /run/. If a relative path is specified it is hence prefixed with /run/. The service manager will read the PID of the main process of the service from this file after start-up of the service. The service manager will not write to the file configured here, although it will remove the file after the service has shut down if it still exists. The PID file does not need to be owned by a privileged user, but if it is owned by an unprivileged user additional safety restrictions are enforced: the file may not be a symlink to a file owned by a different user (neither directly nor indirectly), and the PID file must refer to a process already belonging to the service.\nNote that PID files should be avoided in modern projects. Use Type=notify, Type=notify-reload or Type=simple where possible, which does not require use of PID files to determine the main process of a service and avoids needless forking. BusName=\nTakes a D-Bus destination name that this service shall use. This option is mandatory for services where Type= is set to dbus. It is recommended to always set this property if known to make it easy to map the service name to the D-Bus destination. In particular, systemctl service-log-level/service-log-target verbs make use of this.\nExecStart= #Commands that are executed when this service is started. The value is split into zero or more command lines according to the rules described in the section \u0026ldquo;Command Lines\u0026rdquo; below.\nUnless Type= is oneshot, exactly one command must be given. When Type=oneshot is used, zero or more commands may be specified. Commands may be specified by providing multiple command lines in the same directive, or alternatively, this directive may be specified more than once with the same effect. If the empty string is assigned to this option, the list of commands to start is reset, prior assignments of this option will have no effect. If no ExecStart= is specified, then the service must have RemainAfterExit=yes and at least one ExecStop= line set. (Services lacking both ExecStart= and ExecStop= are not valid.)\nIf more than one command is specified, the commands are invoked sequentially in the order they appear in the unit file. If one of the commands fails (and is not prefixed with \u0026ldquo;-\u0026rdquo;), other lines are not executed, and the unit is considered failed.\nUnless Type=forking is set, the process started via this command line will be considered the main process of the daemon.\nExecStartPre=, ExecStartPost= #Additional commands that are executed before or after the command in ExecStart=, respectively. Syntax is the same as for ExecStart=, except that multiple command lines are allowed and the commands are executed one after the other, serially.\nIf any of those commands (not prefixed with \u0026ldquo;-\u0026rdquo;) fail, the rest are not executed and the unit is considered failed.\nExecStart= commands are only run after all ExecStartPre= commands that were not prefixed with a \u0026ldquo;-\u0026rdquo; exit successfully.\nExecStartPost= commands are only run after the commands specified in ExecStart= have been invoked successfully, as determined by Type= (i.e. the process has been started for Type=simple or Type=idle, the last ExecStart= process exited successfully for Type=oneshot, the initial process exited successfully for Type=forking, \u0026ldquo;READY=1\u0026rdquo; is sent for Type=notify/Type=notify-reload, or the BusName= has been taken for Type=dbus).\nNote that ExecStartPre= may not be used to start long-running processes. All processes forked off by processes invoked via ExecStartPre= will be killed before the next service process is run.\nNote that if any of the commands specified in ExecStartPre=, ExecStart=, or ExecStartPost= fail (and are not prefixed with \u0026ldquo;-\u0026rdquo;, see above) or time out before the service is fully up, execution continues with commands specified in ExecStopPost=, the commands in ExecStop= are skipped.\nNote that the execution of ExecStartPost= is taken into account for the purpose of Before=/After= ordering constraints.\nExecCondition= #Optional commands that are executed before the commands in ExecStartPre=. Syntax is the same as for ExecStart=, except that multiple command lines are allowed and the commands are executed one after the other, serially.\nThe behavior is like an ExecStartPre= and condition check hybrid: when an ExecCondition= command exits with exit code 1 through 254 (inclusive), the remaining commands are skipped and the unit is not marked as failed. However, if an ExecCondition= command exits with 255 or abnormally (e.g. timeout, killed by a signal, etc.), the unit will be considered failed (and remaining commands will be skipped). Exit code of 0 or those matching SuccessExitStatus= will continue execution to the next commands.\nThe same recommendations about not running long-running processes in ExecStartPre= also applies to ExecCondition=. ExecCondition= will also run the commands in ExecStopPost=, as part of stopping the service, in the case of any non-zero or abnormal exits, like the ones described above.\nAdded in version 243.\nExecReload= #Commands to execute to trigger a configuration reload in the service. This argument takes multiple command lines, following the same scheme as described for ExecStart= above. Use of this setting is optional. Specifier and environment variable substitution is supported here following the same scheme as for ExecStart=.\nOne additional, special environment variable is set: if known, $MAINPID is set to the main process of the daemon, and may be used for command lines like the following:\nExecReload=kill -HUP $MAINPID\nNote however that reloading a daemon by enqueuing a signal (as with the example line above) is usually not a good choice, because this is an asynchronous operation and hence not suitable when ordering reloads of multiple services against each other. It is thus strongly recommended to either use Type=notify-reload in place of ExecReload=, or to set ExecReload= to a command that not only triggers a configuration reload of the daemon, but also synchronously waits for it to complete. For example, dbus-broker(1) uses the following:\nExecReload=busctl call org.freedesktop.DBus \\ /org/freedesktop/DBus org.freedesktop.DBus \\ ReloadConfig ExecStop= #Commands to execute to stop the service started via ExecStart=. This argument takes multiple command lines, following the same scheme as described for ExecStart= above. Use of this setting is optional. After the commands configured in this option are run, it is implied that the service is stopped, and any processes remaining for it are terminated according to the KillMode= setting (see systemd.kill(5)). If this option is not specified, the process is terminated by sending the signal specified in KillSignal= or RestartKillSignal= when service stop is requested. Specifier and environment variable substitution is supported (including $MAINPID, see above).\nNote that it is usually not sufficient to specify a command for this setting that only asks the service to terminate (for example, by sending some form of termination signal to it), but does not wait for it to do so. Since the remaining processes of the services are killed according to KillMode= and KillSignal= or RestartKillSignal= as described above immediately after the command exited, this may not result in a clean stop. The specified command should hence be a synchronous operation, not an asynchronous one.\nNote that the commands specified in ExecStop= are only executed when the service started successfully first. They are not invoked if the service was never started at all, or in case its start-up failed, for example because any of the commands specified in ExecStart=, ExecStartPre= or ExecStartPost= failed (and weren\u0026rsquo;t prefixed with \u0026ldquo;-\u0026rdquo;, see above) or timed out. Use ExecStopPost= to invoke commands when a service failed to start up correctly and is shut down again. Also note that the stop operation is always performed if the service started successfully, even if the processes in the service terminated on their own or were killed. The stop commands must be prepared to deal with that case. $MAINPID will be unset if systemd knows that the main process exited by the time the stop commands are called.\nService restart requests are implemented as stop operations followed by start operations. This means that ExecStop= and ExecStopPost= are executed during a service restart operation.\nIt is recommended to use this setting for commands that communicate with the service requesting clean termination. For post-mortem clean-up steps use ExecStopPost= instead.\nExecStopPost= #Additional commands that are executed after the service is stopped. This includes cases where the commands configured in ExecStop= were used, where the service does not have any ExecStop= defined, or where the service exited unexpectedly. This argument takes multiple command lines, following the same scheme as described for ExecStart=. Use of these settings is optional. Specifier and environment variable substitution is supported. Note that – unlike ExecStop= – commands specified with this setting are invoked when a service failed to start up correctly and is shut down again.\nIt is recommended to use this setting for clean-up operations that shall be executed even when the service failed to start up correctly. Commands configured with this setting need to be able to operate even if the service failed starting up half-way and left incompletely initialized data around. As the service\u0026rsquo;s processes have been terminated already when the commands specified with this setting are executed they should not attempt to communicate with them.\nNote that all commands that are configured with this setting are invoked with the result code of the service, as well as the main process\u0026rsquo; exit code and status, set in the $SERVICE_RESULT, $EXIT_CODE and $EXIT_STATUS environment variables, see systemd.exec(5) for details.\nNote that the execution of ExecStopPost= is taken into account for the purpose of Before=/After= ordering constraints.\nRestartSec= #Configures the time to sleep before restarting a service (as configured with Restart=). Takes a unit-less value in seconds, or a time span value such as \u0026ldquo;5min 20s\u0026rdquo;. Defaults to 100ms.\nRestartSteps= #Configures the number of steps to take to increase the interval of auto-restarts from RestartSec= to RestartMaxDelaySec=. Takes a positive integer or 0 to disable it. Defaults to 0.\nThis setting is effective only if RestartMaxDelaySec= is also set.\nAdded in version 254.\nRestartMaxDelaySec= #Configures the longest time to sleep before restarting a service as the interval goes up with RestartSteps=. Takes a value in the same format as RestartSec=, or infinity to disable the setting. Defaults to infinity.\nThis setting is effective only if RestartSteps= is also set.\nAdded in version 254.\nTimeoutStartSec= #Configures the time to wait for start-up. If a daemon service does not signal start-up completion within the configured time, the service will be considered failed and will be shut down again. The precise action depends on the TimeoutStartFailureMode= option. Takes a unit-less value in seconds, or a time span value such as \u0026ldquo;5min 20s\u0026rdquo;. Pass \u0026ldquo;infinity\u0026rdquo; to disable the timeout logic. Defaults to DefaultTimeoutStartSec= set in the manager, except when Type=oneshot is used, in which case the timeout is disabled by default (see systemd-system.conf(5)).\nIf a service of Type=notify/Type=notify-reload sends \u0026ldquo;EXTEND_TIMEOUT_USEC=…\u0026rdquo;, this may cause the start time to be extended beyond TimeoutStartSec=. The first receipt of this message must occur before TimeoutStartSec= is exceeded, and once the start time has extended beyond TimeoutStartSec=, the service manager will allow the service to continue to start, provided the service repeats \u0026ldquo;EXTEND_TIMEOUT_USEC=…\u0026rdquo; within the interval specified until the service startup status is finished by \u0026ldquo;READY=1\u0026rdquo;. (see sd_notify(3)).\nAdded in version 188.\nTimeoutStopSec= #This option serves two purposes. First, it configures the time to wait for each ExecStop= command. If any of them times out, subsequent ExecStop= commands are skipped and the service will be terminated by SIGTERM. If no ExecStop= commands are specified, the service gets the SIGTERM immediately. This default behavior can be changed by the TimeoutStopFailureMode= option. Second, it configures the time to wait for the service itself to stop. If it doesn\u0026rsquo;t terminate in the specified time, it will be forcibly terminated by SIGKILL (see KillMode= in systemd.kill(5)). Takes a unit-less value in seconds, or a time span value such as \u0026ldquo;5min 20s\u0026rdquo;. Pass \u0026ldquo;infinity\u0026rdquo; to disable the timeout logic. Defaults to DefaultTimeoutStopSec= from the manager configuration file (see systemd-system.conf(5)).\nIf a service of Type=notify/Type=notify-reload sends \u0026ldquo;EXTEND_TIMEOUT_USEC=…\u0026rdquo;, this may cause the stop time to be extended beyond TimeoutStopSec=. The first receipt of this message must occur before TimeoutStopSec= is exceeded, and once the stop time has extended beyond TimeoutStopSec=, the service manager will allow the service to continue to stop, provided the service repeats \u0026ldquo;EXTEND_TIMEOUT_USEC=…\u0026rdquo; within the interval specified, or terminates itself (see sd_notify(3)).\nAdded in version 188.\nTimeoutAbortSec= #This option configures the time to wait for the service to terminate when it was aborted due to a watchdog timeout (see WatchdogSec=). If the service has a short TimeoutStopSec= this option can be used to give the system more time to write a core dump of the service. Upon expiration the service will be forcibly terminated by SIGKILL (see KillMode= in systemd.kill(5)). The core file will be truncated in this case. Use TimeoutAbortSec= to set a sensible timeout for the core dumping per service that is large enough to write all expected data while also being short enough to handle the service failure in due time.\nTakes a unit-less value in seconds, or a time span value such as \u0026ldquo;5min 20s\u0026rdquo;. Pass an empty value to skip the dedicated watchdog abort timeout handling and fall back TimeoutStopSec=. Pass \u0026ldquo;infinity\u0026rdquo; to disable the timeout logic. Defaults to DefaultTimeoutAbortSec= from the manager configuration file (see systemd-system.conf(5)).\nIf a service of Type=notify/Type=notify-reload handles SIGABRT itself (instead of relying on the kernel to write a core dump) it can send \u0026ldquo;EXTEND_TIMEOUT_USEC=…\u0026rdquo; to extended the abort time beyond TimeoutAbortSec=. The first receipt of this message must occur before TimeoutAbortSec= is exceeded, and once the abort time has extended beyond TimeoutAbortSec=, the service manager will allow the service to continue to abort, provided the service repeats \u0026ldquo;EXTEND_TIMEOUT_USEC=…\u0026rdquo; within the interval specified, or terminates itself (see sd_notify(3)).\nAdded in version 243.\nTimeoutSec= #A shorthand for configuring both TimeoutStartSec= and TimeoutStopSec= to the specified value.\nTimeoutStartFailureMode=, TimeoutStopFailureMode= #These options configure the action that is taken in case a daemon service does not signal start-up within its configured TimeoutStartSec=, respectively if it does not stop within TimeoutStopSec=. Takes one of terminate, abort and kill. Both options default to terminate.\nIf terminate is set the service will be gracefully terminated by sending the signal specified in KillSignal= (defaults to SIGTERM, see systemd.kill(5)). If the service does not terminate the FinalKillSignal= is sent after TimeoutStopSec=. If abort is set, WatchdogSignal= is sent instead and TimeoutAbortSec= applies before sending FinalKillSignal=. This setting may be used to analyze services that fail to start-up or shut-down intermittently. By using kill the service is immediately terminated by sending FinalKillSignal= without any further timeout. This setting can be used to expedite the shutdown of failing services.\nAdded in version 246.\nRuntimeMaxSec= #Configures a maximum time for the service to run. If this is used and the service has been active for longer than the specified time it is terminated and put into a failure state. Note that this setting does not have any effect on Type=oneshot services, as they terminate immediately after activation completed. Pass \u0026ldquo;infinity\u0026rdquo; (the default) to configure no runtime limit.\nIf a service of Type=notify/Type=notify-reload sends \u0026ldquo;EXTEND_TIMEOUT_USEC=…\u0026rdquo;, this may cause the runtime to be extended beyond RuntimeMaxSec=. The first receipt of this message must occur before RuntimeMaxSec= is exceeded, and once the runtime has extended beyond RuntimeMaxSec=, the service manager will allow the service to continue to run, provided the service repeats \u0026ldquo;EXTEND_TIMEOUT_USEC=…\u0026rdquo; within the interval specified until the service shutdown is achieved by \u0026ldquo;STOPPING=1\u0026rdquo; (or termination). (see sd_notify(3)).\nAdded in version 229.\nRuntimeRandomizedExtraSec= #This option modifies RuntimeMaxSec= by increasing the maximum runtime by an evenly distributed duration between 0 and the specified value (in seconds). If RuntimeMaxSec= is unspecified, then this feature will be disabled.\nAdded in version 250.\nWatchdogSec= #Configures the watchdog timeout for a service. The watchdog is activated when the start-up is completed. The service must call sd_notify(3) regularly with \u0026ldquo;WATCHDOG=1\u0026rdquo; (i.e. the \u0026ldquo;keep-alive ping\u0026rdquo;). If the time between two such calls is larger than the configured time, then the service is placed in a failed state and it will be terminated with SIGABRT (or the signal specified by WatchdogSignal=). By setting Restart= to on-failure, on-watchdog, on-abnormal or always, the service will be automatically restarted. The time configured here will be passed to the executed service process in the WATCHDOG_USEC= environment variable. This allows daemons to automatically enable the keep-alive pinging logic if watchdog support is enabled for the service. If this option is used, NotifyAccess= (see below) should be set to open access to the notification socket provided by systemd. If NotifyAccess= is not set, it will be implicitly set to main. Defaults to 0, which disables this feature. The service can check whether the service manager expects watchdog keep-alive notifications. See sd_watchdog_enabled(3) for details. sd_event_set_watchdog(3) may be used to enable automatic watchdog notification support. Restart=\nConfigures whether the service shall be restarted when the service process exits, is killed, or a timeout is reached. The service process may be the main service process, but it may also be one of the processes specified with ExecStartPre=, ExecStartPost=, ExecStop=, ExecStopPost=, or ExecReload=. When the death of the process is a result of systemd operation (e.g. service stop or restart), the service will not be restarted. Timeouts include missing the watchdog \u0026ldquo;keep-alive ping\u0026rdquo; deadline and a service start, reload, and stop operation timeouts.\nTakes one of no, on-success, on-failure, on-abnormal, on-watchdog, on-abort, or always. If set to no (the default), the service will not be restarted. If set to on-success, it will be restarted only when the service process exits cleanly. In this context, a clean exit means any of the following:\nexit code of 0; for types other than Type=oneshot, one of the signals SIGHUP, SIGINT, SIGTERM, or SIGPIPE; exit statuses and signals specified in SuccessExitStatus=.\nIf set to on-failure, the service will be restarted when the process exits with a non-zero exit code, is terminated by a signal (including on core dump, but excluding the aforementioned four signals), when an operation (such as service reload) times out, and when the configured watchdog timeout is triggered. If set to on-abnormal, the service will be restarted when the process is terminated by a signal (including on core dump, excluding the aforementioned four signals), when an operation times out, or when the watchdog timeout is triggered. If set to on-abort, the service will be restarted only if the service process exits due to an uncaught signal not specified as a clean exit status. If set to on-watchdog, the service will be restarted only if the watchdog timeout for the service expires. If set to always, the service will be restarted regardless of whether it exited cleanly or not, got terminated abnormally by a signal, or hit a timeout.\nTable 1. Exit causes and the effect of the Restart= settings Restart settings/Exit causes\tno\talways\ton-success\ton-failure\ton-abnormal\ton-abort\ton-watchdog Clean exit code or signal\tX\tX\tUnclean exit code\tX\tX\tUnclean signal\tX\tX\tX\tX\tTimeout\tX\tX\tX\tWatchdog\tX\tX\tX\tX\nAs exceptions to the setting above, the service will not be restarted if the exit code or signal is specified in RestartPreventExitStatus= (see below) or the service is stopped with systemctl stop or an equivalent operation. Also, the services will always be restarted if the exit code or signal is specified in RestartForceExitStatus= (see below).\nNote that service restart is subject to unit start rate limiting configured with StartLimitIntervalSec= and StartLimitBurst=, see systemd.unit(5) for details.\nSetting this to on-failure is the recommended choice for long-running services, in order to increase reliability by attempting automatic recovery from errors. For services that shall be able to terminate on their own choice (and avoid immediate restarting), on-abnormal is an alternative choice.\nRestartMode= #Takes a string value that specifies how a service should restart:\nIf set to normal (the default), the service restarts by going through a failed/inactive state.\nIf set to direct, the service transitions to the activating state directly during auto-restart, skipping failed/inactive state. ExecStopPost= is invoked. OnSuccess= and OnFailure= are skipped.\nThis option is useful in cases where a dependency can fail temporarily but we don\u0026rsquo;t want these temporary failures to make the dependent units fail. When this option is set to direct, dependent units are not notified of these temporary failures.\nAdded in version 254.\nSuccessExitStatus= #Takes a list of exit status definitions that, when returned by the main service process, will be considered successful termination, in addition to the normal successful exit status 0 and, except for Type=oneshot, the signals SIGHUP, SIGINT, SIGTERM, and SIGPIPE. Exit status definitions can be numeric termination statuses, termination status names, or termination signal names, separated by spaces. See the Process Exit Codes section in systemd.exec(5) for a list of termination status names (for this setting only the part without the \u0026ldquo;EXIT_\u0026rdquo; or \u0026ldquo;EX_\u0026rdquo; prefix should be used). See signal(7) for a list of signal names.\nNote that this setting does not change the mapping between numeric exit statuses and their names, i.e. regardless how this setting is used 0 will still be mapped to \u0026ldquo;SUCCESS\u0026rdquo; (and thus typically shown as \u0026ldquo;0/SUCCESS\u0026rdquo; in tool outputs) and 1 to \u0026ldquo;FAILURE\u0026rdquo; (and thus typically shown as \u0026ldquo;1/FAILURE\u0026rdquo;), and so on. It only controls what happens as effect of these exit statuses, and how it propagates to the state of the service as a whole.\nThis option may appear more than once, in which case the list of successful exit statuses is merged. If the empty string is assigned to this option, the list is reset, all prior assignments of this option will have no effect.\nExample 1. A service with the SuccessExitStatus= setting\nSuccessExitStatus=TEMPFAIL 250 SIGKILL\nExit status 75 (TEMPFAIL), 250, and the termination signal SIGKILL are considered clean service terminations.\nNote: systemd-analyze exit-status may be used to list exit statuses and translate between numerical status values and names.\nAdded in version 189.\nRestartPreventExitStatus= #Takes a list of exit status definitions that, when returned by the main service process, will prevent automatic service restarts, regardless of the restart setting configured with Restart=. Exit status definitions can either be numeric exit codes or termination signal names, and are separated by spaces. Defaults to the empty list, so that, by default, no exit status is excluded from the configured restart logic. For example:\nRestartPreventExitStatus=1 6 SIGABRT\nensures that exit codes 1 and 6 and the termination signal SIGABRT will not result in automatic service restarting. This option may appear more than once, in which case the list of restart-preventing statuses is merged. If the empty string is assigned to this option, the list is reset and all prior assignments of this option will have no effect.\nNote that this setting has no effect on processes configured via ExecStartPre=, ExecStartPost=, ExecStop=, ExecStopPost= or ExecReload=, but only on the main service process, i.e. either the one invoked by ExecStart= or (depending on Type=, PIDFile=, …) the otherwise configured main process.\nAdded in version 189.\nRestartForceExitStatus= #Takes a list of exit status definitions that, when returned by the main service process, will force automatic service restarts, regardless of the restart setting configured with Restart=. The argument format is similar to RestartPreventExitStatus=.\nAdded in version 215.\nRootDirectoryStartOnly= #Takes a boolean argument. If true, the root directory, as configured with the RootDirectory= option (see systemd.exec(5) for more information), is only applied to the process started with ExecStart=, and not to the various other ExecStartPre=, ExecStartPost=, ExecReload=, ExecStop=, and ExecStopPost= commands. If false, the setting is applied to all configured commands the same way. Defaults to false. NonBlocking=\nSet the O_NONBLOCK flag for all file descriptors passed via socket-based activation. If true, all file descriptors \u0026gt;= 3 (i.e. all except stdin, stdout, stderr), excluding those passed in via the file descriptor storage logic (see FileDescriptorStoreMax= for details), will have the O_NONBLOCK flag set and hence are in non-blocking mode. This option is only useful in conjunction with a socket unit, as described in systemd.socket(5) and has no effect on file descriptors which were previously saved in the file-descriptor store for example. Defaults to false.\nNote that if the same socket unit is configured to be passed to multiple service units (via the Sockets= setting, see below), and these services have different NonBlocking= configurations, the precise state of O_NONBLOCK depends on the order in which these services are invoked, and will possibly change after service code already took possession of the socket file descriptor, simply because the O_NONBLOCK state of a socket is shared by all file descriptors referencing it. Hence it is essential that all services sharing the same socket use the same NonBlocking= configuration, and do not change the flag in service code either.\nNotifyAccess= #Controls access to the service status notification socket, as accessible via the sd_notify(3) call. Takes one of none (the default), main, exec or all. If none, no daemon status updates are accepted from the service processes, all status update messages are ignored. If main, only service updates sent from the main process of the service are accepted. If exec, only service updates sent from any of the main or control processes originating from one of the Exec*= commands are accepted. If all, all services updates from all members of the service\u0026rsquo;s control group are accepted. This option should be set to open access to the notification socket when using Type=notify/Type=notify-reload or WatchdogSec= (see above). If those options are used but NotifyAccess= is not configured, it will be implicitly set to main.\nNote that sd_notify() notifications may be attributed to units correctly only if either the sending process is still around at the time PID 1 processes the message, or if the sending process is explicitly runtime-tracked by the service manager. The latter is the case if the service manager originally forked off the process, i.e. on all processes that match main or exec. Conversely, if an auxiliary process of the unit sends an sd_notify() message and immediately exits, the service manager might not be able to properly attribute the message to the unit, and thus will ignore it, even if NotifyAccess=all is set for it.\nHence, to eliminate all race conditions involving lookup of the client\u0026rsquo;s unit and attribution of notifications to units correctly, sd_notify_barrier() may be used. This call acts as a synchronization point and ensures all notifications sent before this call have been picked up by the service manager when it returns successfully. Use of sd_notify_barrier() is needed for clients which are not invoked by the service manager, otherwise this synchronization mechanism is unnecessary for attribution of notifications to the unit.\nSockets= #Specifies the name of the socket units this service shall inherit socket file descriptors from when the service is started. Normally, it should not be necessary to use this setting, as all socket file descriptors whose unit shares the same name as the service (subject to the different unit name suffix of course) are passed to the spawned process.\nNote that the same socket file descriptors may be passed to multiple processes simultaneously. Also note that a different service may be activated on incoming socket traffic than the one which is ultimately configured to inherit the socket file descriptors. Or, in other words: the Service= setting of .socket units does not have to match the inverse of the Sockets= setting of the .service it refers to.\nThis option may appear more than once, in which case the list of socket units is merged. Note that once set, clearing the list of sockets again (for example, by assigning the empty string to this option) is not supported.\nFileDescriptorStoreMax= #Configure how many file descriptors may be stored in the service manager for the service using sd_pid_notify_with_fds(3)\u0026rsquo;s \u0026ldquo;FDSTORE=1\u0026rdquo; messages. This is useful for implementing services that can restart after an explicit request or a crash without losing state. Any open sockets and other file descriptors which should not be closed during the restart may be stored this way. Application state can either be serialized to a file in RuntimeDirectory=, or stored in a memfd_create(2) memory file descriptor. Defaults to 0, i.e. no file descriptors may be stored in the service manager. All file descriptors passed to the service manager from a specific service are passed back to the service\u0026rsquo;s main process on the next service restart (see sd_listen_fds(3) for details about the precise protocol used and the order in which the file descriptors are passed). Any file descriptors passed to the service manager are automatically closed when POLLHUP or POLLERR is seen on them, or when the service is fully stopped and no job is queued or being executed for it (the latter can be tweaked with FileDescriptorStorePreserve=, see below). If this option is used, NotifyAccess= (see above) should be set to open access to the notification socket provided by systemd. If NotifyAccess= is not set, it will be implicitly set to main.\nThe fdstore command of systemd-analyze(1) may be used to list the current contents of a service\u0026rsquo;s file descriptor store.\nNote that the service manager will only pass file descriptors contained in the file descriptor store to the service\u0026rsquo;s own processes, never to other clients via IPC or similar. However, it does allow unprivileged clients to query the list of currently open file descriptors of a service. Sensitive data may hence be safely placed inside the referenced files, but should not be attached to the metadata (e.g. included in filenames) of the stored file descriptors.\nIf this option is set to a non-zero value the $FDSTORE environment variable will be set for processes invoked for this service. See systemd.exec(5) for details.\nFor further information on the file descriptor store see the File Descriptor Store overview.\nAdded in version 219.\nFileDescriptorStorePreserve= #Takes one of no, yes, restart and controls when to release the service\u0026rsquo;s file descriptor store (i.e. when to close the contained file descriptors, if any). If set to no the file descriptor store is automatically released when the service is stopped; if restart (the default) it is kept around as long as the unit is neither inactive nor failed, or a job is queued for the service, or the service is expected to be restarted. If yes the file descriptor store is kept around until the unit is removed from memory (i.e. is not referenced anymore and inactive). The latter is useful to keep entries in the file descriptor store pinned until the service manager exits.\nUse systemctl clean \u0026ndash;what=fdstore … to release the file descriptor store explicitly.\nAdded in version 254.\nUSBFunctionDescriptors= #Configure the location of a file containing USB FunctionFS descriptors, for implementation of USB gadget functions. This is used only in conjunction with a socket unit with ListenUSBFunction= configured. The contents of this file are written to the ep0 file after it is opened.\nAdded in version 227.\nUSBFunctionStrings= #Configure the location of a file containing USB FunctionFS strings. Behavior is similar to USBFunctionDescriptors= above.\nAdded in version 227.\nOOMPolicy= #Configure the out-of-memory (OOM) killing policy for the kernel and the userspace OOM killer systemd-oomd.service(8). On Linux, when memory becomes scarce to the point that the kernel has trouble allocating memory for itself, it might decide to kill a running process in order to free up memory and reduce memory pressure. Note that systemd-oomd.service is a more flexible solution that aims to prevent out-of-memory situations for the userspace too, not just the kernel, by attempting to terminate services earlier, before the kernel would have to act.\nThis setting takes one of continue, stop or kill. If set to continue and a process in the unit is killed by the OOM killer, this is logged but the unit continues running. If set to stop the event is logged but the unit is terminated cleanly by the service manager. If set to kill and one of the unit\u0026rsquo;s processes is killed by the OOM killer the kernel is instructed to kill all remaining processes of the unit too, by setting the memory.oom.group attribute to 1; also see kernel page Control Group v2.\nDefaults to the setting DefaultOOMPolicy= in systemd-system.conf(5) is set to, except for units where Delegate= is turned on, where it defaults to continue.\nUse the OOMScoreAdjust= setting to configure whether processes of the unit shall be considered preferred or less preferred candidates for process termination by the Linux OOM killer logic. See systemd.exec(5) for details.\nThis setting also applies to systemd-oomd.service(8). Similarly to the kernel OOM kills performed by the kernel, this setting determines the state of the unit after systemd-oomd kills a cgroup associated with it.\nAdded in version 243.\nOpenFile= #Takes an argument of the form \u0026ldquo;path[:fd-name:options]\u0026rdquo;, where:\n\u0026ldquo;path\u0026rdquo; is a path to a file or an AF_UNIX socket in the file system; \u0026ldquo;fd-name\u0026rdquo; is a name that will be associated with the file descriptor; the name may contain any ASCII character, but must exclude control characters and \u0026ldquo;:\u0026rdquo;, and must be at most 255 characters in length; it is optional and, if not provided, defaults to the file name; \u0026ldquo;options\u0026rdquo; is a comma-separated list of access options; possible values are \u0026ldquo;read-only\u0026rdquo;, \u0026ldquo;append\u0026rdquo;, \u0026ldquo;truncate\u0026rdquo;, \u0026ldquo;graceful\u0026rdquo;; if not specified, files will be opened in rw mode; if \u0026ldquo;graceful\u0026rdquo; is specified, errors during file/socket opening are ignored. Specifying the same option several times is treated as an error.\nThe file or socket is opened by the service manager and the file descriptor is passed to the service. If the path is a socket, we call connect() on it. See sd_listen_fds(3) for more details on how to retrieve these file descriptors.\nThis setting is useful to allow services to access files/sockets that they can\u0026rsquo;t access themselves (due to running in a separate mount namespace, not having privileges, \u0026hellip;).\nThis setting can be specified multiple times, in which case all the specified paths are opened and the file descriptors passed to the service. If the empty string is assigned, the entire list of open files defined prior to this is reset.\nAdded in version 253.\nReloadSignal= #Configures the UNIX process signal to send to the service\u0026rsquo;s main process when asked to reload the service\u0026rsquo;s configuration. Defaults to SIGHUP. This option has no effect unless Type=notify-reload is used, see above.\nAdded in version 253. Check systemd.unit(5), systemd.exec(5), and systemd.kill(5) for more settings.\n","date":"1 January 0001","permalink":"/posts/systemd/service-unit-configuration/","section":"Posts","summary":"TL;DR #nano /etc/systemd/system/\u0026lt;name\u0026gt;.","title":"Service Unit Configuration"},{"content":"Default Assignee #Create a new category under Project -\u0026gt; Project setings -\u0026gt; Work package categories and assign a default Assignee to the category.\nThe receive_imap can now set Assignee if category=Category is set.\nDefault Start Date #Set Use current date as start date for new work packages under Administration -\u0026gt; Work package tracking.\n","date":"1 January 0001","permalink":"/posts/openproject/default-assignee-and-start-date/","section":"Posts","summary":"Default Assignee #Create a new category under Project -\u0026gt; Project setings -\u0026gt; Work package categories and assign a default Assignee to the category.","title":"Set Default Assignee and Start Date in OpenProject"},{"content":"sudo mysql create database my_database; CREATE USER \u0026#39;user\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;PASSWORD\u0026#39;; GRANT ALL PRIVILEGES ON db.* TO \u0026#39;user\u0026#39;@\u0026#39;localhost\u0026#39;; flush privileges; ","date":"1 January 0001","permalink":"/posts/mysql/setup/","section":"Posts","summary":"sudo mysql create database my_database; CREATE USER \u0026#39;user\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;PASSWORD\u0026#39;; GRANT ALL PRIVILEGES ON db.","title":"Setup a New Database and User in MySQL"},{"content":"Server #Create WireGuard server.\nSetup #Set temporary permission for new files:\numask 077 Create the keys:\nwg genkey | tee /etc/wireguard/privkey wg pubkey \u0026lt; /etc/wireguard/privkey | tee /etc/wireguard/pubkey Create the config file:\nnano /etc/wireguard/wg0.conf [Interface] Address = 10.10.10.1/24 ListenPort = 51820 SaveConfig = True PrivateKey = ... Start:\nwg-quick up wg0 Enable:\nsystemctl enable wg-quick@wg0 Add peer #:::caution Stop WireGuard before editing wg0.conf! :::\nAppend to wg0.conf:\nnano /etc/wireguard/wg0.conf [Peer] AllowedIPs = 10.10.10.2/32 PublicKey = ... PresharedKey = ... Client #Configure WireGuard client.\nSet temporary permission for new files:\numask 077 Create the keys:\nwg genkey | tee /etc/wireguard/privkey wg pubkey \u0026lt; /etc/wireguard/privkey | tee /etc/wireguard/pubkey wg genpsk | tee /etc/wireguard/psk Create the config file:\nnano /etc/wireguard/wg0.conf [Interface] Address = 10.10.10.2/32 PrivateKey = ... [Peer] Endpoint = X.X.X.X:51820 AllowedIPs = 10.10.10.0/24 PublicKey = ... PreSharedKey = ... PersistentKeepalive = 20 Gateway #Use WireGuard server as gateway.\nnftable #define WAN_IF = eth0 define WG_NET = 10.10.10.0/24 define WG_IF = wg0 table nat { chain prerouting { type nat hook prerouting priority -100; policy accept; #tcp dport 8080 iif $WAN_IF dnat to 10.10.10.2:8080 } chain postrouting { type nat hook postrouting priority 100; policy accept; ip saddr $WG_NET oif $WAN_IF masquerade } } table inet filter { chain input_wan { tcp dport 22 accept udp dport 51820 accept icmp type echo-request limit rate 5/second accept icmpv6 type { nd-neighbor-solicit, nd-router-advert, nd-neighbor-advert } accept icmpv6 type echo-request limit rate 5/second accept } chain input_wg { accept } chain input { type filter hook input priority 0; policy drop; ct state vmap { established : accept, related : accept, invalid : drop } iifname vmap { lo : accept, $WAN_IF : jump input_wan, $WG_IF : jump input_wg } reject } chain forward { type filter hook forward priority 0; policy drop; ct state vmap { established : accept, related : accept, invalid : drop } iif $WG_IF oif $WAN_IF accept iif $WAN_IF oif $WG_IF accept iif $WG_IF oif $WG_IF accept } chain output { type filter hook output priority 0; } } Forwarding #Enable IP forwarding:\necho \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf echo \u0026#34;net.ipv6.conf.all.forwarding = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p ","date":"1 January 0001","permalink":"/posts/wireguard/remote-access-vpn/","section":"Posts","summary":"Server #Create WireGuard server.","title":"Setup a Remote Access VPN with WireGuard"},{"content":"The SSH protocol uses encryption to secure the connection between a client and a server. All user authentication, commands, output, and file transfers are encrypted to protect against attacks in the network. SSH is an Appliaction Layer protocol, uses TCP port 22 by default.\nCommon softwares that uses SSH protocol:\nOpenSSH sftp scp rsync Putty sshfs What NSA can do with encrypted traffic? Read here. The cryptographic algorithms based on stribika\u0026rsquo;s recommendations.\nThe config file #OpenSSH reads its configurations from /etc/ssh/sshd_config.\nBefore any modification, backup the existing config file:\nsudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak Lets look into the details\u0026hellip;\nOpen the config file:\nsudo nano /etc/ssh/sshd_config Options #Port #The default port that SSH binds to is 22. Somebody change it to protect himself against bots created by script kiddies (better bots finds the port number anyway). Im not going to change it, i leave the protection from bots to fail2ban. To change it, modify 22 to any arbitary number, eg. Port 2222. I use the default Port 22.\nPort 22 AddressFamily #Possible options:\nany (IPv4 + IPv6) inet (IPv4) inet6 (IPv6) Its up to you, i use both IPv4 and IPv6:\nAddressFamily any ListenAddress #To bind to localhost on IPv4, use ListenAddress 0.0.0.0. To bind to localhost on IPv6, use ListenAddress ::\nListenAddress 0.0.0.0 ListenAddress :: SyslogFacility #The default setting is to log to the security/authentication (auth) facility of syslog. This is good, so its not need to be modified. The logs can be found in /var/log/auth.log by default.\nSyslogFacility AUTH LogLevel #This describes the verbosity of the logs. Logging with a DEBUG level violates the privacy of users and is not recommended.\nOptions: QUIET, FATAL, ERROR, INFO, VERBOSE, DEBUG, DEBUG1, DEBUG2, DEBUG3\nThe default is:\nLogLevel INFO LoginGraceTime #Time to wait for authentication before disconnection. The default is 2 minutes, to disable this feature use 0.\nLoginGraceTime 2m PermitRootLogin #Do you want to enable root login? I dont think so\u0026hellip; Disable it!\nUse sudo or su - if you need root.\nPermitRootLogin no StrictModes #sshd check file modes and ownership of the user\u0026rsquo;s files and home directory before accepting login. The deault is yes because novices sometimes accidentally leave their directory or files world-writable.\nMaxAuthTries #The number of failed authentication atttempt per connection. Once the number of failures reaches half this value, additional failures are logged. The lower the better, because administrator gets notified earlier and fail2ban reads the log to ban IPs.\nMaxAuthTries 2 MaxSessions #In SSH, it is allowed to use a session for more than one thing (session multiplexing), this is a not a very useful feature for an average user. To disable it, set it the value to 1.\nMaxSessions 1 PubkeyAuthentication #This allows to login with a secure ssh key. The default is yes so no need to modify.\nPubkeyAuthentication yes AuthorizedKeysFile #The file SSH search from the authorized keys. By default, this is $HOME/.ssh/authorized_keys. ssh-copy-id place your key to this file. Dont modify!\nAuthorizedKeysFile .ssh/authorized_keys HostbasedAuthentication #Enables the remote host to authenticate with his HostKey\u0026rsquo;s public key. It is usefull for automated stuffs. Do you need it? Its up to you.\nHostbasedAuthentication no PasswordAuthentication #Use clear text password (in an encrypted tunnel) to login. If no good password policy applied, your server is vulnerable to brute forcing attack. I always use an SSH key so i disable it, i suggest to do it too!\nPasswordAuthentication no PermitEmptyPasswords #Do i have to write anything about it? NEVER enable it! It allows to login in without password.\nPermitEmptyPasswords no ChallengeResponseAuthentication #Allows to authenticate via challenge-response. It is possible to setup a 2FA with Google Authenticator for SSH.\nChallengeResponseAuthentication no KerberosAuthentication #Do you want to authenticate with Kerberos?\nKerberosAuthentication no GSSAPIAuthentication #Have you ever heard about GSSAPI? No? Then you need the default no.\nGSSAPIAuthentication no UsePAM #PAM (Pluggable Authentication Module) is an authentication framework in Unix. If it is nopt sounds familiar, then disable it. I dont use it, so the default no remain unchanged.\nUsePAM no AllowAgentForwarding #ssh-agent is used to manage your key. You can forward this ssh-agent to a remote host to use your ssh key on the server. This useful if need to operate with your ssh key on the remote server.\nExample: authenticate on GitHub with your ssh key, and need to deploy your code on the remote host.\nDisabling it dont increase security, but if dont use it worth disabling it, unused feature.\nAllowAgentForwarding no AllowTcpForwarding #SSH can be used to forward TCP connections. It can forward local port to the remote host, or vice versa. It is a useful feature in SSH.\nDisabling it dont increase security.\nThe case is the same as at AllowAgentForwarding, if you dont need it, disable it.\nAllowTcpForwarding no GatewayPorts #If you forward a port from remote host to the client, requests only allowed for the server\u0026rsquo;s loopback only by default, so third party cant make a request to the client. With this option, you can enable it.\nGatewayPorts no X11Forwarding #Most Linux distributions enables it by default. X11Forwarding allows to use graphical applications on the server. Most headless Linux system dont have X at all.\nEnabling X forwarding considered harmfull.\nDisable it!\nX11Forwarding no PrintMotd #Message of the day can be fun and useful if you create one. Ubuntu has a package (update-motd) to generate dynamic messages. Thats it. This is shown after successfull authentication. The banner before authentication is Banner below.\nPrintMotd no PrintLastLog #Do you want to print the last login\u0026rsquo;s details?\nIt look like this:\nLast login: Fri Dec 6 22:45:44 2019 from [IP]\nIt can be useful if you are the only user in the server.\nPrintLastLog yes TCPKeepAlive #Send TCP keep alive to the other side of the connection. It is usefull to properly handle the crash of the other side (eg. network problems, system crash) and kill connection to avoid \u0026ldquo;ghost\u0026rdquo; users.\nTCPKeepAlive yes PermitUserEnvironment #Allows user to set their environment. It can be a security risk if your are managing what a user can do. With an interactive shell, the security risk is zero.\nIf you are using ~/.ssh/environment and environment= options in ~/.ssh/authorized_keys, enable it.\nPermitUserEnvironment no Compression #Compression can speed up your connection. If your internet connection is slow (eg. using SSH over Tor) enable it.\nPossible options:\nno: no compression delayed: compresion after successful authentication, this is the default yes: compress everything Your choice!\nI select not to compress:\nCompression no ClientAliveInterval #Time to wait in second before sending a null packet on an idle ssh session. This option is different from TCPKeepAlive. The ClientAliveInterval sends the data in an encrypted tunnel (so not spoofable), while TCPKeepAlive is sent unencrypted (spoofable). Idle connection can be a security problem (eg. client gets comporomised while the connection is open).\nFirst part of disabling idle connection is to set this option to a specific time, eg. 10 minutes:\nClientAliveInterval 600 ClientAliveCountMax #This sets the number of keep alive packets sent by SSH (not TCPKeepAlive). If the threshold is reached, the SSH server disconnect the client.\nThis is second (and last) part to disable the idle sessions. To disconnect the client after 30 minute of idling, set it to 3 (3x600 sec):\nClientAliveCountMax 3 UseDNS #Do a reverse DNS lookup on the remote IP. This setting is useless because of high chance that the IP dont have reverse DNS setted. Second, it could cause to hang the connection if the DNS server not respond for any reason.\nUseDNS no PidFile #Pid (process is) file is a simple text file. Programs write the main pid\u0026rsquo;s in it to use it later (eg. kill itself). If you want to specify the SSH\u0026rsquo;s pid file\u0026rsquo;s location, modify it, else leave it the default setting:\nPidFile /var/run/sshd.pid MaxStartups #Specify the number of allowed unaunthenticated connections. The default is 10, its ok.\nMaxStartups 10 PermitTunnel #Do you want to use your ssh server as a proxy?\nPermitTunnel no ChrootDirectory #chroot is special to Unix systems. Its modifys the current root director (/). If you want to restrict what user can do on your server set it, a good explanation can be found here.\nChrootDirectory none VersionAddendum #Append text to the SSH protocol banner sent by the server uppon connection.\nThis is not the login banner below, it is the text that you see when using Nmap with service scan.\nVersionAddendum none Banner #Banner shows the message before authentication, It reads its content from a file.\nThis is just a fun factor, so i disabled it:\nBanner none AcceptEnv #The client can send theit local environment variables to the server. This options specifies what environment variables are accepted.\nThe default is not accept anything, but on Debian the default is to accept LANG and LC_*.\nAcceptEnv LANG LC_* Subsystem #Subsystem is a useful feature of SSH, it is a set of remote command predefined on the server. Read more here if you are interested.\nBy default, sftp is configured:\nSubsystem sftp /usr/lib/openssh/sftp-server AllowUsers #This creates a whitelist of users that is allowed to log in. Any other user is disabled. The users are space separated list.\nIt is useful if you dont have much users to manage on your server.\nAllowUsers user There are more option to manage users. It will be explained below.\nThe order of parsing this rules are this, started from the top:\nDenyUsers AllowUsers DenyGroups AllowGroups DenyUsers #This creates a blacklist of users that cant log in. Any other users that not on the list can log in. The list of users is a space separated list.\nAllowGroups #This option allows user groups to log in. Only users of this group can login.\nThis option is useful if you need to manage large number of users.\nIf you want to use this:\n# create a group groupadd ssh-login # Add the user to the group usermod -aG ssh-login example # configure sshd: ... AllowGroups ssh-login ... DenyGroups #The groups specified in this option cant login. This is the opposite of AllowGroups.\nCrypto #KexAlgorithms #Key exchange algorithm is used to exchange secret between the server and the client, so it should be secure.\nThere a list of methods to key exchange, worth reading it. I use the two largest Diffie-Helman algorithms. It may be slower than others!\nIf you need to use a faster algorithm, use curve25519-sha256@libssh.org.\nI use the two strongest:\nKexAlgorithms diffie-hellman-group18-sha512,diffie-hellman-group16-sha512 HostKey #Host key is used to authenticate the server to the client. It should be unique to prevent network based attack (eg. mitm).\nStribika suggests not to use DSA/ECDSA because it is depends on random numbers and DSA\u0026rsquo;s key lenght is only 1024 bits. He is right, so i disable it.\nThe final config looks like this:\nHostKey /etc/ssh/ssh_host_rsa_key HostKey /etc/ssh/ssh_host_ed25519_key Don\u0026rsquo;t forget to generate larger host keys after the configuration:\ncd /etc/ssh rm ssh_host_*key* ssh-keygen -t ed25519 -f ssh_host_ed25519_key -N \u0026#34;\u0026#34; \u0026lt; /dev/null ssh-keygen -t rsa -b 4096 -f ssh_host_rsa_key -N \u0026#34;\u0026#34; \u0026lt; /dev/null On a new connection, you should see this:\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! ... Remove the known hosts file and it should be fine:\nrm $HOME/.ssh/known_hosts Ciphers #Ciphers is used to encrypt the data between the client and the server. It is use a symmetric encryption. The bigger the better.\nChaCha20 is stream cipher, while AES is a block cipher.\nChaCha20 is the preferred encryption method is SSH and the de facto standard for stream ciphers, replacing the old and broken RC4.\nCiphers chacha20-poly1305@openssh.com MACs #Message Aauthentication Code provides integrity. Because i use chacha20-poly1305@openssh.com for cipher, the MAC is poly1305.\nAnyway, i set the strongest MAC to disable the weaks.\nMACs hmac-sha2-512-etm@openssh.com RekeyLimit #Changing the session key over time to mitigate crypt analysis attacks. One method to attack cryptography is to collect a huge ammount of data to analyse and restore the key.\nChanging key too often not suggested.\nMy options is after 1 gigabyte or 1 hour:\nRekeyLimit 1G 1h The final config file ## IP Port 22 AddressFamily any ListenAddress 0.0.0.0 ListenAddress :: # logging SyslogFacility AUTH LogLevel INFO # authentication LoginGraceTime 2m PermitRootLogin no StrictModes yes MaxAuthTries 2 MaxSessions 1 PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys HostbasedAuthentication no PasswordAuthentication no ChallengeResponseAuthentication no KerberosAuthentication no GSSAPIAuthentication no UsePAM no # misc AllowAgentForwarding no AllowTcpForwarding yes GatewayPorts no X11Forwarding no PrintMotd no PrintLastLog yes TCPKeepAlive yes PermitUserEnvironment no Compression no ClientAliveInterval 600 ClientAliveCountMax 3 UseDNS no PidFile /var/run/sshd.pid MaxStartups 10 PermitTunnel no ChrootDirectory none VersionAddendum none Banner none AcceptEnv LANG LC_* Subsystem sftp /usr/lib/openssh/sftp-server # users AllowUsers CHANGEME # crypto KexAlgorithms diffie-hellman-group18-sha512,diffie-hellman-group16-sha512 HostKey /etc/ssh/ssh_host_ed25519_key HostKey /etc/ssh/ssh_host_rsa_key Ciphers chacha20-poly1305@openssh.com MACs hmac-sha2-512-etm@openssh.com RekeyLimit 1G 1h ","date":"1 January 0001","permalink":"/posts/openssh/nsa-proof-server/","section":"Posts","summary":"The SSH protocol uses encryption to secure the connection between a client and a server.","title":"Setup an NSA-Proof OpenSSH server"},{"content":"# https://www.example.com server { # Enable SSL and HTTP2 listen 443 ssl http2; listen [::]:443 ssl http2; server_name www.example.com; # Set certificate path ssl_certificate /etc/letsencrypt/live/www.example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/www.example.com/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/www.example.com/fullchain.pem; ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305; ssl_prefer_server_ciphers on; ssl_conf_command Options ServerPreference; ssl_conf_command Ciphersuites TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256; # Enable OCSP ssl_stapling on; ssl_stapling_verify on; resolver 1.1.1.1 1.0.0.1; resolver_timeout 5s; # Add security headers add_header X-Frame-Options \u0026#34;SAMEORIGIN\u0026#34; always; add_header X-Content-Type-Options \u0026#34;nosniff\u0026#34; always; add_header Referrer-Policy \u0026#34;strict-origin\u0026#34; always; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34; always; add_header Strict-Transport-Security \u0026#34;max-age=63072000; includeSubdomains; preload\u0026#34; always; # Set root path root /var/www/www.example.com/; index index.html; location / { try_files $uri $uri/ =404; } # Cache static content location ~* \\.(css|js|png|jpg|webp)$ { expires max; add_header Cache-Control \u0026#34;public\u0026#34;; } # Disable accessing hidden files except .well-known location ~ /\\.(?!well-known).* { deny all; } # Disable unused methods if ($request_method !~ ^(GET|HEAD)$ ) { return 405; } error_page 404 /404.html; } # http://www.example.com # Redirects to https://www.example.com server { listen 80; listen [::]:80; server_name www.example.com; # Redirect http to https return 301 https://$host$request_uri; } # https://example.com # Redirects to https://www.example.com server { # Enable SSL and HTTP2 listen 443 ssl http2; listen [::]:443 ssl http2; # Set certificate path ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/example.com/fullchain.pem; server_name example.com; # Add HSTS header add_header Strict-Transport-Security \u0026#34;max-age=63072000; includeSubdomains; preload\u0026#34; always; # Redirect http to https return 301 https://www.$host$request_uri; } # http://example.com # Redirects to https://www.example.com server { listen 80; listen [::]:80; server_name example.com; # Redirect http to https return 301 https://www.$host$request_uri; } ","date":"1 January 0001","permalink":"/posts/nginx/static-site/","section":"Posts","summary":"# https://www.","title":"Setup Nginx to host a Static Site"},{"content":"Connect #sudo -u postgres psql Create DB #CREATE DATABASE name; Create user #CREATE USER user WITH ENCRYPTED PASSWORD \u0026#39;password\u0026#39;; GRANT ALL PRIVILEGES ON DATABASE name TO user; :::info Change the database before configuring the schema:\n\\c \u0026lt;db\u0026gt; :::\nGRANT ALL ON SCHEMA public TO user; ","date":"1 January 0001","permalink":"/posts/postgresql/setup/","section":"Posts","summary":"Connect #sudo -u postgres psql Create DB #CREATE DATABASE name; Create user #CREATE USER user WITH ENCRYPTED PASSWORD \u0026#39;password\u0026#39;; GRANT ALL PRIVILEGES ON DATABASE name TO user; :::info Change the database before configuring the schema:","title":"Setup PostgreSQL"},{"content":"The nftables is a subsystem of the Linux kernel providing filtering and classification of network packets/datagrams/frames.\nConfigure a simple firewall for a basic webserver.\n#!/usr/sbin/nft -f flush ruleset table inet filter { chain inbound_ipv4 { icmp type echo-request limit rate 5/second accept } chain inbound_ipv6 { icmpv6 type { nd-neighbor-solicit, nd-router-advert, nd-neighbor-advert } accept icmpv6 type echo-request limit rate 5/second accept } chain input { type filter hook input priority 0; policy drop; ct state { established, related } accept iifname lo accept meta protocol vmap { ip : jump inbound_ipv4, ip6 : jump inbound_ipv6 } tcp dport 22 accept tcp dport 80 accept tcp dport 443 accept reject } chain forward { type filter hook forward priority 0; } chain output { type filter hook output priority 0; } } ","date":"1 January 0001","permalink":"/posts/nftables/stateful-firewall/","section":"Posts","summary":"The nftables is a subsystem of the Linux kernel providing filtering and classification of network packets/datagrams/frames.","title":"Simple Stateful Firewall with nftables"},{"content":"","date":null,"permalink":"/tags/sql/","section":"Tags","summary":"","title":"Sql"},{"content":"::::info iptables is replaced by nftables starting in Debian 10 (Buster) ::::\nSimple stateful firewall #In computing, a stateful firewall is a network firewall that tracks the operating state and characteristics of network connections traversing it. The firewall is configured to distinguish legitimate network packets for different types of connections. Only packets matching a known active connection are allowed to pass the firewall. In contrast a stateless firewall does not take context into account when determining whether to allow or block packets[1].\nThese rules are enough for a simple web server.\nIPv4 #*filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT IPv6 #*filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p ipv6-icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -d fe80::/64 -p udp -m udp --dport 546 -m state --state NEW -j ACCEPT -A INPUT -j REJECT --reject-with icmp6-adm-prohibited -A FORWARD -j REJECT --reject-with icmp6-adm-prohibited COMMIT Explanation #Default policies #INPUT\nDrop everything, only accept incoming traffic to ports that we want. On LAN, it is suggested to gracefully REJECT packets instead of DROP.\nFORWARD\nOn a typical server, we dont have any packets to forward, dont need it.\nOUTPUT\nAllow any output.\nRules #-A INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\nAllow related and established traffic. This mean that we initated the connection and the packet is the response.\n-A INPUT -p icmp -j ACCEPT\nAllow icmp protocol.\n-A INPUT -i lo -j ACCEPT\nAllow traffic on the loopback interface. This is essential for a proper work.\n-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT\nAllow new connections to my server\u0026rsquo;s SSH, which is operates on TCP port 22 by default.\nSetup #Iptables is not persistent by default, rebooting your server will flush all iptables rules. There is a package, called iptables-persistent to make it persistent.\nsudo apt install iptables-persistent This will want to save your existing rules.\nTo save again, use this command:\nsudo dpkg-reconfigure iptables-persistent or modify /etc/iptables/rules.v{4,6}.\n","date":"1 January 0001","permalink":"/posts/iptables/stateful-firewall/","section":"Posts","summary":"::::info iptables is replaced by nftables starting in Debian 10 (Buster) ::::","title":"Stateful Firewall with iptables"},{"content":"","date":null,"permalink":"/tags/systemd/","section":"Tags","summary":"","title":"Systemd"},{"content":"","date":null,"permalink":"/tags/tls/","section":"Tags","summary":"","title":"Tls"},{"content":"cd \u0026lt;uptime-kuma-directory\u0026gt; Update from git #git fetch --all git checkout $(curl -s \u0026#39;https://api.github.com/repos/louislam/uptime-kuma/releases/latest\u0026#39; | jq -r \u0026#39;.tag_name\u0026#39;) --force Install dependencies and prebuilt #npm install --production npm run download-dist Restart #systemctl restart uptime-kuma ","date":"1 January 0001","permalink":"/posts/uptime-kuma/update-from-source/","section":"Posts","summary":"cd \u0026lt;uptime-kuma-directory\u0026gt; Update from git #git fetch --all git checkout $(curl -s \u0026#39;https://api.","title":"Update Uptime Kuma from Source on Debian 12"},{"content":"Upgrade 11 to 12 #Prerequisites # Superuser Privileges: You must perform the upgrade with superuser privileges. Log in as root or a user with sudo privileges. Data Backup: Back up your data before starting the upgrade. If you\u0026rsquo;re using a virtual machine, consider taking a complete system snapshot. Update All Currently Installed Packages #Ensure your Debian 11 system is fully updated before the upgrade. Use the following APT commands and then reboot the system.\nsudo apt update sudo apt upgrade sudo apt full-upgrade sudo apt --purge autoremove sudo reboot Check for Installed Non-Debian Packages #Inspect your system for non-Debian packages, as they might cause complications during the upgrade. You might need to uninstall non-critical software installed from external repositories.\nsudo apt list \u0026#39;?narrow(?installed, ?not(?origin(Debian)))\u0026#39; Update Software Sources Files #Reconfigure your APT sources to point to the Debian 12 repositories. Backup current sources first, then update them to target \u0026lsquo;Bookworm\u0026rsquo;.\nmkdir ~/apt cp /etc/apt/sources.list ~/apt cp -r /etc/apt/sources.list.d/ ~/apt sudo sed -i \u0026#39;s/bullseye/bookworm/g\u0026#39; /etc/apt/sources.list sudo sed -i \u0026#39;s/bullseye/bookworm/g\u0026#39; /etc/apt/sources.list.d/* non-free-firmware #For Debian 12 onwards, all the packaged non-free firmware binaries that Debian can distribute have been moved to a new component in the Debian archive, called non-free-firmware.\ndeb http://deb.debian.org/debian/ bookworm main non-free-firmware Upgrade to Debian 12 “Bookworm” from Debian 11 “Bullseye” #Proceed with the full system upgrade using the apt full-upgrade command. Keep an eye on the screen for notifications and prompts during the process, and reboot the system once completed.\nsudo apt full-upgrade sudo reboot Cleaning up Obsolete Packages #After upgrading, remove obsolete packages from your Debian 12 system using the following command.\nsudo apt --purge autoremove Upgrade 10 to 11 #Prerequisites # Superuser Privileges: You must perform the upgrade with superuser privileges. Log in as root or a user with sudo privileges. Data Backup: Back up your data before starting the upgrade. If you\u0026rsquo;re using a virtual machine, consider taking a complete system snapshot. Update Current Packages # Check for Held Back Packages: Run sudo apt-mark showhold to check for any packages that are held back, as they can cause issues during the upgrade. Unhold them if necessary. Update Installed Packages: Refresh your package index and upgrade all installed packages using the following commands: sudo apt update sudo apt upgrade Perform a Full Upgrade: Use sudo apt full-upgrade to update your packages to the latest versions. This command may also remove unnecessary packages. Clean Up: After the full upgrade, remove any automatically installed dependencies that are no longer needed with sudo apt autoremove. Modify APT’s Source-List Files # Reconfigure APT Sources: Open /etc/apt/sources.list and replace each occurrence of buster with bullseye. If you have other source files under /etc/apt/sources.list.d, update those as well. Using sed Command: Alternatively, execute the following sed commands to update your sources list: sudo sed -i \u0026#39;s/buster/bullseye/g\u0026#39; /etc/apt/sources.list sudo sed -i \u0026#39;s/buster/bullseye/g\u0026#39; /etc/apt/sources.list.d/*.list sudo sed -i \u0026#39;s#/debian-security bullseye/updates# bullseye-security#g\u0026#39; /etc/apt/sources.list deb http://deb.debian.org/debian bullseye main contrib non-free deb http://deb.debian.org/debian bullseye-updates main contrib non-free deb http://deb.debian.org/debian-security bullseye-security/updates main Set Terminal Output to English: This helps to avoid language-specific issues during the upgrade. Use export LC_ALL=C to set the language to English. Update Packages Index Again: Run sudo apt update to refresh the package index with the new sources. Perform the System Upgrade # Upgrade Installed Packages: Begin the system upgrade with sudo apt upgrade. This step upgrades packages without requiring additional packages to be installed or removed. Full System Upgrade: Execute sudo apt full-upgrade to perform a complete system upgrade. This command resolves dependency changes and upgrades packages that were not updated in the previous step. Clean Up and Reboot: After completing the full upgrade, clean up unnecessary packages again with sudo apt autoremove. Then, reboot your machine to activate the new kernel using sudo systemctl reboot. Confirm the Upgrade #After rebooting, confirm that your system has been successfully upgraded to Debian 11 (Bullseye) by running lsb_release -a. The output should indicate Debian GNU/Linux 11 (Bullseye) as the distribution.\n","date":"1 January 0001","permalink":"/posts/debian/upgrade/index.en./","section":"Posts","summary":"A guide about how to upgrade to the Debian release","title":"Upgrade Debian release"},{"content":"","date":null,"permalink":"/tags/uptime/","section":"Tags","summary":"","title":"Uptime"},{"content":"","date":null,"permalink":"/tags/uptime-kuma/","section":"Tags","summary":"","title":"Uptime Kuma"},{"content":"","date":null,"permalink":"/tags/uptime-monitoring/","section":"Tags","summary":"","title":"Uptime-Monitoring"},{"content":"","date":null,"permalink":"/tags/vpn/","section":"Tags","summary":"","title":"Vpn"},{"content":"","date":null,"permalink":"/tags/webserver/","section":"Tags","summary":"","title":"Webserver"},{"content":"","date":null,"permalink":"/tags/wireguard/","section":"Tags","summary":"","title":"WireGuard"},{"content":"http://www.wireguard.com\nJason A. Donenfeld\njason@zx2c4.com\nDraft Revision\nAbstract #WireGuard is a secure network tunnel, operating at layer 3, implemented as a kernel virtual network interface for Linux, which aims to replace both IPsec for most use cases, as well as popular user space and/or TLS-based solutions like OpenVPN, while being more secure, more performant, and easier to use. The virtual tunnel interface is based on a proposed fundamental principle of secure tunnels: an association between a peer public key and a tunnel source IP address. It uses a single round trip key exchange, based on NoiseIK, and handles all session creation transparently to the user using a novel timer state machine mechanism. Short pre-shared static keys—Curve25519 points—are used for mutual authentication in the style of OpenSSH. The protocol provides strong perfect forward secrecy in addition to a high degree of identity hiding. Transport speed is accomplished using ChaCha20Poly1305 authenticated-encryption for encapsulation of packets in UDP. An improved take on IP-binding cookies is used for mitigating denial of service attacks, improving greatly on IKEv2 and DTLS’s cookie mechanisms to add encryption and authentication. The overall design allows for allocating no resources in response to received packets, and from a systems perspective, there are multiple interesting Linux implementation techniques for queues and parallelism. Finally, WireGuard can be simply implemented for Linux in less than 4,000 lines of code, making it easily audited and verified.\nPermanent ID of this document: 4846ada1492f5d92198df154f48c3d54205657bc. Static link: https://www.wireguard.com/papers/wireguard.pdf. Date: June 1, 2020. This is draft revision e2da747. A version of this paper appears in Proceedings of the Network and Distributed System Security Symposium, NDSS 2017. Copyright©2015–2020 Jason A. Donenfeld. All Rights Reserved.\n1 Introduction \u0026amp; Motivation #In Linux, the standard solution for encrypted tunnels is IPsec, which uses the Linux transform (“xfrm”) layer. Users fill in a kernel structure determining which ciphersuite and key, or other transforms such as compression, to use for which selector of packets traversing the subsystem. Generally a user space daemon is responsible for updating these data structures based on the results of a key exchange, generally done with IKEv2 [13], itself a complicated protocol with much choice and malleability. The complexity, as well as the sheer amount of code, of this solution is considerable. Administrators have a completely separate set of firewalling semantics and secure labeling for IPsec packets. While separating the key exchange layer from the transport encryption— or transformation—layer is a wise separation from a semantic viewpoint, and similarly while separating the transformation layer from the interface layer is correct from a networking viewpoint, this strictly correct layering approach increases complexity and makes correct implementation and deployment prohibitive.\nWireGuard does away with these layering separations. Instead of the complexity of IPsec and the xfrm layers, WireGuard simply gives a virtual interface—wg0for example—which can then be administered using the standard ip(8)andifconfig(8)utilities. After configuring the interface with a private key (and optionally a pre-shared symmetric key as explained in section 5.2) and the various public keys of peers with whom it will communicate securely, the tunnel simply works. Key exchanges, connections, disconnections, reconnections, discovery, and so forth happen behind the scenes transparently and reliably, and the administrator does not need to worry about these details. In other words, from the perspective of administration, the WireGuard interface appears to be stateless. Firewall rules can then be configured using the ordinary infrastructure for firewalling interfaces, with the guarantee that packets coming from a WireGuard interface will be authenticated and encrypted. Simple and straightforward, WireGuard is much less prone to catastrophic failure and misconfiguration than IPsec. It is important to stress, however, that the layering of IPsec is correct and sound ; everything is in the right place with IPsec, to academic perfection. But, as often happens with correctness of abstraction, there is a profound lack of usability, and a verifiably safe implementation is very difficult to achieve. WireGuard, in contrast, starts from the basis of flawed layering violations and then attempts to rectify the issues arising from this conflation using practical engineering solutions and cryptographic techniques that solve real world problems.\nOn the other end of the spectrum is OpenVPN, a user space TUN/TAP based solution that uses TLS. By virtue of it being in user space, it has very poor performance—since packets must be copied multiple times between kernel space and user space—and a long-lived daemon is required; OpenVPN appears far from stateless to an administrator. While TUN/TAP interfaces (say,tun0) have similarwg0-like benefits as described above, OpenVPN is also enormously complex, supporting the entire plethora of TLS functionality, which exposes quite a bit of code to potential vulnerabilities. OpenVPN is right to be implemented in user space, since ASN.1 and x parsers in the kernel have historically been quite problematic (CVE-2008-1673, CVE-2016-2053), and adding a TLS stack would only make that issue worse. TLS also brings with it an enormous state machine, as well as a less clear association between source IP addresses and public keys.\nFor key distribution, WireGuard draws inspiration from OpenSSH, for which common uses include a very simple approach toward key management. Through a diverse set of out-of-band mechanisms, two peers generally exchange their static public keys. Sometimes it is simple as PGP-signed email, and other times it is a complicated key distribution mechanism using LDAP and certificate authorities. Importantly, for the most part OpenSSH key distribution is entirely agnostic. WireGuard follows suit. Two WireGuard peers exchange their public keys through some unspecified mechanism, and afterward they are able to communicate. In other words, WireGuard’s attitude toward key distribution is that this is the wrong layer to address that particular problem, and so the interface is simple enough that any key distribution solution can be used with it. As an additional advantage, public keys are only 32 bytes long and can be easily represented in Base64 encoding in 44 characters, which is useful for transferring keys through a variety of different mediums.\nFinally, WireGuard is cryptographically opinionated. It intentionally lacks cipher and protocol agility. If holes are found in the underlying primitives, all endpoints will be required to update. As shown by the continuing torrent of SSL/TLS vulnerabilities, cipher agility increases complexity monumentally. WireGuard uses a variant of Trevor Perrin’s Noise [23]—which during its development received quite a bit of input from the authors of this paper for the purposes of being used in WireGuard—for a 1-RTT key exchange, with Curve25519 [5] for ECDH, HKDF [15] for expansion of ECDH results, RFC7539 [17]’s construction of ChaCha20 [3] and Poly1305 [8] for authenticated encryption, and BLAKE2s [2] for hashing. It has built-in protection against denial of service attacks, using a new crypto-cookie mechanism for IP address attributability.\nSimilarly opinionated, WireGuard is layer 3-only; as explained below in section 2, this is the cleanest approach for ensuring authenticity and attributability of the packets. The authors believe that layer 3 is the correct way for bridging multiple IP networks, and the imposition of this onto WireGuard allows for many simplifications, resulting in a cleaner and more easily implemented protocol. It supports layer 3 for both IPv4 and IPv6, and can encapsulate v4-in-v6 as well as v6-in-v4.\nWireGuard puts together these principles, focusing on simplicity and an auditable codebase, while still being extremely high-speed and suitable for a modicum of environments. By combining the key exchange and the layer 3 transport encryption into one mechanism and using a virtual interface rather than a transform layer, WireGuard indeed breaks traditional layering principles, in pursuit of a solid engineering solution that is both more practical and more secure. Along the way, it employs several novel cryptographic and systems solutions to achieve its goals.\n2 Cryptokey Routing #The fundamental principle of a secure VPN is an association between peers and the IP addresses each is allowed to use as source IPs. In WireGuard, peers are identified strictly by their public key, a 32-byte Curve25519 point. This means that there is a simple association mapping between public keys and a set of allowed IP addresses. Examine the following cryptokey routing table :\nConfiguration 1a\nInterface Public Key Interface Private Key Listening UDP Port HIgo\u0026hellip;8ykw yAnz\u0026hellip;fBmk 41414 Peer Public Key Allowed Source IPs xTIB\u0026hellip;p8Dg 10.192.122.3/32,10.192.124.0/24 TrMv\u0026hellip;WXX0 10.192.122.4/32,192.168.0.0/16 gN65\u0026hellip;z6EA 10.10.10.230/32 The interface itself has a private key and a UDP port on which it listens (more on that later), followed by a list of peers. Each peer is identified by its public key. Each then has a list of allowed source IPs.\nWhen an outgoing packet is being transmitted on a WireGuard interface, wg0, this table is consulted to determine which public key to use for encryption. For example, a packet with a destination IP of 10.192.122.4 will be encrypted using the secure session derived from the public key TrMv...WXX0. Conversely, when wg0 receives an encrypted packet, after decrypting and authenticating it, it will only accept it if its source IP resolves in the table to the public key used in the secure session for decrypting it. For example, if a packet is decrypted fromx TIB...qp8D, it will only be allowed if the decrypted packet has a source IP of 110.192.122.3 or in the range of 10.192.124.0 to 10.192.124.255; otherwise it is dropped.\nWith this very simple principle, administrators can rely on simple firewall rules. For example, an incoming packet on interface wg0 with a source IP of 10.10.10.230 may be considered as authentically from the peer with a public key of gN65...Bz6E. More generally, any packets arriving on a WireGuard interface will have a reliably authentic source IP (in addition, of course, to guaranteed perfect forward secrecy of the transport). Do note that this is only possible because WireGuard is strictly layer 3 based. Unlike some common VPN protocols, like L2TP/IPsec, using authenticated identification of peers at a layer 3 level enforces a much cleaner network design.\nIn the case of a WireGuard peer who wishes to route all traffic through another WireGuard peer, the cryptokey routing table could be configured more simply as:\nConfiguration 2a\nInterface Public Key Interface Private Key Listening UDP Port gN65\u0026hellip;z6EA gI6E\u0026hellip;fWGE 21841 Peer Public Key Allowed Source IPs HIgo\u0026hellip;8ykw 0.0.0.0/0 Here, the peer authorizes HIgo...f8yk to put packets onto wg0 with any source IP, and all packets that are outgoing on wg0 will be encrypted using the secure session associated with that public key and sent to that peer’s endpoint.\n2.1 Endpoints \u0026amp; Roaming #Of course, it is important that peers are able to send encrypted WireGuard UDP packets to each other at particular Internet endpoints. Each peer in the cryptokey routing table may optionally pre-specify a known external IP address and UDP port of that peer’s endpoint. The reason it is optional is that if it is not specified and WireGuard receives a correctly authenticated packet from a peer, it will use the outer external source IP address for determining the endpoint.\nSince a public key uniquely identifies a peer, the outer external source IP of an encrypted WireGuard packet is used to identify the remote endpoint of a peer, enabling peers to roam freely between different external IPs, between mobile networks for example, similar to what is allowed by Mosh [25]. For example, the prior cryptokey routing table could be augmented to have the initial endpoint of a peer:\nConfiguration 2b\nInterface Public Key Interface Private Key Listening UDP Port gN65\u0026hellip;z6EA gI6E\u0026hellip;fWGE 21841 Peer Public Key Allowed Source IPs Internet Endpoint HIgo\u0026hellip;8ykw 0.0.0.0/0 192.95.5.69:41414 Then, this host, gN65...z6EA, sends an encrypted packet to HIgo...f8yk at 192.95.5.69:41414. After HIgo...f8yk receives a packet, it updates its table to learn that the endpoint for sending reply packets is, for example, 192.95.5.64:21841:\nConfiguration 1b\nInterface Public Key Interface Private Key Listening UDP Port HIgo\u0026hellip;8ykw yAnz\u0026hellip;fBmk 41414 Peer Public Key Allowed Source IPs Internet Endpoint xTIB\u0026hellip;p8Dg 10.192.122.3/32,10.192.124.0/ TrMv\u0026hellip;WXX0 10.192.122.4/32,192.168.0.0/ gN65\u0026hellip;z6EA 10.10.10.230/32 192.95.5.64:21841 Note that the listen port of peers and the source port of packets sent are always the same, adding much simplicity, while also ensuring reliable traversal behind NAT. And since this roaming property ensures that peers will have the very latest external source IP and UDP port, there is no requirement for NAT to keep sessions open for long. (For use cases in which it is imperative to keep open a NAT session or stateful firewall indefinitely, the interface can be optionally configured to periodically send persistent authenticated keepalives.)\nThis design allows for great convenience and minimal configuration. While an attacker with an active man-in-the-middle could, of course, modify these unauthenticated external source IPs, the attacker would not be able to decrypt or modify any payload, which merely amounts to a denial-of-service attack, which would already be trivially possible by just dropping the original packets from this presumed man-in-the-middle position. And, as explained in section Passive Keepalive, hosts that cannot decrypt and subsequently reply to packets will quickly be forgotten.\n3 Send/Receive Flow #The roaming design of section Endpoint \u0026amp; Roaming, put together with the cryptokey routing table of section 2, amounts to the following flows when receiving and sending a packet on interfacewg0using Configuration 1 from above.\nA packet is locally generated (or forwarded) and is ready to be transmitted on the outgoing interfacewg0:\nThe plaintext packet reaches the WireGuard interface, wg0.\nThe destination IP address of the packet, 192.168.87.21, is inspected, which matches the peer TrMv...WXX0. (If it matches no peer, it is dropped, and the sender is informed by a standard ICMP “no route to host” packet, as well as returning ENOKEY to user space.)\nThe symmetric sending encryption key and nonce counter of the secure session associated with peer TrMv...WXX0 are used to encrypt the plaintext packet using ChaCha20Poly1305.\nA header containing various fields, explained in section 5.4, is prepended to the now encrypted packet.\nThis header and encrypted packet, together, are sent as a UDP packet to the Internet UDP/IP endpoint associated with peer TrMv...WXX0, resulting in an outer UDP/IP packet containing as its payload a header and encrypted inner-packet. The peer’s endpoint is either pre-configured, or it is learned from the outer external source IP header field of the most recent correctly-authenticated packet received. (Otherwise, if no endpoint can be determined, the packet is dropped, an ICMP message is sent, and EHOSTUNREACH is returned to user space.)\nA UDP/IP packet reaches UDP port 41414 of the host, which is the listening UDP port of interface wg0:\nA UDP/IP packet containing a particular header and an encrypted payload is received on the correct port (in this particular case, port 41414).\nUsing the header (described below in section Messages), WireGuard determines that it is associated with peer TrMv...WXX0’s secure session, checks the validity of the message counter, and attempts to authenticate and decrypt it using the secure session’s receiving symmetric key. If it cannot determine a peer or if authentication fails, the packet is dropped.\nSince the packet has authenticated correctly, the source IP of the outer UDP/IP packet is used to update the endpoint for peer TrMv...WXX0.\nOnce the packet payload is decrypted, the interface has a plaintext packet. If this is not an IP packet, it is dropped. Otherwise, WireGuard checks to see if the source IP address of the plaintext inner-packet routes correspondingly in the cryptokey routing table. For example, if the source IP of the decrypted plaintext packet is 192.168.31.28, the packet correspondingly routes. But if the source IP is 10.192.122.3, the packet does not route correspondingly for this peer, and is dropped.\nIf the plaintext packet has not been dropped, it is inserted into the receive queue of the wg0 interface.\nIt would be possible to separate the list of allowed IPs into two lists—one for checking the source address of incoming packets and one for choosing peer based on the destination address. But, by keeping these as part of the same list, it allows for something similar to reverse-path filtering. When sending a packet, the list is consulted based on the destination IP; when receiving a packet, that same list is consulted for determining if the source IP is allowed. However, rather than asking whether the received packet’s sending peer has that source IP as part of its allowed IPs list, it instead is able to ask a more global question—which peer would be chosen in the table for that source IP, and does that peer match that of the received packet. This enforces a one-to-one mapping of sending and receiving IP addresses, so that if a packet is received from a particular peer, replies to that IP will be guaranteed to go to that same peer.\n4 Basic Usage #Before going deep into the cryptography and implementation details, it may be useful to see a simple command line interface for using WireGuard, to bring concreteness to the concepts thus far presented.\nConsider a Linux environment with a single physical network interface,eth0, connecting it to the Internet with a public IP of 192.95.5.69. A WireGuard interface, wg0, can be added and configured to have a tunnel IP address of 10.192.122.3 in a /24 subnet with the standard ip(8) utilities, shown on the left. The cryptokey routing table can then be configured using the wg(8) tool in a variety of fashions, including reading from configuration files, shown on the right:\nAdding the wg0 interface\n$ ip link add dev wg0 type wireguard $ ip address add dev wg0 10.192.122.3/ $ ip route add 10.0.0.0/8 dev wg $ ip address show 1: lo: \u0026lt;LOOPBACK\u0026gt; mtu 65536 inet 127.0.0.1/8 scope host lo 2: eth0: \u0026lt;BROADCAST\u0026gt; mtu 1500 inet 192.95.5.69/24 scope global eth 3: wg0: \u0026lt;POINTOPOINT,NOARP\u0026gt; mtu 1420 inet 10.192.122.3/24 scope global wg Configuring the cryptokey routing table of wg0\n$ wg setconf wg0 configuration-1.conf $ wg show wg interface: wg public key: HIgo...8ykw private key: yAnz...fBmk listening port: 41414 peer: xTIB...p8Dg allowed ips: 10.192.124.0/24, 10.192.122.3/ peer: TrMv...WXX allowed ips: 192.168.0.0/16, 10.192.122.4/ peer: gN65...z6EA allowed ips: 10.10.10.230/ endpoint: 192.95.5.70: $ ip link set wg0 up $ ping 10.10.10. PING 10.10.10.230 56(84) bytes of data. 64 bytes: icmp_seq=1 ttl=49 time=0.01 ms At this point, sending a packet to 10.10.10.230 on that system will send the data through the wg0 interface, which will encrypt the packet using a secure session associated with the public key gN65...z6EA and send that encrypted and encapsulated packet to 192.95.5.70:54421 over UDP. When receiving a packet from 10.10.10.230 on wg0, the administrator can be assured that it is authentically from gN65...z6EA.\n5 Protocol \u0026amp; Cryptography #As mentioned prior, in order to begin sending encrypted encapsulated packets, a 1-RTT key exchange handshake must first take place. The initiator sends a message to the responder, and the responder sends a message back to the initiator. After this handshake, the initiator may send encrypted messages using a shared pair of symmetric keys, one for sending and one for receiving, to the responder, and following the first encrypted message from initiator to responder, the responder may begin to send encrypted messages to the initiator. This ordering restriction is to require confirmation as described for KEA+C [18], as well as allowing handshake message to be processed asynchronously to transport data messages. These messages use the “IK” pattern from Noise [23], in addition to a novel cookie construction to mitigate denial of service attacks. The net result of the protocol is a very robust security system, which achieves the requirements of authenticated key exchange (AKE) security [18], avoids key-compromise impersonation, avoids replay attacks, provides perfect forward secrecy, provides identity hiding of static public keys similar to SIGMA [16], and has resistance to denial of service attacks.\n5.1 Silence is a Virtue #One design goal of WireGuard is to avoid storing any state prior to authentication and to not send any responses to unauthenticated packets. With no state stored for unauthenticated packets, and with no response generated, WireGuard is invisible to illegitimate peers and network scanners. Several classes of attacks are avoided by not allowing unauthenticated packets to influence any state. And more generally, it is possible to implement WireGuard in a way that requires no dynamic memory allocation at all, even for authenticated packets, as explained in section 7. However, this property requires the very first message received by the responder to authenticate the initiator. Having authentication in the first packet like this potentially opens up the responder to a replay attack. An attacker could replay initial handshake messages to trick the responder into regenerating its ephemeral key, thereby invalidating the session of the legitimate initiator (though not affecting the secrecy or authenticity of any messages). To prevent this, a 12-byte TAI64N [7] timestamp is included, encrypted and authenticated, in the first message. The responder keeps track of the greatest timestamp received per peer and discards packets containing timestamps less than or equal to it. (In fact, it does not even have to be an accurate timestamp; it simply must be a per-peer monotonically increasing 96-bit number.) If the responder restarts and loses this state, that is not a problem: even though an initial packet from earlier can be replayed, it could not possibly disrupt any ongoing secure sessions, because the responder has just restarted and therefore has no active secure sessions to disrupt. Once the initiator reestablishes a secure session with the responder after its restart, the initiator will be using a greater timestamp, invalidating the previous one. This timestamp ensures that an attacker may not disrupt a current session between initiator and responder via replay attack. (This also means that two distinct peers should not share private keys, since in that situation a packet sent to one could be replayed to another, and the ensuing response would then cause the initiator to involuntarily roam from one peer to another. But one should not be sharing private keys in the first place, anyway.) From an implementation point of view, TAI64N [7] is very convenient because it is big-endian, allowing comparisons between two 12-byte timestamps to be done using standardmemcmp(). Since WireGuard does not use signatures, in order to gain a degree of deniability, the first message relies only on a Diffie-Hellman result of both peers’ static keys for authentication. This means that if either one of their static keys is compromised, an attacker would be able to forge an initiation message—though it would not be able to complete the full handshake—containing a maximum timestamp value, thereby preventing all future connections from succeeding. While this may seem similar to traditional key-compromise impersonation vulnerabilities—to which WireGuard is not vulnerable—it is in fact very different. For, if a key compromise enables an attacker to prevent peers from ever using their compromised keys again, the attacker has actually aided a proper response to such a compromise. If the precision of a TIA64N timestamp poses an unsuitable information leak, implementations may truncate 24 bits of the nanoseconds portion of the timestamp.\n5.2 Optional Pre-shared Symmetric Key Mode #WireGuard rests upon peers exchanging static public keys with each other a priori , as their static identities. The secrecy of all data sent relies on the security of the Curve25519 ECDH function. In order to mitigate any future advances in quantum computing, WireGuard also supports a mode in which any pair of peers might additionally pre-share a single 256-bit symmetric encryption key between themselves, in order to add an additional layer of symmetric encryption. The attack model here is that adversaries may be recording encrypted traffic on a long term basis, in hopes of someday being able to break Curve25519 and decrypt past traffic. While pre-sharing symmetric encryption keys is usually troublesome from a key management perspective and might be more likely stolen, the idea is that by the time quantum computing advances to break Curve25519, this pre-shared symmetric key has been long forgotten. And, more importantly, in the shorter term, if the pre-shared symmetric key is compromised, the Curve25519 keys still provide more than sufficient protection. In lieu of using a completely post-quantum crypto system, which as of writing are not practical for use here, this optional hybrid approach of a pre-shared symmetric key to complement the elliptic curve cryptography provides a sound and acceptable trade-off for the extremely paranoid. Furthermore, it allows for building on top of WireGuard sophisticated key-rotation schemes, in order to achieve varying types of post-compromise security.\n5.3 Denial of Service Mitigation \u0026amp; Cookies #Computing Curve25519 point multiplication is CPU intensive, even if Curve25519 is an extremely fast curve on most processors. In order to determine the authenticity of a handshake message, a Curve25519 multiplication must be computed, which means there is a potential avenue for a denial-of-service attack. In order to fend off a CPU-exhaustion attack, if the responder—the recipient of a message—is under load, it may choose to not process a handshake message (either an initiation or a response handshake message), but instead to respond with a cookie reply message, containing a cookie. The initiator then uses this cookie in order to resend the message and have it be accepted the following time by the responder.\nThe responder maintains a secret random value that changes every two minutes. A cookie is simply the result of computing a MAC of the initiator’s source IP address using this changing secret as the MAC key. The initiator, when resending its message, sends a MAC of its message using this cookie as the MAC key. When the responder receives the message, if it is under load, it may choose whether or not to accept and process the message based on whether or not there is a correct MAC that uses the cookie as the key. This mechanism ties messages sent from an initiator to its IP address, giving proof of IP ownership, allowing for rate limiting using classical IP rate limiting algorithms (token bucket, etc—see section 7.4 for implementation details).\nThis is more or less the scheme used by DTLS [24] and IKEv2 [13]. However it suffers from three major flaws. First, as mentioned in section 5.1, we prefer to stay silent by not sending any reply to unauthenticated messages; indiscriminately sending a cookie reply message when under load would break this property. Second, the cookie should not be sent in clear text, because a man-in-the-middle could use this to then send fraudulent messages that are processed. And third, the initiator himself could be denial-of-service attacked by being sent fraudulent cookies, which it would then use with no success in computing a MAC of its message. The cookie mechanism of WireGuard, which uses two MACs (msg.mac1andmsg.mac2), fixes these problems, the computations for which will be shown in section 5.4.4 below.\nFor the first problem, in order for the responder to remain silent, even while under load, all messages have a first MAC (msg.mac1) that uses the responder’s public key. This means that at the very least, a peer sending a message must know to whom it is talking (by virtue of knowing its public key), in order to elicit any kind of response. Under load or not under load, this first MAC (msg.mac1) always is required to be present and valid. While the public key of the responder itself is not secret, it is sufficiently secret within this attack model, in which the goal is to ensure stealthiness of services, and so knowing the responder’s public key is sufficient proof for already knowing of its existence. (It is worth noting that this first MAC allows a passive attacker to make guesses about for which public key the packet is intended, slightly weakening identity hiding properties, though a correct guess would not constitute cryptographic proof since no private material was used in generating the MAC.)\nLikewise, to solve the second problem—that of sending MACs in clear text—we apply an AEAD with an extended randomized nonce to the cookie in transit, again using as a symmetric encryption key the responder’s public key. Again, the mostly public values here are sufficient for our purposes within the denial-of-service attack threat model.\nFinally, to solve the third problem, we use the “additional data” field of the AEAD to encrypt the cookie in transit to additionally authenticate the first MAC (msg.mac1) of the initiating message that provoked a cookie reply message. This ensures that an attacker without a man-in-the-middle position cannot send torrents of invalid cookie replies to initiators to prevent them from authenticating with a correct cookie. (An attacker with an man-in-the-middle position could simply drop cookie reply messages anyway to prevent a connection, so that case is not relevant, though an attacker with a merely passive man-in-the-middle position could indeed forge these packets, which is not considerably different from a denial-of-service attack against TCP.) In other words, we use the AD field to bind cookie replies to initiation messages.\nWith these problems solved, we can then add the aforementioned second MAC (msg.mac2) using the securely transmitted cookie as the MAC key. When the responder is under load, it will only accept messages that additionally have this second MAC.\nIn sum, the responder, after computing these MACs as well and comparing them to the ones received in the message, must always reject messages with an invalidmsg.mac1, and when under load may reject messages with an invalidmsg.mac2. If the responder receives a message with a validmsg.mac1yet with an invalidmsg.mac2, and is under load , it may respond with a cookie reply message, detailed in section 5.4.7. This considerably improves on the cookie scheme used by DTLS and IKEv2.\nIn contrast to HIPv2 [20], which solves this problem by using a 2-RTT key exchange and complexity puzzles, WireGuard eschews puzzle-solving constructs, because the former requires storing state while the latter makes the relationship between initiator and responder asymmetric. In WireGuard, either peer at any point might be motivated to begin a handshake. This means that it is not feasible to require a complexity puzzle from the initiator, because the initatior and responder may soon change roles, turning this mitigation mechanism into a denial of service vulnerability itself. Our above cookie solution, in contrast, enables denial of service attack mitigation on a 1-RTT protocol, while keeping the initiator and responder roles symmetric.\n5.4 Messages #There are four types of messages, each prefixed by a single-byte message type identifier, notated asmsg.type below:\nSection 5.4.2: The handshake initiation message that begins the handshake process for establishing a secure session. Section 5.4.3: The handshake response to the initiation message that concludes the handshake, after which a secure session can be established. Section 5.4.7: A reply to either a handshake initiation message or a handshake response message, explained in section 5.3, that communicates an encrypted cookie value for use in resending either the rejected handshake initiation message or handshake response message. Section 5.4.6: An encapsulated and encrypted IP packet that uses the secure session negotiated by the handshake. The initiator of the handshake is denoted as subscript i , and the responder of the handshake is denoted as subscript r , and either one is denoted as subscript∗. For messages that can be created by either an initiator or responder, if the peer creating the message is the initiator, let( m,m ′) = ( i,r ), and if the peer creating the message is the responder, let( m,m ′) = ( r,i ). The two peers have several variables they maintain locally:\nI ∗ A 32-bit index that locally represents the other peer, analogous to IPsec’s “SPI”. Spriv ∗ , S ∗ pub The static private and public key values. E ∗ priv , Epub ∗ The ephemeral private and public key values. Q The optional pre-shared symmetric key value from section 5.2 When pre-shared key mode is not in use, this is set to 032. H ∗, C ∗ A hash result value and a chaining key value. T ∗ send , T ∗ recv Transport data symmetric key values for sending and receiving. N ∗ send , N ∗ recv Transport data message nonce counters for sending and receiving. In the constructions that follow, several symbols, functions, and operators are used. The binary operator‖ represents concatenation of its operands, and the binary operator:=represents assignment of its right operand to its left operand. The annotation̂ n returns the value( n + 16), which is the Poly1305 authentication tag length added to n. \u000f represents an empty zero-length bitstring, 0 n represents the all zero (0x0) bitstring of length n bytes, and ρn represents a random bitstring of length n bytes. Let τ be considered a temporary variable and let κ be considered a temporary encryption key. All integer assignments are little-endian, unless otherwise noted. The following functions and constants are utilized:\nDH(private key, public key)Curve25519 point multiplication ofprivate keyandpublic key, re- turning 32 bytes of output. DH-Generate()Generates a random Curve25519 private key and derives its corresponding public key, returning a pair of 32 bytes values, (private, public). Aead(key, counter, plain text, auth text)ChaCha20Poly1305 AEAD, as specified in RFC7539 [17], with its nonce being composed of 32 bits of zeros followed by the 64-bit little-endian value ofcounter. Xaead(key, nonce, plain text, auth text)XChaCha20Poly1305 AEAD, with a 24-byte random nonce, instantiated using HChaCha20 [6] and ChaCha20Poly1305. Hash(input)Blake2s(input, 32), returning 32 bytes of output. Mac(key, input)Keyed-Blake2s(key, input, 16), the keyed MAC variant of the BLAKE2s hash function, returning 16 bytes of output. Hmac(key, input)Hmac-Blake2s(key, input, 32), the ordinary BLAKE2s hash function used in an HMAC construction, returning 32 bytes of output. Kdf n (key, input)Sets τ 0 :=Hmac(key , input) ,τ 1 :=Hmac( τ 0 , 0x1) ,τi :=Hmac( τ 0 ,τi − 1 ‖i), and returns an n -tuple of 32 byte values,( τ 1 ,...,τn ). This is the HKDF [15] function. Timestamp()Returns the TAI64N timestamp [7] of the current time, which is 12 bytes of output, the first 8 bytes being a big-endian integer of the number of seconds since 1970 TAI and the last 4 bytes being a big-endian integer of the number of nanoseconds from the beginning of that second. ConstructionThe UTF-8 string literal “Noise_IKpsk2_25519_ChaChaPoly_BLAKE2s”, 37 bytes of output. IdentifierThe UTF-8 string literal “WireGuard v1 zx2c4 Jason@zx2c4.com”, 34 bytes of output. Label-Mac1The UTF-8 string literal “mac1----”, 8 bytes of output. Label-CookieThe UTF-8 string literal “cookie--”, 8 bytes of output. 5.4.1 Protocol Overview #In the majority of cases, the handshake will complete in 1-RTT, after which transport data follows:\nsequenceDiagram participant Initiator participant Responder Initiator-\u0026gt;\u0026gt;Responder: Handshake Initiation Responder-\u0026gt;\u0026gt;Initiator: Handshake Response Initiator-\u0026gt;\u0026gt;Responder: Transport Data Responder-\u0026gt;\u0026gt;Initiator: Transport Data If one peer is under load, then a cookie reply message is added to the handshake, to prevent against denial-of-service attacks:\nsequenceDiagram participant Initiator participant Responder Initiator-\u0026gt;\u0026gt;Responder: Handshake Initiation Responder-\u0026gt;\u0026gt;Initiator: Cookie Reply Initiator-\u0026gt;\u0026gt;Responder: Handshake Initiation Responder-\u0026gt;\u0026gt;Initiator: Handshake Response Initiator-\u0026gt;\u0026gt;Responder: Transport Data Responder-\u0026gt;\u0026gt;Initiator: Transport Data 5.4.2 First Message: Initiator to Responder #The initiator sends this message, msg:\n|--------------------|--------------------------| | type:=0x1(1 byte) | reserved:= 0^3 (3 bytes) | |-----------------------------------------------| | sender := Ii (4 bytes) | |-----------------------------------------------| | ephemeral (32 bytes) | |-----------------------------------------------| | static (̂32 bytes) | |-----------------------------------------------| | timestamp (̂12 bytes) | |-----------------------------------------------| | mac1 (16 bytes) | mac2 (16 bytes) | |--------------------|--------------------------| Thetimestampfield is explained in section 5.1, andmac1andmac2are explained further in section 5.4.4. Ii is generated randomly ( ρ^4 ) when this message is sent, and is used to tie subsequent replies to the session begun by this message. The above remaining fields are calculated [23] as follows:\nCi :=Hash(Construction) Hi :=Hash( Ci ‖Identifier) Hi :=Hash( Hi ‖ Spubr ) ( Eipriv,Eipub ):=DH-Generate() Ci :=Kdf 1 ( Ci,Eipub ) msg.ephemeral:= Eipub Hi :=Hash( Hi ‖msg.ephemeral) ( Ci,κ ):=Kdf 2 ( Ci, DH( Eipriv,Srpub )) msg.static:=Aead( κ, 0 ,Spubi ,Hi ) Hi :=Hash( Hi ‖msg.static) ( Ci,κ ):=Kdf 2 ( Ci, DH( Sipriv,Spubr )) msg.timestamp:=Aead( κ, 0 , Timestamp() ,Hi ) Hi :=Hash( Hi ‖msg.timestamp) When the responder receives this message, it does the same operations so that its final state variables are identical, replacing the operands of theDHfunction to produce equivalent values. (Side note: while not part of Noise and hence not part of WireGuard at the moment, one modification on the above message would be to computemsg.staticrather asAead( κ, 0 , Hash( Spubi ) ,Hi ). The additional hash ensures that this elliptic curve point would not be transmitted directly, and hence the entire handshake would have some limited degree of non-forward secret post-quantum security, provided the public keys are not made known by some other means.)\n5.4.3 Second Message: Responder to Initiator #The responder sends this message, after processing the first message above from the initiator and applying the same operations to arrive at an identical state. Ir is generated randomly ( ρ^4 ) when this message is sent, and is used to tie subsequent replies to the session begun by this message, just as above. The responder sends this message,msg:\n|------------------------|--------------------------| | type:=0x2(1 byte) | reserved:= 0^3 (3 bytes) | |------------------------|--------------------------| | sender := Ir (4 bytes) | receiver := Ii (4 bytes) | |-----------------------------------------------| | ephemeral (32 bytes) | |-----------------------------------------------| | empty (^0 bytes) | |-----------------------------------------------| | mac1 (16 bytes) | mac2 (16 bytes) | |--------------------|--------------------------| The fieldsmac1andmac2are explained further in section 5.4.4. The above remaining fields are calculated [23] as follows:\n( Eprivr ,Epubr ):=DH-Generate() Cr :=Kdf 1 ( Cr,Epubr ) msg.ephemeral:= Erpub Hr :=Hash( Hr ‖msg.ephemeral) Cr :=Kdf 1 ( Cr, DH( Erpriv,Eipub )) Cr :=Kdf 1 ( Cr, DH( Erpriv,Spubi )) ( Cr,τ,κ ):=Kdf 3 ( Cr,Q ) Hr :=Hash( Hr ‖ τ ) msg.empty := Aead(κ, 0, \u000f, Hr ) Hr :=Hash( Hr ‖msg.empty) When the initiator receives this message, it does the same operations so that its final state variables are identical, replacing the operands of theDHfunction to produce equivalent values. Note that this handshake response message is smaller than the handshake initiation message, preventing amplification attacks.\n5.4.4 Cookie MACs #In sections 5.4.2 and 5.4.3, the two handshake messages have themsg.mac1andmsg.mac2parameters. For a given handshake message,msg α represents all bytes ofmsgprior tomsg.mac1, andmsg β represents all bytes of msgprior tomsg.mac2. The latest cookie received L ̃∗seconds ago is represented by L ∗. Themsg.mac1and msg.mac2fields are populated as follows:\nmsg.mac1:=Mac(Hash(Label-Mac1‖ Spubm ′) , msg α ) if Lm = \u000f or L ̃ m ≥ 120 : msg.mac2:= 0^16 otherwise: msg.mac2:=Mac( Lm, msg β ) The valueHash(Label-Mac1‖ Smpub ′)above can be pre-computed.\n5.4.5 Transport Data Key Derivation #After the above two messages have been exchanged, keys are calculated [23] by the initiator and responder for sending and receiving transport data messages (section 5.4.6):\n( Tisend = Trrecv,Tirecv = Trsend ):=Kdf 2 ( Ci = Cr,\u000f ) Nisend = Nrrecv = Nirecv = Nrsend := 0 Eprivi = Epubi = Eprivr = Erpub = Ci = Cr := \u000f On the last line, most prior states of the handshake are zeroed from memory (described in section 7.4), but the value Hi = Hr is not necessarily zeroed, as it could potentially be useful in future revisions of Noise [23].\n5.4.6 Subsequent Messages: Transport Data Messages #The initiator and the responder exchange transport data messages for exchanging encrypted encapsulated packets. The inner plaintext packet that is encapsulated is represented as P , of length‖ P ‖. Both peers send this message, msg:\n|--------------------|--------------------------| | type:=0x4(1 byte) | reserved:= 0^3 (3 bytes) | |-----------------------------------------------| | receiver:= Im\u0026#39; (4 bytes) | |-----------------------------------------------| | counter (8 bytes) | |-----------------------------------------------| | packet (^‖P ‖ bytes) | |-----------------------------------------------| The remaining fields are populated as follows:\nP := P ‖ 016 ·d‖ P ‖ /^16 e−‖ P ‖ msg.counter:= Nmsend msg.packet:=Aead( Tmsend,Nmsend,P,\u000f ) Nmsend := Nmsend + 1 The recipient of this messages uses Tmrecv ′ to read the message. Note that no length value is stored in this header, since the authentication tag serves to determine whether the message is legitimate, and the inner IP packet already has a length field in its header. The encapsulated packet itself is zero padded (without modifying the IP packet’s length field) before encryption to complicate traffic analysis, though that zero padding should never increase the UDP packet size beyond the maximum transmission unit length. Prior tomsg.packet, there are exactly 16 bytes of header fields, which means that decryption may be done in-place and still achieve natural memory address alignment, allowing for easier implementation in hardware and a significant performance improvement on many common CPU architectures. This is in part the result of the 3 bytes of reserved zero fields, making the first four bytes readable together as a little-endian integer.\nThe msg.counter value is a nonce for the ChaCha20Poly1305 AEAD and is kept track of by the recipient using Nmrecv ′. It also functions to avoid replay attacks. Since WireGuard operates over UDP, messages can sometimes arrive out of order. For that reason we use a sliding window to keep track of received message counters, in which we keep track of the greatest counter received, as well as a window of prior messages received, checked only after having verified the authentication tag, using the algorithm detailed by appendix C of RFC2401 [14] or by RFC6479 [26], which uses a larger bitmap while avoiding bitshifts, enabling more extreme packet reordering that may occur on multi-core systems.\n5.4.7 Under Load: Cookie Reply Message #As mentioned in section 5.3, when a message with a validmsg.mac1is received, butmsg.mac2is invalid or expired, and the peer is under load, the peer may send a cookie reply message. Im ′is determined from the msg.senderfield of the message that prompted this cookie reply message,msg:\n|--------------------|--------------------------| | type:=0x3(1 byte) | reserved:= 0^3 (3 bytes) | |-----------------------------------------------| | receiver:= Im ′(4 bytes) | |-----------------------------------------------| | nonce:= ρ^24 (24 bytes) | |-----------------------------------------------| | cookie( ^16 bytes) | |-----------------------------------------------| The secret variable, Rm , changes every two minutes to a random value, Am ′represents a concatenation of the subscript’s external IP source address and UDP source port, and M represents themsg.mac1value of the message to which this is in reply. The remaining encrypted cookie reply field is populated as such:\n$$ \\(τ := Mac(Rm, Am′ )\\) $$\n$$ \\(msg.cookie := Xaead(Hash(Label-Cookie ‖ S pub m ), msg.nonce, τ, M )\\) $$\nThe valueHash(Label-Cookie‖ Smpub )above can be pre-computed. By using M as the additional authenticated data field, we bind the cookie reply to the relevant message, in order to prevent peers from being attacked by sending them fraudulent cookie reply messages. Also note that this message is smaller than either the handshake initiation message or the handshake response message, avoiding amplification attacks. Upon receiving this message, if it is valid, the only thing the recipient of this message should do is store the cookie along with the time at which it was received. The mechanism described in section 6 will be used for retransmitting handshake messages with these received cookies; this cookie reply message should not, by itself, cause a retransmission.\n6 Timers \u0026amp; Stateless UX #From the perspective of the user, WireGuard appears stateless. The private key of the interface is configured, followed by the public key of each of its peers, and then a user may simply send packets normally. The maintenance of session states, perfect forward secrecy, handshakes, and so forth is completely behind the scenes, invisible to the user. While similar automatic mechanisms historically have been buggy and disastrous, WireGuard employs an extremely simple timer state machine, in which each state and transitions to all adjacent states are clearly defined, resulting in total reliability. There are no anomalous states or sequences of states; everything is accounted for. It has been tested with success on 10 gigabit intranets as well as on low-bandwidth high-latency transatlantic commercial airline Internet. The simplicity of the timer state machine is owed to the fact that only a 1-RTT handshake is required, that the initiator and responder can transparently switch roles, and that WireGuard breaks down traditional layering, as discussed in section 1, and can therefore use intra-layer characteristics.\n6.1 Preliminaries #The following constants are used for the timer state system:\nSymbol Value Rekey-After-Messages 2^60 messages Reject-After-Messages 2^64 - 2^13 - 1 messages Rekey-After-Time 120 seconds Reject-After-Time 180 seconds Rekey-Attempt-Time 90 seconds Rekey-Timeout 5 seconds Keepalive-Timeout 10 seconds Under no circumstances will WireGuard send an initiation message more than once every Rekey-Timeout. A secure session is created after the successful receipt of a handshake response message (section 5.4.3), and the age of a secure session is measured from the time of processing this message and the immediately following derivation of transport data keys (section 5.4.5). Whenever a handshake initiation message is sent as the result of an expiring timer, an additional amount of jitter is added to the expiration, in order to prevent two peers from repeatedly initiating handshakes at the same time.\n6.2 Transport Message Limits #After a secure session has first been established, WireGuard will try to create a new session, by sending a handshake initiation message (section 5.4.2), after it has sent Rekey-After-Messages transport data messages. Likewise, if a peer is the initiator of a current secure session, WireGuard will send a handshake initiation message to begin a new secure session if, after transmitting a transport data message, the current secure session is Rekey-After-Time seconds old, or if after receiving a transport data message, the current secure session is( Reject-After-Time − Keepalive-Timeout − Rekey-Timeout )seconds old and it has not yet acted upon this event. This time-based opportunistic rekeying is restricted to the initiator of the current session, in order to prevent the “thundering herd” problem, in which both peers might try to establish a new session at the same time. Due to the passive keepalive feature, described in section 6.5, the initiation triggered by an old secure session after transmitting a transport data message should usually be sufficient to ensure new sessions are created every Rekey-After-Time seconds. However, for the case in which a peer has received data but does not have any data to send back immediately, and the Reject-After-Time second deadline is approaching in sooner than Keepalive-Timeout seconds, then the initiation triggered by an aged secure session occurs during the receive path. After Reject-After-Messages transport data messages or after the current secure session is Reject- After-Time seconds old, whichever comes first, WireGuard will refuse to send or receive any more transport data messages using the current secure session, until a new secure session is created through the 1-RTT handshake.\n6.3 Key Rotation #New secure sessions are created approximately every Rekey-After-Time seconds (which is far more likely to occur before Rekey-After-Messages transport data messages have been sent), due to the transport message limits described above in section 6.2. This means that the secure session is constantly rotating, creating a new ephemeral symmetric session key each time, for perfect forward secrecy. But, keep in mind that after an initiator receives a handshake response message (section 5.4.3), the responder cannot send transport data messages (section 5.4.6) until it has received the first transport data message from the initiator. And, further, transport data messages encrypted using the previous secure session might be in transit after a new secure session has been created. For these reasons, WireGuard keeps in memory the current secure session, the previous secure session, and the next secure session for the case of an unconfirmed session. Every time a new secure session is created, the existing one rotates into the “previous” slot, and the new one occupies the “current” slot, for the initiator, and for the responder, the “next” slot is used interstitially until the handshake is confirmed. The “previous-previous” one is then discarded and its memory is zeroed (see section 7.4 for a discussion of memory zeroing). If no new secure session is created after ( Reject-After-Time ×3) seconds, the current secure session, the previous secure session, and potentially the next secure session are discarded and zeroed out, in addition to any possible partially-completed handshake states and ephemeral keys.\n6.4 Handshake Initiation Retransmission #The first time the user sends a packet over a WireGuard interface, the packet cannot immediately be sent, because no current session exists. So, after queuing the packet, WireGuard sends a handshake initiation message (section 5.4.2). After sending a handshake initiation message, because of a first-packet condition, or because of the limit conditions of section 6.2, if a handshake response message (section 5.4.3) is not subsequently received after Rekey-Timeout seconds, a new handshake initiation message is constructed (with new random ephemeral keys) and sent. This reinitiation is attempted for Rekey-Attempt-Time seconds before giving up, though this counter is reset when a peer explicitly attempts to send a new transport data message. Critically important future work includes adjusting the Rekey-Timeout value to use exponential backoff, instead of the current fixed value.\n6.5 Passive Keepalive #Most importantly, and most elegant, WireGuard implements a passive keepalive mechanism to ensure that sessions stay active and allow both peers to passively determine if a connection has failed or been disconnected. If a peer has received a validly-authenticated transport data message (section 5.4.6), but does not have any packets itself to send back for Keepalive-Timeout seconds, it sends a keepalive message. A keepalive message is simply a transport data message with a zero-length encapsulated encrypted inner-packet. Since all other transport data messages contain IP packets, which have a minimum length ofmin(‖IPv4 header‖ , ‖IPv6 header‖), this keepalive message can be easily distinguished by simple virtue of having a zero length encapsulated packet. (Note that themsg.packetfield of the message will in fact be of length 16, the length of the Poly1305 [8] authentication tag, since a zero length plaintext still needs to be authenticated, even if there is nothing to encrypt.)\nThis passive keepalive is only sent when a peer has nothing to send, and is only sent in circumstances when another peer is sending authenticated transport data messages to it. This means that when neither side is exchanging transport data messages, the network link will be silent.\nBecause every transport data message sent warrants a reply of some kind—either an organic one generated by the nature of the encapsulated packets or this keepalive message—we can determine if the secure session is broken or disconnected if a transport data message has not been received for ( Keepalive-Timeout + Rekey-Timeout ) seconds, in which case a handshake initiation message is sent to the unresponsive peer, once every Rekey-Timeout seconds, as in section 6.4, until a secure session is recreated successfully or until Rekey-Attempt-Time seconds have passed.\n6.6 Interaction with Cookie Reply System #As noted in sections 5.3 and 5.4.7, when a peer is under load, a handshake initiation message or a handshake response message may be discarded and a cookie reply message sent. On receipt of the cookie reply message, which will enable the peer to send a new initiation or response message with a validmsg.mac2that will not be discarded, the peer is not supposed to immediately resend the now valid message. Instead, it should simply store the decrypted cookie value from the cookie reply message, and wait for the expiration of the Rekey-Timeout timer for retrying a handshake initiation message. This prevents potential bandwidth generation abuse, and helps to alleviate the load conditions that are requiring the cookie reply messages in the first place.\n7 Linux Kernel Implementation #The implementation of WireGuard inside the Linux kernel has a few goals. First, it should be short and simple, so that auditing and reviewing the code for security vulnerabilities is not only easy, but also enjoyable; WireGuard is implemented in less than 4,000 lines of code (excluding cryptographic primitives). Second, it must be extremely fast, so that it is competitive with IPsec on performance. Third, it must avoid allocations and other resource intensive allocations in response to incoming packets. Fourth, it must integrate as natively and smoothly as possible with existing kernel infrastructure and userland expectations, tools, and APIs. And fifth, it must be buildable as an external kernel module without requiring any changes to the core Linux kernel. WireGuard is not merely an academic project with never-released laboratory code, but rather a practical project aiming for production-ready implementations.\n7.1 Queuing System #The WireGuard device driver has flags indicating to the kernel that it supports generic segmentation offload (GSO), scatter gather I/O, and hardware checksum offloading, which in sum means that the kernel will hand “super packets” to WireGuard, packets that are well over the MTU size, having been priorly queued up by the upper layers, such as TCP or the TCP and UDP corking systems. This allows WireGuard to operate on batch groups of outgoing packets. After splitting packets into≤MTU-sized chunks, WireGuard attempts to encrypt, encapsulate, and send over UDP all of these at once, caching routing information, so that it only has to be computed once per cluster of packets. This has the very important effect of also reducing cache misses: by waiting until all individual packets of a super packet have been encrypted and encapsulated to pass them off to the network layer, the very complicated and CPU-intensive network layer keeps instructions, intermediate variables, and branch predictions in CPU cache, giving in many cases a 35% increase in sending performance. As well, as mentioned in section 6.4, sometimes outgoing packets must be queued until a handshake completes successfully. When packets are finally able to be sent, the entire queue of existing queued packets along are treated as a single super packet, in order to benefit from the same optimizations as above.\nFinally, in order to prevent against needless allocations, all packet transformations are done in-place , avoiding the need for copying. This applies not only to the encryption and decryption of data, which occur in-place, but also to certain user space data and files sent usingsendfile(2); these are processed using this zero-copy super packet queuing system.\nFuture work on the queuing system could potentially involve integrating WireGuard with the FlowQueue [12]- CoDel [21] scheduling algorithm.\n7.2 Softirq \u0026amp; Parallelism #The xfrm layer, in contrast to WireGuard, has the advantage that it does not need to do cryptography in softirq, which opens it up to a bit more flexibility. However, there is precedent for doing cryptographic processing in softirq on the interface level: themac802111subsystem used for wireless WPA encryption. WireGuard, being a virtual interface that does encryption, is not architecturally so much different from wireless interfaces doing encryption at the same layer. While in practice it does work very well, it is not parallel. For this reason, the kernel’spadatasystem is used for parallelizing into concurrent workers encryption and decryption operations for utilization of all CPUs and CPU cores. As well, packet checksums can be computed in parallel with this method. When sending packets, however, they must be sent in order, which means each packet cannot simply be sent immediately after it is encrypted. Fortunately, thepadataAPI divides operations up into a parallel step, followed by an in-order serial step. This is also helpful for parallel decryption, in which the message counter must be checked and incremented in the order that packets arrive, lest they be rejected unnecessarily. In order to reduce latency, if there is only a single packet in a super packet and its length is less than 256 bytes, or if there is only one CPU core online, the packet is processed in softirq.\nLikewise, handshake initiation and response messages and cookie reply messages are processed on a separate parallel low-priority worker thread. As mentioned in section 5.3, ECDH operations are CPU intensive, so it is important that a flood of handshake work does not monopolize the CPU. Low priority background workqueues are employed for this asynchronous handshake message handling.\n7.3 RTNL-based Virtual Interface \u0026amp; Containerization #In order to integrate with the existingip(8)utilities and the netlink-based Linux user space, the kernel’s RTNL layer is used for registering a virtual interface, known inside the kernel as a “link”. This easily gives access to the kernel APIs accessed byip-link(8)andip-set(8). For configuring the interface private key and the public keys and endpoints of peers, initially theRTM_SETLINKRTNL message was used, but this proved to be too limited. It proved to be much cleaner to simply implement anioctl(2)-based API, passing a series of structures back and forth. While that approach was quite clean, the Linux networking stack is moving toward an entirely Netlink-based configuration API, so ultimately the Generic Netlink protocol was chosen. A separate user space tool,wg(8), is used for communicating over Netlink, and future plans involve integrating this functionality directly intoip(8).\nThe RTNL subsystem allows for moving the WireGuard virtual interface between network namespaces. This enables the sending and receiving sockets (for the outer UDP packets) to be created in one namespace, while the interface itself remains in another namespace. For example, adocker(1)orrkt(1)container guest could have as its sole network interface a WireGuard interface, with the actual outer encrypted packets being sent out of the real network interface on the host, creating end-to-end authenticated encryption in and out of the container.\n7.4 Data Structures and Primitives #While the Linux kernel already includes two elaborate routing table implementations—an LC-trie [22] for IPv and a radix trie for IPv6—they are intimately tied to the FIB routing layer, and not at all reusable for other uses. For this reason, a very minimal routing table was developed. The authors have had success implementing the cryptokey routing table as an allotment routing table [11], an LC-trie [22], and a standard radix trie, with each one giving adequate but slightly different performance characteristics. Ultimately the simplicity of the venerable radix trie was preferred, having good performance characteristics and the ability to implement it with lock-less lookups, using the RCU system [19]. Every time an outgoing packet goes through WireGuard, the destination peer is looked up using this table, and every time an incoming packet reaches WireGuard, its validity is checked by consulting this table, so performance is in fact important here.\nFor all handshake initiation messages (section 5.4.2), the responder must lookup the decrypted static public key of the initiator. For this, WireGuard employs a hash table using the extremely fast SipHash2-4 [1] MAC function with a secret, so that upper layers, which may provide the WireGuard interface with public keys in a more complicated key distribution scheme, cannot mount a hash table collision denial of service attack.\nWhile the Linux kernel’s crypto API has a large collection of primitives and is meant to be reused in several different systems, the API introduces needless complexity and allocations. Several revisions of WireGuard used the crypto API with different integration techniques, but ultimately, using raw primitives with direct, non-abstracted APIs proved to be far cleaner and less resource intensive. Both stack and heap pressure were reduced by using crypto primitives directly, rather than going through the kernel’s crypto API. The crypto API also makes it exceedingly difficult to avoid allocations when using multiple keys in the multifaceted ways required by Noise. As of writing, WireGuard ships with optimized implementations of ChaCha20Poly1305 for the various Intel Architecture vector extensions, with implementations for ARM/NEON and MIPS on their way. The fastest implementation supported by the hardware is selected at runtime, with the floating-point unit being used opportunistically. All ephemeral keys and intermediate results of cryptographic operations are zeroed out of memory after use, in order to maintain perfect forward secrecy and prevent against various potential leaks. The compiler must be specially informed about this explicit zeroing so that the “dead-store” is not optimized out, and for this the kernel provides thememzero_explicitfunction.\nIn contrast to crypto primitives, the existing kernel implementations of token bucket hash-based rate limiting, for rate limiting handshake initiation and response messages when under-load after cookie IP attribution has occurred, have been very minimal and easy to reuse in WireGuard. WireGuard uses the Netfilterhashlimit matcher for this.\n7.5 FIB Considerations #In order to avoid routing loops, one proposed change for the Linux kernel—currently posted by the authors to the Linux kernel mailing list [9]—is to allow for FIB route lookups that exclude an interface. This way, the kernel’s routing table could have0.0.0.0/1and128.0.0.0/1, for a combined coverage of0.0.0.0/0, while being more specific, sent to thewg0interface. Then, the individual endpoints of WireGuard peers could be routed using the device that a FIB lookup would return ifwg0did not exist, namely one through the actual0.0.0.0/ route. Or more generally, when looking up the correct interface for routing packets to particular peer endpoints, a route for an interface would be returned that is guaranteed not to bewg0. This is preferable to the current situation of needing to add explicit routes for WireGuard peer endpoints to the kernel routing table when the WireGuard-bound route has precedence. This work is ongoing.\nAnother approach, alluded to above, is to use network namespaces to entirely isolate the WireGuard interface and routing table from the physical interfaces and routing tables. One namespace would contain the WireGuard interface and a routing table with a default route to send all packets over the WireGuard interface. The other namespace would contain the various physical interfaces (Ethernet devices, wireless radios, and so forth) along with its usual routing table. The incoming and outgoing UDP socket for the WireGuard interface would live in the second physical interface namespace , not the first WireGuard interface namespace. This way, packets sent in the WireGuard interface namespace are encrypted there, and then sent using a socket that lives in the physical interface namespace. This prevents all routing loops and also ensures total isolation. Processes living in the WireGuard interface namespace would have as their only networking means the WireGuard interface, preventing any potential clear-text packet leakage.\n7.6 Potential Userspace Implementations #In order for WireGuard to have widespread adoption, more implementations than our current one for the Linux kernel must be written. As a next step, the authors plan to implement a cross-platform low-speed user space TUN-based implementation in a safe yet high-speed language like Rust, Go, or Haskell.\n8 Performance #WireGuard was benchmarked alongside IPsec in two modes and OpenVPN, using iperf3(1) between an Intel Core i7-3820QM and an Intel Core i7-5200U with Intel 82579LM and Intel I218LM gigabit Ethernet cards respectively, with results averaged over thirty minutes. The results were quite promising:\nProtocol Configuration WireGuard 256-bit ChaCha20, 128-bit Poly IPsec #1 256-bit ChaCha20, 128-bit Poly IPsec #2 256-bit AES, 128-bit GCM OpenVPN 256-bit AES, HMAC-SHA2-256, UDP mode For both metrics, WireGuard outperformed OpenVPN and both modes of IPsec. The CPU was at 100% utilization during the throughput tests of OpenVPN and IPsec, but was not completely utilized for the test of WireGuard, suggesting that WireGuard was able to completely saturate the gigabit Ethernet link. While the AES-NI-accelerated AES-GCM IPsec cipher suite appears to outperform the AVX2-accelerated ChaCha20Poly1305 IPsec cipher suite, as future chips increase the width of vector instructions—such as the upcom- ing AVX512—it is expected that over time ChaCha20Poly1305 will outperform AES-NI [4]. ChaCha20Poly is especially well suited to be implemented in software, free from side-channel attacks, with great efficiency, in contrast to AES, so for embedded platforms with no dedicated AES instructions, ChaCha20Poly1305 will also be most performant. Furthermore, WireGuard already outperforms both IPsec cipher suites, due to the simplicity of implementation and lack of overhead. The enormous gap between OpenVPN and WireGuard is to be expected, both in terms of ping time and throughput, because OpenVPN is a user space application, which means there is added latency and overhead of the scheduler and copying packets between user space and kernel space several times.\n9 Conclusion #In less than 4,000 lines, WireGuard demonstrates that it is possible to have secure network tunnels that are simply implemented, extremely performant, make use of state of the art cryptography, and remain easy to administer. The simplicity allows it to be very easily independently verified and reimplemented on a wide diversity of platforms. The cryptographic constructions and primitives utilized ensure high-speed in a wide diversity of devices, from data center servers to cellphones, as well as dependable security properties well into the future. The ease of deployment will also eliminate many of the common and disastrous pitfalls currently seen with many IPsec deployments. Described around the time of its introduction by Ferguson and Schneier [10], “IPsec was great disappointment to us. Given the quality of the people that [ sic ] worked on it and the time that was spent on it, we expected a much better result. [.. .] Our main criticism of IPsec is its complexity.”\nWireGuard, in contrast, focuses on simplicity and usability, while still delivering a scalable and highly secure system. By remaining silent to unauthenticated packets and by not making any allocations and generally keeping resource utilization to a minimum, it can be deployed on the outer edges of networks, as a trustworthy and reliable access point, which does not readily reveal itself to attackers nor provide a viable attack target. The cryptokey routing table paradigm is easy to learn and will promote safe network designs. The protocol is based on cryptographically sound and conservative principles, using well understood yet modern crypto primitives. WireGuard was designed from a practical perspective, meant to solve real world secure networking problems.\n10 Acknowledgments #WireGuard was made possible with the great advice and guidance of many, in particular: Trevor Perrin, Jean-Philippe Aumasson, Steven M. Bellovin, and Greg Kroah-Hartman.\nReferences # [1] Jean-Philippe Aumasson and Daniel J. Bernstein. “Progress in Cryptology - INDOCRYPT 2012: 13th International Conference on Cryptology in India, Kolkata, India, December 9-12, 2012. Proceedings”. In: ed. by Steven Galbraith and Mridul Nandi. Document ID:b9a943a805fbfc6fde808af9fc0ecdfa. Berlin, Heidelberg: Springer Berlin Heidelberg, 2012. Chap. SipHash: A Fast Short-Input PRF, pp. 489–508.isbn: 978-3-642-34931-7.doi:10.1007/978-3-642-34931-7_28.url:https://cr.yp.to/siphash/siphash- 20120918.pdf(cit. on p. 17). [2] Jean-Philippe Aumasson et al. “BLAKE2: Simpler, Smaller, Fast As MD5”. In: Proceedings of the 11th International Conference on Applied Cryptography and Network Security. ACNS’13. Banff, AB, Canada: Springer-Verlag, 2013, pp. 119–135.isbn: 978-3-642-38979-5.doi:10.1007/978-3-642-38980-1_8.url: https://blake2.net/blake2.pdf(cit. on p. 3). [3] Daniel J. Bernstein. “ChaCha, a variant of Salsa20”. In: SASC 2008. Document ID:4027b5256e17b 42e6d0f68b0b5e. 2008.url:https://cr.yp.to/chacha/chacha-20080128.pdf(cit. on p. 3). [4] Daniel J. Bernstein. CPUs Are Optimized for Video Games .url:https://moderncrypto.org/mail- archive/noise/2016/000699.html(cit. on p. 18). [5] Daniel J. Bernstein. “Curve25519: new Diffie-Hellman speed records”. In: Public Key Cryptography – PKC Ed. by Moti Yung et al. Vol. 3958. Lecture Notes in Computer Science. Document ID:4230efdfa 480fc079449d90f322c0. Berlin, Heidelberg: Springer-Verlag Berlin Heidelberg, 2006, pp. 207–228.isbn: 978-3-540-33852-9.doi:10.1007/11745853_14.url:https://cr.yp.to/ecdh/curve25519-20060209.pdf (cit. on p. 3). [6] Daniel J. Bernstein. Extending the Salsa20 nonce. Document ID:c4b172305ff16e1429a48d9434d50e8a. 2011.url:https://cr.yp.to/snuffle/xsalsa-20110204.pdf(cit. on p. 9). [7] Daniel J. Bernstein. TAI64, TAI64N, and TAI64NA .url:https://cr.yp.to/libtai/tai64.html(cit. on pp. 7, 10). [8] Daniel J. Bernstein. “The Poly1305-AES Message-Authentication Code”. In: Fast Software Encryption: 12th International Workshop, FSE 2005, Paris, France, February 21-23, 2005, Revised Selected Papers. Vol. 3557. Lecture Notes in Computer Science. Document ID:0018d9551b5546d97c340e0dd8cb5750. Springer, 2005, pp. 32–49.doi:10.1007/11502760_3.url:https://cr.yp.to/mac/poly1305-20050329.pdf(cit. on pp. 3, 15). [9] Jason A. Donenfeld. Inverse of flowi{4,6}_oif: flowi{4,6}_not_oif .url:http://lists.openwall.net/ netdev/2016/02/02/222(cit. on p. 17). [10] Niels Ferguson and Bruce Schneier. A Cryptographic Evaluation of IPsec. Tech. rep. Counterpane Internet Security, Inc, 2000.doi:10.1.1.33.7922.url:https://www.schneier.com/cryptography/paperfiles/ paper-ipsec.pdf(cit. on p. 18). [11] Yoichi Hariguchi. Allotment Routing Table: A Fast Free Multibit Trie Based Routing Table. 2002.url: https://github.com/hariguchi/art/blob/master/docs/art.pdf(cit. on p. 17). [12] Toke Hoeiland-Joergensen et al. The FlowQueue-CoDel Packet Scheduler and Active Queue Management Algorithm. RFC. Internet Engineering Task Force, Mar. 2016, p. 23.url:https://tools.ietf.org/html/draft- ietf-aqm-fq-codel-06(cit. on p. 16). [13] C. Kaufman et al. Internet Key Exchange Protocol Version 2. RFC 5996. RFC Editor, Sept. 2010.url: http://www.rfc-editor.org/rfc/rfc5996.txt(cit. on pp. 3, 8). [14] Stephen Kent and Randall Atkinson. Security Architecture for IP. RFC 2401. RFC Editor, Nov. 1998, p. 57.url:http://www.rfc-editor.org/rfc/rfc2401.txt(cit. on p. 13). [15] Hugo Krawczyk. “Advances in Cryptology – CRYPTO 2010: 30th Annual Cryptology Conference, Santa Barbara, CA, USA, August 15-19, 2010. Proceedings”. In: ed. by Tal Rabin. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010. Chap. Cryptographic Extraction and Key Derivation: The HKDF Scheme, pp. 631– 648.isbn: 978-3-642-14623-7.doi:10.1007/978-3-642-14623-7_34.url:https://eprint.iacr.org/2010/ 264.pdf(cit. on pp. 3, 10). [16] Hugo Krawczyk. “SIGMA: The ‘SIGn-and-MAc’ Approach to Authenticated Diffie-Hellman and Its Use in the IKE-Protocols”. In: Advances in Cryptology - CRYPTO 2003, 23rd Annual International Cryptology Conference, Santa Barbara, California, USA, August 17-21, 2003, Proceedings. Vol. 2729. Lecture Notes in Computer Science. Springer, 2003, pp. 400–425.doi:10.1007/978-3-540-45146-4_24. url:http://www.iacr.org/cryptodb/archive/2003/CRYPTO/1495/1495.pdf(cit. on p. 7). [17] Adam Langley and Yoav Nir. ChaCha20 and Poly1305 for IETF Protocols. RFC 7539. RFC Editor, May 2015.url:http://www.rfc-editor.org/rfc/rfc7539.txt(cit. on pp. 3, 9). [18] Kristin Lauter and Anton Mityagin. “Public Key Cryptography - PKC 2006: 9th International Conference on Theory and Practice in Public-Key Cryptography, New York, NY, USA, April 24-26, 2006. Proceedings”. In: ed. by Moti Yung et al. Berlin, Heidelberg: Springer Berlin Heidelberg, 2006. Chap. Security Analysis of KEA Authenticated Key Exchange Protocol, pp. 378–394.isbn: 978-3-540-33852-9.doi:10.1007/11745853_25. url:http://research.microsoft.com/en-us/um/people/klauter/pkcspringer.pdf(cit. on p. 7). [19] Paul E. McKenny et al. “Read-Copy Update”. In: Ottawa Linux Symposium. June 2002, pp. 338–367.url: [http://www.rdrop.com/~paulmck/RCU/rcu.2002.07.08.pdf(cit.](http://www.rdrop.com/~paulmck/RCU/rcu.2002.07.08.pdf(cit.) on p. 17). [20] R. Moskowitz et al. Host Identity Protocol Version 2. RFC 7401. RFC Editor, Apr. 2015.url:http: //www.rfc-editor.org/rfc/rfc7401.txt(cit. on p. 9). [21] Kathleen Nichols and Van Jacobson. “Controlling Queue Delay”. In: Commun. ACM 55.7 (July 2012), pp. 42–50.issn: 0001-0782.doi:10.1145/2209249.2209264.url:http://doi.acm.org/10.1145/2208917. 2209336 (cit. on p. 16). [22] Stefan Nilsson and Gunnar Karlsson. “IP-address lookup using LC-tries”. In: IEEE Journal on Selected Areas in Communications 17.6 (June 1999), pp. 1083–1092.issn: 0733-8716.doi:10.1109/49.772439.url: https://www.nada.kth.se/~snilsson/publications/IP-address-lookup-using-LC-tries/text.pdf(cit. on p. 17). [23] Trevor Perrin. The Noise Protocol Framework. 2016.url:http://noiseprotocol.org/noise.pdf(cit. on pp. 3, 7, 11, 12). [24] E. Rescorla and N. Modadugu. Datagram Transport Layer Security Version 1.2. RFC 6347. RFC Editor, Jan. 2012.url:http://www.rfc-editor.org/rfc/rfc6347.txt(cit. on p. 8). [25] Keith Winstein and Hari Balakrishnan. “Mosh: An Interactive Remote Shell for Mobile Clients”. In: USENIX Annual Technical Conference. Boston, MA, June 2012.url:https://mosh.mit.edu/mosh-paper.pdf (cit. on p. 5). [26] Xiangyang Zhang and Tina Tsou. IPsec Anti-Replay Algorithm without Bit Shifting. RFC 6479. RFC Editor, Jan. 2012, p. 9.url:http://www.rfc-editor.org/rfc/rfc6479.txt(cit. on p. 13). ","date":"1 January 0001","permalink":"/posts/wireguard/whitepaper/","section":"Posts","summary":"http://www.wireguard.com","title":"WireGuard: Next Generation Kernel Network Tunnel"},{"content":"WireGuard, a relatively new open-source VPN protocol introduced in 2016, has gained popularity due to its fast, efficient, and secure communication between online devices. It\u0026rsquo;s available across multiple platforms including Linux, Windows, Mac, Android, and iOS. WireGuard ensures secure connections by creating an encrypted tunnel, routing internet traffic via a VPN server for enhanced security and privacy.\nSecurity Features of WireGuard #WireGuard stands out for its use of ChaCha20 for encryption, a faster alternative to the commonly used AES-256 encryption in other VPN protocols. It also employs a streamlined approach for key generation and exchange, with a public key handshake process that establishes a secure connection between the server and client. Moreover, WireGuard operates using UDP, allowing for fast and secure data transmission.\nThe protocol\u0026rsquo;s design focuses on simplicity and efficiency, using only about 4,000 lines of code, significantly less than other VPN protocols like OpenVPN or IPsec. This compact codebase not only makes it easier to identify bugs but also reduces the risk of vulnerabilities. WireGuard uses modern encryption methods including Curve25519, Blake2s, and Poly1305, ensuring robust security for VPN use.\nBest Practices for Configuring WireGuard #Configuring WireGuard involves several key steps:\nInterface Addition #Adding a new interface for WireGuard and assigning IP addresses to peers.\nKey Generation #Creating base64-encoded public and private keys using the WireGuard utility.\nConfiguration #Setting up the interface with keys and peer endpoints, and activating the interface.\nWireGuard also supports silent operation when not in use, transmitting data only when required. However, for peers behind NAT or firewalls, enabling persistent keepalives ensures incoming packet reception, keeping the NAT/firewall mapping valid.\nComparing WireGuard with Other VPN Protocols #When compared to other VPN protocols like OpenVPN, WireGuard offers superior speed due to its more streamlined codebase and support for multi-threading. OpenVPN, on the other hand, provides flexibility, running on both TCP and UDP, and supports a wider range of encryption ciphers. However, its extensive code makes it harder to audit and thus, potentially more vulnerable to undiscovered security issues.\nIn terms of security, WireGuard has been professionally audited and found secure, with its simplicity allowing for easier combination with other obfuscation tools. OpenVPN, while older and well-established, has undergone fewer audits, highlighting the need for more frequent security checks.\nRegarding the ability to go undetected, OpenVPN has an advantage due to its ability to use TCP, making it harder to block. WireGuard, primarily using UDP, is easier to detect but can be combined with obfuscation methods to enhance its stealth.\nLevel of Support #OpenVPN currently enjoys wider support and easier installation across consumer VPNs and router firmware. WireGuard, while growing in popularity, faces challenges in router support and integration with proprietary protocols. Ultimately, the choice between WireGuard and OpenVPN depends on specific needs such as speed or evading geo-blocking, with WireGuard being the preferred choice for speed and efficiency.\nWireGuard represents a significant advancement in VPN technology, offering a balance of speed, security, and simplicity. Its ongoing development and open-source nature contribute to its continuous improvement and adaptability. As with any technology, it\u0026rsquo;s essential to stay updated on best practices and evolving features to ensure optimal performance and security.\n","date":"1 January 0001","permalink":"/posts/wireguard/security-features-and-best-practices/","section":"Posts","summary":"WireGuard, a relatively new open-source VPN protocol introduced in 2016, has gained popularity due to its fast, efficient, and secure communication between online devices.","title":"WireGuard's Security Features and Best Practices"}]